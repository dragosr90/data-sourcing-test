(bsrc-etl-venv) PS C:\Users\B25712\bsrc-etl-venv\bsrc-etl> pytest test/staging/test_extract_non_ssf_data.py 
========================================================================================== test session starts ===========================================================================================
platform win32 -- Python 3.10.11, pytest-8.3.3, pluggy-1.5.0
rootdir: C:\Users\B25712\bsrc-etl-venv\bsrc-etl
configfile: pyproject.toml
plugins: cov-6.0.0, mock-3.14.0
collected 25 items

test\staging\test_extract_non_ssf_data.py ...F...................F.                                                                                                                                 [100%]

================================================================================================ FAILURES ================================================================================================ 
___________________________________________________________________ test_place_static_data_individual_deadlines[202503-test-container] ___________________________________________________________________ 

spark_session = <pyspark.sql.session.SparkSession object at 0x000002907FC2CD00>, mocker = <pytest_mock.plugin.MockerFixture object at 0x000002907FDCFF40>, run_month = '202503'
source_container = 'test-container'
metadata_schema_with_deadline = StructType([StructField('SourceSystem', StringType(), True), StructField('SourceFileName', StringType(), True), Struct...ntegerType(), True), StructField('FileDeliveryStatus', StringType(), True), StructField('Deadline', DateType(), True)])
empty_log_df = DataFrame[SourceSystem: string, SourceFileName: string, DeliveryNumber: int, FileDeliveryStep: int, FileDeliveryStatus: string, Result: string, LastUpdatedDateTimestamp: timestamp, Comment: string]
caplog = <_pytest.logging.LogCaptureFixture object at 0x000002907FE51A80>

    @pytest.mark.parametrize(
        ("run_month", "source_container"),
        [("202503", "test-container")],
    )
    def test_place_static_data_individual_deadlines(
        spark_session,
        mocker,
        run_month,
        source_container,
        metadata_schema_with_deadline,
        empty_log_df,
        caplog,
    ):
        """Test place_static_data processes files based on individual deadlines."""
        test_container = f"abfss://{source_container}@bsrcdadls.dfs.core.windows.net"

        # Current time for comparison
        current_time = datetime.now(timezone.utc)
        yesterday = (current_time - timedelta(days=1)).date()
        tomorrow = (current_time + timedelta(days=1)).date()

        # Create mock metadata with different deadline scenarios
        mock_meta = spark_session.createDataFrame(
            [
                # File 1: Deadline passed, should be copied
                (
                    "lrd_static",
                    "FILE_PAST_DEADLINE",
                    ".txt",
                    "|",
                    "test_file1",
                    NonSSFStepStatus.EXPECTED.value,
                    "Expected",
                    yesterday,
                ),
                # File 2: Deadline not passed, should NOT be copied
                (
                    "lrd_static",
                    "FILE_FUTURE_DEADLINE",
                    ".txt",
                    "|",
                    "test_file2",
                    NonSSFStepStatus.EXPECTED.value,
                    "Expected",
                    tomorrow,
                ),
                # File 3: No deadline, should be copied if overall deadline passed
                (
                    "lrd_static",
                    "FILE_NO_DEADLINE",
                    ".txt",
                    "|",
                    "test_file3",
                    NonSSFStepStatus.EXPECTED.value,
                    "Expected",
                    None,
                ),
            ],
            schema=metadata_schema_with_deadline,
        )

        # Mock spark.read
        mock_read = mocker.patch("pyspark.sql.SparkSession.read", autospec=True)
        mock_read.table.side_effect = [mock_meta, empty_log_df]

        extraction = ExtractNonSSFData(
            spark_session,
            run_month,
            source_container=source_container,
        )

        # Mock filesystem operations
        mock_dbutils_fs_ls = mocker.patch.object(extraction.dbutils.fs, "ls")
        mock_dbutils_fs_cp = mocker.patch.object(extraction.dbutils.fs, "cp")

        # Set up ls responses for each file check
        mock_dbutils_fs_ls.side_effect = [
            # FILE_PAST_DEADLINE check
            [
                FileInfoMock(
                    {
                        "path": f"{test_container}/LRD_STATIC/processed/FILE_PAST_DEADLINE_20240101.txt",  # noqa: E501
                        "name": "FILE_PAST_DEADLINE_20240101.txt",
                    }
                )
            ],
            [
                FileInfoMock(
                    {
                        "path": f"{test_container}/LRD_STATIC/processed/FILE_PAST_DEADLINE_20240101.txt",  # noqa: E501
                        "name": "FILE_PAST_DEADLINE_20240101.txt",
                    }
                )
            ],
            # FILE_FUTURE_DEADLINE check - won't be called due to deadline check
            # FILE_NO_DEADLINE check
            [
                FileInfoMock(
                    {
                        "path": f"{test_container}/LRD_STATIC/processed/FILE_NO_DEADLINE_20240101.txt",  # noqa: E501
                        "name": "FILE_NO_DEADLINE_20240101.txt",
                    }
                )
            ],
            [
                FileInfoMock(
                    {
                        "path": f"{test_container}/LRD_STATIC/processed/FILE_NO_DEADLINE_20240101.txt",  # noqa: E501
                        "name": "FILE_NO_DEADLINE_20240101.txt",
                    }
                )
            ],
        ]

        # Mock saveAsTable to prevent actual writes
        mocker.patch("pyspark.sql.DataFrameWriter.saveAsTable")

        # Call place_static_data with overall deadline passed
        extraction.place_static_data([], deadline_passed=True)

        # Verify that only files with passed deadlines were copied
>       assert (
            mock_dbutils_fs_cp.call_count == 2
        )  # Only FILE_PAST_DEADLINE and FILE_NO_DEADLINE
E       AssertionError: assert 0 == 2
E        +  where 0 = <MagicMock name='cp' id='2819644348048'>.call_count

test\staging\test_extract_non_ssf_data.py:584: AssertionError
------------------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------------------ 
2025-07-11 12:53:17 [ERROR] place_static_data:  File FILE_NO_DEADLINE not delivered and not found in LRD_STATIC/processed folder.
2025-07-11 12:53:17 [ERROR] place_static_data:  File FILE_NO_DEADLINE not delivered and not found in LRD_STATIC/processed folder.
2025-07-11 12:53:19 [ERROR] place_static_data:  File FILE_FUTURE_DEADLINE not delivered and not found in LRD_STATIC/processed folder.
2025-07-11 12:53:19 [ERROR] place_static_data:  File FILE_FUTURE_DEADLINE not delivered and not found in LRD_STATIC/processed folder.
2025-07-11 12:53:20 [ERROR] place_static_data:  File FILE_PAST_DEADLINE not delivered and not found in LRD_STATIC/processed folder.
2025-07-11 12:53:20 [ERROR] place_static_data:  File FILE_PAST_DEADLINE not delivered and not found in LRD_STATIC/processed folder.
------------------------------------------------------------------------------------------ Captured stderr call ------------------------------------------------------------------------------------------ 

------------------------------------------------------------------------------------------- Captured log call -------------------------------------------------------------------------------------------- 
ERROR    betl_src_poc_logger:extract_nonssf_data.py:147 File FILE_NO_DEADLINE not delivered and not found in LRD_STATIC/processed folder.
ERROR    betl_src_poc_logger:extract_nonssf_data.py:147 File FILE_FUTURE_DEADLINE not delivered and not found in LRD_STATIC/processed folder.
ERROR    betl_src_poc_logger:extract_nonssf_data.py:147 File FILE_PAST_DEADLINE not delivered and not found in LRD_STATIC/processed folder.
_________________________________________________________________________ test_save_to_stg_table_failure[202503-test-container] __________________________________________________________________________ 

spark_session = <pyspark.sql.session.SparkSession object at 0x000002907FC2CD00>, mocker = <pytest_mock.plugin.MockerFixture object at 0x000002907FC6E950>, run_month = '202503'
source_container = 'test-container'
metadata_schema = StructType([StructField('SourceSystem', StringType(), True), StructField('SourceFileName', StringType(), True), Struct...), True), StructField('FileDeliveryStep', IntegerType(), True), StructField('FileDeliveryStatus', StringType(), True)])
empty_log_df = DataFrame[SourceSystem: string, SourceFileName: string, DeliveryNumber: int, FileDeliveryStep: int, FileDeliveryStatus: string, Result: string, LastUpdatedDateTimestamp: timestamp, Comment: string]

    @pytest.mark.parametrize(
        ("run_month", "source_container"),
        [("202503", "test-container")],
    )
    def test_save_to_stg_table_failure(
        spark_session,
        mocker,
        run_month,
        source_container,
        metadata_schema,
        empty_log_df,
    ):
        """Test save_to_stg_table failure handling."""
        # Create mock metadata DataFrame
        mock_meta = spark_session.createDataFrame(
            [
                (
                    "nme",
                    "TEST_FILE",
                    ".csv",
                    ",",
                    "test_file",
                    NonSSFStepStatus.EXPECTED.value,
                    "Expected",
                ),
            ],
            schema=metadata_schema,
        )

        # Mock spark.read
        mock_read = mocker.patch("pyspark.sql.SparkSession.read", autospec=True)
        mock_read.table.side_effect = [mock_meta, empty_log_df]

        extraction = ExtractNonSSFData(
            spark_session,
            run_month,
            source_container=source_container,
        )

        # Create a dummy DataFrame
        dummy_df = spark_session.createDataFrame([(1, "test")], ["id", "value"])

        # Mock the saveAsTable to fail by patching at the method level
        mock_save_table = mocker.patch("pyspark.sql.DataFrameWriter.saveAsTable")
        mock_save_table.side_effect = Exception("Write failed")

        # Test save_to_stg_table with failure
>       result = extraction.save_to_stg_table(
            data=dummy_df,
            stg_table_name="test_table",
            source_system="NME",
            file_name="TEST_FILE.csv",
        )

test\staging\test_extract_non_ssf_data.py:1966:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  
src\staging\extract_base.py:396: in save_to_stg_table
    self.update_log_metadata(
src\staging\extract_base.py:218: in update_log_metadata
    write_to_log(
src\utils\table_logging.py:33: in write_to_log
    log_entry_df.write.mode("append").saveAsTable(
C:\Program Files\Python310\lib\unittest\mock.py:1114: in __call__
    return self._mock_call(*args, **kwargs)
C:\Program Files\Python310\lib\unittest\mock.py:1118: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
C:\Program Files\Python310\lib\unittest\mock.py:1173: in _execute_mock_call
    raise effect
src\staging\extract_base.py:393: in save_to_stg_table
    comment = self.write_table_with_exception(data, full_path)
src\staging\extract_base.py:118: in write_table_with_exception
    data.write.mode("overwrite").saveAsTable(full_table_name)
C:\Program Files\Python310\lib\unittest\mock.py:1114: in __call__
    return self._mock_call(*args, **kwargs)
C:\Program Files\Python310\lib\unittest\mock.py:1118: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  

self = <MagicMock name='saveAsTable' id='2819644235952'>, args = ('bsrc_d.stg_202503.test_table',), kwargs = {}, effect = Exception('Write failed')

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method

        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
>               raise effect
E               Exception: Write failed

C:\Program Files\Python310\lib\unittest\mock.py:1173: Exception
------------------------------------------------------------------------------------------ Captured stdout call ------------------------------------------------------------------------------------------ 
2025-07-11 12:54:28 [ERROR] save_to_stg_table:  Failed to save to staging table bsrc_d.stg_202503.test_table
Traceback (most recent call last):
  File "C:\Users\B25712\bsrc-etl-venv\bsrc-etl\src\staging\extract_base.py", line 393, in save_to_stg_table
    comment = self.write_table_with_exception(data, full_path)
  File "C:\Users\B25712\bsrc-etl-venv\bsrc-etl\src\staging\extract_base.py", line 118, in write_table_with_exception
    data.write.mode("overwrite").saveAsTable(full_table_name)
  File "C:\Program Files\Python310\lib\unittest\mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "C:\Program Files\Python310\lib\unittest\mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "C:\Program Files\Python310\lib\unittest\mock.py", line 1173, in _execute_mock_call
    raise effect
Exception: Write failed
2025-07-11 12:54:28 [ERROR] save_to_stg_table:  Failed to save to staging table bsrc_d.stg_202503.test_table
Traceback (most recent call last):
  File "C:\Users\B25712\bsrc-etl-venv\bsrc-etl\src\staging\extract_base.py", line 393, in save_to_stg_table
    comment = self.write_table_with_exception(data, full_path)
  File "C:\Users\B25712\bsrc-etl-venv\bsrc-etl\src\staging\extract_base.py", line 118, in write_table_with_exception
    data.write.mode("overwrite").saveAsTable(full_table_name)
  File "C:\Program Files\Python310\lib\unittest\mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "C:\Program Files\Python310\lib\unittest\mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "C:\Program Files\Python310\lib\unittest\mock.py", line 1173, in _execute_mock_call
    raise effect
Exception: Write failed
2025-07-11 12:54:28 [INFO] update_log_metadata:  FileDeliveryStatus: Loaded Staging table for TEST_FILE
2025-07-11 12:54:28 [INFO] update_log_metadata:  FileDeliveryStatus: Loaded Staging table for TEST_FILE
------------------------------------------------------------------------------------------ Captured stderr call ------------------------------------------------------------------------------------------ 

------------------------------------------------------------------------------------------- Captured log call -------------------------------------------------------------------------------------------- 
ERROR    betl_src_poc_logger:extract_base.py:395 Failed to save to staging table bsrc_d.stg_202503.test_table
Traceback (most recent call last):
  File "C:\Users\B25712\bsrc-etl-venv\bsrc-etl\src\staging\extract_base.py", line 393, in save_to_stg_table
    comment = self.write_table_with_exception(data, full_path)
  File "C:\Users\B25712\bsrc-etl-venv\bsrc-etl\src\staging\extract_base.py", line 118, in write_table_with_exception
    data.write.mode("overwrite").saveAsTable(full_table_name)
  File "C:\Program Files\Python310\lib\unittest\mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "C:\Program Files\Python310\lib\unittest\mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "C:\Program Files\Python310\lib\unittest\mock.py", line 1173, in _execute_mock_call
    raise effect
Exception: Write failed
INFO     betl_src_poc_logger:extract_base.py:214 FileDeliveryStatus: Loaded Staging table for TEST_FILE
============================================================================================ warnings summary ============================================================================================ 
..\bsrc-etl-venv\lib\site-packages\holidays\deprecations\v1_incompatibility.py:40
  C:\Users\B25712\bsrc-etl-venv\bsrc-etl-venv\lib\site-packages\holidays\deprecations\v1_incompatibility.py:40: FutureIncompatibilityWarning:

  This is a future version incompatibility warning from Holidays v0.62
  to inform you about an upcoming change in our API versioning strategy that may affect your
  project's dependencies. Starting from version 1.0 onwards, we will be following a loose form of
  Semantic Versioning (SemVer, https://semver.org) to provide clearer communication regarding any
  potential breaking changes.

  This means that while we strive to maintain backward compatibility, there might be occasional
  updates that introduce breaking changes to our API. To ensure the stability of your projects,
  we highly recommend pinning the version of our API that you rely on. You can pin your current
  holidays v0.x dependency (e.g., holidays==0.62) or limit it (e.g., holidays<1.0) in order to
  avoid potentially unwanted upgrade to the version 1.0 when it's released (ETA 2025Q1-Q2).

  If you have any questions or concerns regarding this change, please don't hesitate to reach out
  to us via https://github.com/vacanza/holidays/discussions/1800.

    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform win32, python 3.10.11-final-0 ----------
Name                                            Stmts   Miss  Cover   Missing
-----------------------------------------------------------------------------
src\__init__.py                                     0      0   100%
src\config\__init__.py                              0      0   100%
src\config\business_logic.py                       52      0   100%
src\config\constants.py                             1      0   100%
src\config\exceptions.py                           21      0   100%
src\config\process.py                               4      4     0%   7-10
src\config\schema.py                                4      4     0%   3-52
src\dq\__init__.py                                  0      0   100%
src\dq\dq_validation.py                           141    108    23%   54-55, 69, 77-78, 88, 166-181, 197-249, 265-286, 318-350, 372-392, 414-486
src\extract\__init__.py                             0      0   100%
src\extract\master_data_sql.py                     90     71    21%   31-33, 37-38, 42, 59-88, 109-137, 149-156, 162-164, 188, 222-231, 285-300, 329-356
src\month_setup\__init__.py                         0      0   100%
src\month_setup\dial_derive_snapshotdate.py        32     27    16%   12-18, 28-37, 47-50, 69-85
src\month_setup\metadata_log_tables.py             32     25    22%   23-84, 159, 166-203
src\month_setup\setup_new_month.py                 13     13     0%   17-84
src\staging\__init__.py                             0      0   100%
src\staging\extract_base.py                        97     20    79%   165, 171-173, 313-321, 344-348, 354, 360, 386, 388, 403, 436, 438
src\staging\extract_dial_data.py                   65     65     0%   16-360
src\staging\extract_nonssf_data.py                136      1    99%   310
src\staging\extract_ssf_data.py                   164    164     0%   26-620
src\staging\status.py                              57      5    91%   18, 53-54, 107, 151
src\transform\__init__.py                           0      0   100%
src\transform\table_write_and_comment.py           72     72     0%   14-237
src\transform\transform_business_logic_sql.py       6      6     0%   6-25
src\utils\__init__.py                               0      0   100%
src\utils\alias_util.py                            13     13     0%   10-109
src\utils\export_parquet.py                        15      6    60%   49-54, 67-68
src\utils\get_dbutils.py                            2      0   100%
src\utils\get_env.py                               10      0   100%
src\utils\logging_util.py                           6      0   100%
src\utils\parameter_utils.py                       23     13    43%   34, 38-42, 79-84, 105-116
src\utils\parse_yaml.py                            22     22     0%   11-127
src\utils\sources_util.py                          52     52     0%   7-218
src\utils\table_logging.py                         14      1    93%   55
src\utils\table_schema.py                           3      3     0%   8-16
src\utils\transformations_util.py                  17     12    29%   20-25, 39, 51, 65-68
src\validate\__init__.py                            0      0   100%
src\validate\base.py                                4      4     0%   4-7
src\validate\expressions.py                        27     27     0%   15-75
src\validate\run_all.py                             7      7     0%   12-48
src\validate\sources.py                            29     29     0%   7-67
src\validate\transformations.py                   192    192     0%   21-593
src\validate\validate_sql.py                       54     54     0%   13-130
src\validate\yaml.py                               18     18     0%   3-34
-----------------------------------------------------------------------------
TOTAL                                            1495   1038    31%
Coverage HTML written to dir htmlcov

======================================================================================== short test summary info ========================================================================================= 
FAILED test/staging/test_extract_non_ssf_data.py::test_place_static_data_individual_deadlines[202503-test-container] - AssertionError: assert 0 == 2
FAILED test/staging/test_extract_non_ssf_data.py::test_save_to_stg_table_failure[202503-test-container] - Exception: Write failed
========================================================================== 2 failed, 23 passed, 1 warning in 186.34s (0:03:06) =========================================================================== 
SUCCESS: The process with PID 26232 (child process of PID 24632) has been terminated.
SUCCESS: The process with PID 24632 (child process of PID 232) has been terminated.
SUCCESS: The process with PID 232 (child process of PID 22404) has been terminated.
