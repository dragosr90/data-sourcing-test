(bsrc-etl-venv) PS C:\Users\B25712\bsrc-etl-venv\bsrc-etl> pytest test/staging/test_extract_non_ssf_data.py
===================================================================================== test session starts ======================================================================================
platform win32 -- Python 3.10.11, pytest-8.3.3, pluggy-1.5.0
rootdir: C:\Users\B25712\bsrc-etl-venv\bsrc-etl
configfile: pyproject.toml
plugins: cov-6.0.0, mock-3.14.0
collected 4 items

test\staging\test_extract_non_ssf_data.py F...                                                                                                                                            [100%]

=========================================================================================== FAILURES =========================================================================================== 
_______________________________________________________________________ test_extract_non_ssf_data[202505-test-container] _______________________________________________________________________ 

spark_session = <pyspark.sql.session.SparkSession object at 0x000001B40604A4A0>, mocker = <pytest_mock.plugin.MockerFixture object at 0x000001B406049C00>, run_month = '202505'
source_container = 'test-container', caplog = <_pytest.logging.LogCaptureFixture object at 0x000001B406049840>

    @pytest.mark.parametrize(
        ("run_month", "source_container"),
        [("202505", "test-container")],
    )
    def test_extract_non_ssf_data(
        spark_session,
        mocker,
        run_month,
        source_container,
        caplog,
    ):
        test_container = f"abfss://{source_container}@bsrcdadls.dfs.core.windows.net"
        month_container = f"abfss://{run_month}@bsrcdadls.dfs.core.windows.net"
        metadata_path = f"bsrc_d.metadata_{run_month}.metadata_nonssf"
        log_path = f"bsrc_d.log_{run_month}.log_nonssf"

        # Create deadline dates
        future_date = (datetime.now(timezone.utc) + timedelta(days=10)).strftime("%Y-%m-%d")
        past_date = (datetime.now(timezone.utc) - timedelta(days=5)).strftime("%Y-%m-%d")

        # Create a mock DataFrame with deadline column
        schema_meta = [
            "SourceSystem",
            "SourceFileName",
            "SourceFileFormat",
            "SourceFileDelimiter",
            "StgTableName",
            "FileDeliveryStep",
            "FileDeliveryStatus",
            "Deadline",
        ]
        mock_meta = spark_session.createDataFrame(
            [
                (
                    "lrd_static",
                    "TEST_NON_SSF_V1",
                    ".txt",
                    "|",
                    "test_non_ssf_v1",
                    NonSSFStepStatus.EXPECTED.value,  # Use the actual enum value
                    "Expected",
                    future_date,  # Future deadline
                ),
                (
                    "lrd_static",
                    "TEST_NON_SSF_V2",
                    ".txt",
                    "|",
                    "test_non_ssf_v2",
                    NonSSFStepStatus.EXPECTED.value,  # Use the actual enum value
                    "Expected",
                    past_date,  # Past deadline - should be copied
                ),
                (
                    "nme",
                    "TEST_NON_SSF_V3",
                    ".parquet",
                    ",",
                    "test_non_ssf_v3",
                    NonSSFStepStatus.EXPECTED.value,  # Use the actual enum value
                    "Expected",
                    future_date,
                ),
                (
                    "finob",
                    "TEST_NON_SSF_V4",
                    ".csv",
                    ",",
                    "test_non_ssf_v4",
                    NonSSFStepStatus.EXPECTED.value,  # Use the actual enum value
                    "Expected",
                    past_date,  # Past deadline
                ),
            ],
            schema=schema_meta,
        )

        schema_log = [
            "SourceSystem",
            "SourceFileName",
            "DeliveryNumber",
            "FileDeliveryStep",
            "FileDeliveryStatus",
            "Result",
            "LastUpdatedDateTimestamp",
            "Comment",
        ]
        mock_log = spark_session.createDataFrame(
            [
                (
                    "lrd_static",
                    "TEST_NON_SSF_V1",
                    1,
                    NonSSFStepStatus.EXPECTED.value,  # Use the actual enum value
                    "Expected",
                    "Success",
                    datetime.now(timezone.utc),
                    "Test comment",
                )
            ],
            schema=schema_log,
        )

        dummy_df = spark_session.createDataFrame(
            [(1, "2", 3)],
            schema=StructType(
                [
                    StructField("col1", IntegerType()),
                    StructField("col2", StringType()),
                    StructField("col3", IntegerType()),
                ]
            ),
        )

        # Mock spark.read.json and spark.read.table to return the mock DataFrames
        mock_read = mocker.patch("pyspark.sql.SparkSession.read", autospec=True)
        mock_read.table.side_effect = [
            mock_meta,
            mock_log,
            dummy_df,
            dummy_df,
            dummy_df,
            dummy_df,
        ]

        mock_write = mocker.patch("pyspark.sql.DataFrameWriter.parquet")
        mock_save_table = mocker.patch("pyspark.sql.DataFrameWriter.saveAsTable")

        # Check ExtractNonSSFData class initialisation
        extraction = ExtractNonSSFData(
            spark_session,
            run_month,
            source_container=source_container,
        )

        # Verify that spark.read.table was called with the correct arguments
        mock_read.table.assert_any_call(f"bsrc_d.metadata_{run_month}.metadata_nonssf")
        mock_read.table.assert_any_call(f"bsrc_d.log_{run_month}.log_nonssf")

        # Test deadline checking
        deadline_reached, deadline_str = extraction.check_deadline_reached(
            "TEST_NON_SSF_V1"
        )
        assert not deadline_reached  # Future deadline
        assert deadline_str == future_date

        deadline_reached, deadline_str = extraction.check_deadline_reached(
            "TEST_NON_SSF_V2"
        )
        assert deadline_reached  # Past deadline
        assert deadline_str == past_date

        mock_dbutils_fs_ls = mocker.patch.object(extraction.dbutils.fs, "ls")
        effect = [
            [
                FileInfoMock(
                    {
                        "path": f"{test_container}/{folder}/{file}",
                        "name": f"{file}",
                    }
                )
                for file, folder in li
            ]
            for li in [
                [
                    ("TEST_NON_SSF_V3.parquet", "NME"),
                    ("processed/", "NME"),
                ],
                [("TEST_NON_SSF_V4.csv", "FINOB"), ("processed/", "FINOB")],
                [
                    ("TEST_NON_SSF_V1.txt", "LRD_STATIC"),
                    ("TEST_NON_SSF_V5.txt", "LRD_STATIC"),
                    ("processed/", "LRD_STATIC"),
                ],
                [("TEST_NON_SSF_V2_999999.txt", "LRD_STATIC/processed")],
                [("TEST_NON_SSF_V2_999999.txt", "LRD_STATIC/processed")],
            ]
        ]
        mock_dbutils_fs_ls.side_effect = effect
        mock_dbutils_fs_cp = mocker.patch.object(extraction.dbutils.fs, "cp")
        mock_dbutils_fs_mv = mocker.patch.object(extraction.dbutils.fs, "mv")

        found_files = extraction.get_all_files()

        # V2 should be copied because deadline is reached
        mock_dbutils_fs_cp.assert_any_call(
            f"{test_container}/LRD_STATIC/processed/TEST_NON_SSF_V2_999999.txt",
            f"{test_container}/LRD_STATIC/TEST_NON_SSF_V2.txt",
        )

        # Check that the warning for V5 (not in metadata) is present
        assert (
            "File TEST_NON_SSF_V5 not found in metadata. "
            "Please check if it should be delivered." in caplog.messages
        )

        # Test check_missing_files_after_deadline
        # Mock the ls calls for this test
        with patch.object(extraction.dbutils.fs, "ls") as mock_ls_missing:
            # Set up the mock to simulate missing FINOB file after deadline
            def ls_side_effect(path):
                if "FINOB" in path:
                    return []  # No files in FINOB
                if "NME" in path:
                    return [
                        FileInfoMock(
                            {"name": "TEST_NON_SSF_V3.parquet", "isDir": lambda: False}
                        )
                    ]
                return []

            mock_ls_missing.side_effect = ls_side_effect

            missing_files = extraction.check_missing_files_after_deadline()

            # V4 should be missing (FINOB, past deadline)
            assert any(f["file_name"] == "TEST_NON_SSF_V4" for f in missing_files)
            # V3 should not be missing (NME, future deadline)
            assert not any(f["file_name"] == "TEST_NON_SSF_V3" for f in missing_files)
            # LRD_STATIC files should not be checked in this method anymore
            assert not any(f["source_system"] == "LRD_STATIC" for f in missing_files)

        # Test log_missing_files_errors
        missing_test_files = [
            {"source_system": "FINOB", "file_name": "TEST_FILE", "deadline": "2024-01-01"}
        ]
        has_critical = extraction.log_missing_files_errors(missing_test_files)
        assert has_critical  # FINOB is critical

        mock_read.csv.return_value = dummy_df
        mock_read.parquet.return_value = dummy_df

        for file in found_files:
            file_name = file["file_name"]
            file_name_base = Path(file_name).name
            file_name_no_ext = Path(file_name).stem
            file_name_ext = Path(file_name).suffix
            source_system = file["source_system"]

            # All files should pass initial checks since we removed the .csv version
            assert extraction.initial_checks(**file) is True

            assert extraction.convert_to_parquet(**file)

            if source_system == "LRD_STATIC" or source_system == "FINOB":
                sep = {"LRD_STATIC": "|", "FINOB": ","}.get(source_system, ",")
                mock_read.csv.assert_any_call(
                    f"{test_container}/{source_system}/{file_name_base}",
                    sep=sep,
                    header=True,
                )
            else:
                mock_read.parquet.assert_any_call(
                    f"{test_container}/{source_system}/{file_name_base}",
                )
            mock_write.assert_any_call(
                f"{month_container}/sourcing_landing_data/NON_SSF/{source_system}/{file_name_no_ext}.parquet",
                mode="overwrite",
            )

            assert extraction.move_source_file(**file)

            calls = mock_dbutils_fs_mv.call_args_list
            assert any(
                args[0] == f"{test_container}/{source_system}/{file_name_base}"
                and re.match(
                    rf"{test_container}/{source_system}/processed/{file_name_no_ext}__\d{{8}}\d{{6}}{file_name_ext}",
                    args[1],
                )
                for args, _ in calls
            )

            data = extraction.extract_from_parquet(file["source_system"], file["file_name"])
            stg_table_name = extraction.get_staging_table_name(file["file_name"])
            assert extraction.save_to_stg_table(
                data=data,
                stg_table_name=stg_table_name,
                **file,
            )
            mock_save_table.assert_any_call(
                f"bsrc_d.stg_{run_month}.{file_name_no_ext.lower()}"
            )

            assert extraction.validate_data_quality(
                **file,
                stg_table_name=file_name_no_ext.lower(),
            )

        # Count update metadata and log calls
        metadata_path_calls, log_path_calls = (
            len(
                [
                    call_args
                    for call_args in mock_save_table.call_args_list
                    if call_args == call(path)
                ]
            )
            for path in [metadata_path, log_path]
        )

        # For every file (v1, v2, v3, v4) we log every step: 4 files X 6 steps = 24
        # + 1 step for log_missing_files_errors test
        # So in total 25 calls for metadata and log
>       assert metadata_path_calls == 25
E       assert 19 == 25

test\staging\test_extract_non_ssf_data.py:326: AssertionError
------------------------------------------------------------------------------------ Captured stderr setup ------------------------------------------------------------------------------------- 
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
------------------------------------------------------------------------------------- Captured stdout call ------------------------------------------------------------------------------------- 
2025-07-29 15:49:41 [INFO] update_log_metadata:  FileDeliveryStatus: Received / Placed for TEST_NON_SSF_V4
2025-07-29 15:49:41 [INFO] update_log_metadata:  FileDeliveryStatus: Received / Placed for TEST_NON_SSF_V4
2025-07-29 15:49:44 [INFO] update_log_metadata:  FileDeliveryStatus: Received / Placed for TEST_NON_SSF_V1
2025-07-29 15:49:44 [INFO] update_log_metadata:  FileDeliveryStatus: Received / Placed for TEST_NON_SSF_V1
2025-07-29 15:49:46 [WARNING] get_all_files:  File TEST_NON_SSF_V5 not found in metadata. Please check if it should be delivered.
2025-07-29 15:49:46 [WARNING] get_all_files:  File TEST_NON_SSF_V5 not found in metadata. Please check if it should be delivered.
2025-07-29 15:49:50 [INFO] place_static_data:  Copied TEST_NON_SSF_V2 to static folder after deadline reached.
2025-07-29 15:49:50 [INFO] place_static_data:  Copied TEST_NON_SSF_V2 to static folder after deadline reached.
2025-07-29 15:49:50 [INFO] update_log_metadata:  FileDeliveryStatus: Received / Placed for TEST_NON_SSF_V2
2025-07-29 15:49:50 [INFO] update_log_metadata:  FileDeliveryStatus: Received / Placed for TEST_NON_SSF_V2
2025-07-29 15:49:56 [ERROR] log_missing_files_errors:  File TEST_FILE from FINOB is missing after deadline (2024-01-01)
2025-07-29 15:49:56 [ERROR] log_missing_files_errors:  File TEST_FILE from FINOB is missing after deadline (2024-01-01)
2025-07-29 15:49:56 [INFO] update_log_metadata:  FileDeliveryStatus: Initial checks done for TEST_FILE
2025-07-29 15:49:56 [INFO] update_log_metadata:  FileDeliveryStatus: Initial checks done for TEST_FILE
2025-07-29 15:49:59 [INFO] update_log_metadata:  FileDeliveryStatus: Initial checks done for TEST_NON_SSF_V4
2025-07-29 15:49:59 [INFO] update_log_metadata:  FileDeliveryStatus: Initial checks done for TEST_NON_SSF_V4
2025-07-29 15:50:02 [INFO] export_to_parquet:  Exported to sourcing_landing_data/NON_SSF/FINOB/TEST_NON_SSF_V4.parquet
2025-07-29 15:50:02 [INFO] export_to_parquet:  Exported to sourcing_landing_data/NON_SSF/FINOB/TEST_NON_SSF_V4.parquet
2025-07-29 15:50:02 [INFO] update_log_metadata:  FileDeliveryStatus: Converted to Parquet for TEST_NON_SSF_V4
2025-07-29 15:50:02 [INFO] update_log_metadata:  FileDeliveryStatus: Converted to Parquet for TEST_NON_SSF_V4
2025-07-29 15:50:05 [INFO] update_log_metadata:  FileDeliveryStatus: Moved source file for TEST_NON_SSF_V4
2025-07-29 15:50:05 [INFO] update_log_metadata:  FileDeliveryStatus: Moved source file for TEST_NON_SSF_V4
2025-07-29 15:50:08 [INFO] update_log_metadata:  FileDeliveryStatus: Loaded Staging table for abfss://test-container@bsrcdadls.dfs.core.windows.net/FINOB/TEST_NON_SSF_V4.csv
2025-07-29 15:50:08 [INFO] update_log_metadata:  FileDeliveryStatus: Loaded Staging table for abfss://test-container@bsrcdadls.dfs.core.windows.net/FINOB/TEST_NON_SSF_V4.csv
2025-07-29 15:50:09 [INFO] standardize_delivery_entity:  Standardized delivery entity 'FINOB' to 'finob'
2025-07-29 15:50:09 [INFO] standardize_delivery_entity:  Standardized delivery entity 'FINOB' to 'finob'
2025-07-29 15:50:09 [INFO] __init__:  No generic checks file available for stg.test_non_ssf_v4 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v4.yml
2025-07-29 15:50:09 [INFO] __init__:  No generic checks file available for stg.test_non_ssf_v4 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v4.yml
2025-07-29 15:50:09 [INFO] __init__:  No specific checks file available for stg.test_non_ssf_v4 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v4.yml
2025-07-29 15:50:09 [INFO] __init__:  No specific checks file available for stg.test_non_ssf_v4 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v4.yml
2025-07-29 15:50:09 [INFO] columns_datatypes:  No columns to check
2025-07-29 15:50:09 [INFO] columns_datatypes:  No columns to check
2025-07-29 15:50:09 [INFO] primary_key:  No Primary Key to check
2025-07-29 15:50:09 [INFO] primary_key:  No Primary Key to check
2025-07-29 15:50:09 [INFO] not_null:  No not nullable columns to check
2025-07-29 15:50:09 [INFO] not_null:  No not nullable columns to check
2025-07-29 15:50:09 [INFO] unique:  No unique columns to check
2025-07-29 15:50:09 [INFO] unique:  No unique columns to check
2025-07-29 15:50:09 [INFO] checks:  No checks done
2025-07-29 15:50:09 [INFO] checks:  No checks done
2025-07-29 15:50:09 [INFO] update_log_metadata:  FileDeliveryStatus: Checked Data Quality for abfss://test-container@bsrcdadls.dfs.core.windows.net/FINOB/TEST_NON_SSF_V4.csv
2025-07-29 15:50:09 [INFO] update_log_metadata:  FileDeliveryStatus: Checked Data Quality for abfss://test-container@bsrcdadls.dfs.core.windows.net/FINOB/TEST_NON_SSF_V4.csv
2025-07-29 15:50:12 [INFO] update_log_metadata:  FileDeliveryStatus: Initial checks done for TEST_NON_SSF_V1
2025-07-29 15:50:12 [INFO] update_log_metadata:  FileDeliveryStatus: Initial checks done for TEST_NON_SSF_V1
2025-07-29 15:50:15 [INFO] export_to_parquet:  Exported to sourcing_landing_data/NON_SSF/LRD_STATIC/TEST_NON_SSF_V1.parquet
2025-07-29 15:50:15 [INFO] export_to_parquet:  Exported to sourcing_landing_data/NON_SSF/LRD_STATIC/TEST_NON_SSF_V1.parquet
2025-07-29 15:50:15 [INFO] update_log_metadata:  FileDeliveryStatus: Converted to Parquet for TEST_NON_SSF_V1
2025-07-29 15:50:15 [INFO] update_log_metadata:  FileDeliveryStatus: Converted to Parquet for TEST_NON_SSF_V1
2025-07-29 15:50:16 [INFO] update_log_metadata:  FileDeliveryStatus: Moved source file for TEST_NON_SSF_V1
2025-07-29 15:50:16 [INFO] update_log_metadata:  FileDeliveryStatus: Moved source file for TEST_NON_SSF_V1
2025-07-29 15:50:19 [INFO] update_log_metadata:  FileDeliveryStatus: Loaded Staging table for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V1.txt
2025-07-29 15:50:19 [INFO] update_log_metadata:  FileDeliveryStatus: Loaded Staging table for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V1.txt
2025-07-29 15:50:21 [INFO] standardize_delivery_entity:  Standardized delivery entity 'LRD_STATIC' to 'lrdstatic'
2025-07-29 15:50:21 [INFO] standardize_delivery_entity:  Standardized delivery entity 'LRD_STATIC' to 'lrdstatic'
2025-07-29 15:50:21 [INFO] __init__:  No generic checks file available for stg.test_non_ssf_v1 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v1.yml
2025-07-29 15:50:21 [INFO] __init__:  No generic checks file available for stg.test_non_ssf_v1 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v1.yml
2025-07-29 15:50:21 [INFO] __init__:  No specific checks file available for stg.test_non_ssf_v1 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v1.yml
2025-07-29 15:50:21 [INFO] __init__:  No specific checks file available for stg.test_non_ssf_v1 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v1.yml
2025-07-29 15:50:21 [INFO] columns_datatypes:  No columns to check
2025-07-29 15:50:21 [INFO] columns_datatypes:  No columns to check
2025-07-29 15:50:21 [INFO] primary_key:  No Primary Key to check
2025-07-29 15:50:21 [INFO] primary_key:  No Primary Key to check
2025-07-29 15:50:21 [INFO] not_null:  No not nullable columns to check
2025-07-29 15:50:21 [INFO] not_null:  No not nullable columns to check
2025-07-29 15:50:21 [INFO] unique:  No unique columns to check
2025-07-29 15:50:21 [INFO] unique:  No unique columns to check
2025-07-29 15:50:21 [INFO] checks:  No checks done
2025-07-29 15:50:21 [INFO] checks:  No checks done
2025-07-29 15:50:21 [INFO] update_log_metadata:  FileDeliveryStatus: Checked Data Quality for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V1.txt
2025-07-29 15:50:21 [INFO] update_log_metadata:  FileDeliveryStatus: Checked Data Quality for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V1.txt
2025-07-29 15:50:24 [INFO] update_log_metadata:  FileDeliveryStatus: Initial checks done for TEST_NON_SSF_V2
2025-07-29 15:50:24 [INFO] update_log_metadata:  FileDeliveryStatus: Initial checks done for TEST_NON_SSF_V2
2025-07-29 15:50:26 [INFO] export_to_parquet:  Exported to sourcing_landing_data/NON_SSF/LRD_STATIC/TEST_NON_SSF_V2.parquet
2025-07-29 15:50:26 [INFO] export_to_parquet:  Exported to sourcing_landing_data/NON_SSF/LRD_STATIC/TEST_NON_SSF_V2.parquet
2025-07-29 15:50:26 [INFO] update_log_metadata:  FileDeliveryStatus: Converted to Parquet for TEST_NON_SSF_V2
2025-07-29 15:50:26 [INFO] update_log_metadata:  FileDeliveryStatus: Converted to Parquet for TEST_NON_SSF_V2
2025-07-29 15:50:28 [INFO] update_log_metadata:  FileDeliveryStatus: Moved source file for TEST_NON_SSF_V2
2025-07-29 15:50:28 [INFO] update_log_metadata:  FileDeliveryStatus: Moved source file for TEST_NON_SSF_V2
2025-07-29 15:50:31 [INFO] update_log_metadata:  FileDeliveryStatus: Loaded Staging table for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V2.txt
2025-07-29 15:50:31 [INFO] update_log_metadata:  FileDeliveryStatus: Loaded Staging table for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V2.txt
2025-07-29 15:50:32 [INFO] standardize_delivery_entity:  Standardized delivery entity 'LRD_STATIC' to 'lrdstatic'
2025-07-29 15:50:32 [INFO] standardize_delivery_entity:  Standardized delivery entity 'LRD_STATIC' to 'lrdstatic'
2025-07-29 15:50:32 [INFO] __init__:  No generic checks file available for stg.test_non_ssf_v2 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v2.yml
2025-07-29 15:50:32 [INFO] __init__:  No generic checks file available for stg.test_non_ssf_v2 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v2.yml
2025-07-29 15:50:32 [INFO] __init__:  No specific checks file available for stg.test_non_ssf_v2 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v2.yml
2025-07-29 15:50:32 [INFO] __init__:  No specific checks file available for stg.test_non_ssf_v2 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v2.yml
2025-07-29 15:50:32 [INFO] columns_datatypes:  No columns to check
2025-07-29 15:50:32 [INFO] columns_datatypes:  No columns to check
2025-07-29 15:50:32 [INFO] primary_key:  No Primary Key to check
2025-07-29 15:50:32 [INFO] primary_key:  No Primary Key to check
2025-07-29 15:50:32 [INFO] not_null:  No not nullable columns to check
2025-07-29 15:50:32 [INFO] not_null:  No not nullable columns to check
2025-07-29 15:50:32 [INFO] unique:  No unique columns to check
2025-07-29 15:50:32 [INFO] unique:  No unique columns to check
2025-07-29 15:50:32 [INFO] checks:  No checks done
2025-07-29 15:50:32 [INFO] checks:  No checks done
2025-07-29 15:50:32 [INFO] update_log_metadata:  FileDeliveryStatus: Checked Data Quality for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V2.txt
2025-07-29 15:50:32 [INFO] update_log_metadata:  FileDeliveryStatus: Checked Data Quality for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V2.txt
------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------- 

-------------------------------------------------------------------------------------- Captured log call --------------------------------------------------------------------------------------- 
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Received / Placed for TEST_NON_SSF_V4
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Received / Placed for TEST_NON_SSF_V1
WARNING  betl_src_poc_logger:extract_nonssf_data.py:357 File TEST_NON_SSF_V5 not found in metadata. Please check if it should be delivered.
INFO     betl_src_poc_logger:extract_nonssf_data.py:203 Copied TEST_NON_SSF_V2 to static folder after deadline reached.
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Received / Placed for TEST_NON_SSF_V2
ERROR    betl_src_poc_logger:extract_nonssf_data.py:302 File TEST_FILE from FINOB is missing after deadline (2024-01-01)
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Initial checks done for TEST_FILE
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Initial checks done for TEST_NON_SSF_V4
INFO     betl_src_poc_logger:export_parquet.py:56 Exported to sourcing_landing_data/NON_SSF/FINOB/TEST_NON_SSF_V4.parquet
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Converted to Parquet for TEST_NON_SSF_V4
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Moved source file for TEST_NON_SSF_V4
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Loaded Staging table for abfss://test-container@bsrcdadls.dfs.core.windows.net/FINOB/TEST_NON_SSF_V4.csv
INFO     betl_src_poc_logger:parameter_utils.py:49 Standardized delivery entity 'FINOB' to 'finob'
INFO     betl_src_poc_logger:dq_validation.py:71 No generic checks file available for stg.test_non_ssf_v4 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v4.yml
INFO     betl_src_poc_logger:dq_validation.py:90 No specific checks file available for stg.test_non_ssf_v4 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v4.yml
INFO     betl_src_poc_logger:dq_validation.py:198 No columns to check
INFO     betl_src_poc_logger:dq_validation.py:266 No Primary Key to check
INFO     betl_src_poc_logger:dq_validation.py:375 No not nullable columns to check
INFO     betl_src_poc_logger:dq_validation.py:321 No unique columns to check
INFO     betl_src_poc_logger:dq_validation.py:174 No checks done
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Checked Data Quality for abfss://test-container@bsrcdadls.dfs.core.windows.net/FINOB/TEST_NON_SSF_V4.csv
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Initial checks done for TEST_NON_SSF_V1
INFO     betl_src_poc_logger:export_parquet.py:56 Exported to sourcing_landing_data/NON_SSF/LRD_STATIC/TEST_NON_SSF_V1.parquet
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Converted to Parquet for TEST_NON_SSF_V1
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Moved source file for TEST_NON_SSF_V1
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Loaded Staging table for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V1.txt
INFO     betl_src_poc_logger:parameter_utils.py:49 Standardized delivery entity 'LRD_STATIC' to 'lrdstatic'
INFO     betl_src_poc_logger:dq_validation.py:71 No generic checks file available for stg.test_non_ssf_v1 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v1.yml
INFO     betl_src_poc_logger:dq_validation.py:90 No specific checks file available for stg.test_non_ssf_v1 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v1.yml
INFO     betl_src_poc_logger:dq_validation.py:198 No columns to check
INFO     betl_src_poc_logger:dq_validation.py:266 No Primary Key to check
INFO     betl_src_poc_logger:dq_validation.py:375 No not nullable columns to check
INFO     betl_src_poc_logger:dq_validation.py:321 No unique columns to check
INFO     betl_src_poc_logger:dq_validation.py:174 No checks done
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Checked Data Quality for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V1.txt
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Initial checks done for TEST_NON_SSF_V2
INFO     betl_src_poc_logger:export_parquet.py:56 Exported to sourcing_landing_data/NON_SSF/LRD_STATIC/TEST_NON_SSF_V2.parquet
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Converted to Parquet for TEST_NON_SSF_V2
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Moved source file for TEST_NON_SSF_V2
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Loaded Staging table for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V2.txt
INFO     betl_src_poc_logger:parameter_utils.py:49 Standardized delivery entity 'LRD_STATIC' to 'lrdstatic'
INFO     betl_src_poc_logger:dq_validation.py:71 No generic checks file available for stg.test_non_ssf_v2 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v2.yml
INFO     betl_src_poc_logger:dq_validation.py:90 No specific checks file available for stg.test_non_ssf_v2 at C:\Users\B25712\bsrc-etl-venv\bsrc-etl\dq_checks\stg\test_non_ssf_v2.yml
INFO     betl_src_poc_logger:dq_validation.py:198 No columns to check
INFO     betl_src_poc_logger:dq_validation.py:266 No Primary Key to check
INFO     betl_src_poc_logger:dq_validation.py:375 No not nullable columns to check
INFO     betl_src_poc_logger:dq_validation.py:321 No unique columns to check
INFO     betl_src_poc_logger:dq_validation.py:174 No checks done
INFO     betl_src_poc_logger:extract_base.py:205 FileDeliveryStatus: Checked Data Quality for abfss://test-container@bsrcdadls.dfs.core.windows.net/LRD_STATIC/TEST_NON_SSF_V2.txt
======================================================================================= warnings summary ======================================================================================= 
..\bsrc-etl-venv\lib\site-packages\holidays\deprecations\v1_incompatibility.py:40
  C:\Users\B25712\bsrc-etl-venv\bsrc-etl-venv\lib\site-packages\holidays\deprecations\v1_incompatibility.py:40: FutureIncompatibilityWarning:

  This is a future version incompatibility warning from Holidays v0.62
  to inform you about an upcoming change in our API versioning strategy that may affect your
  project's dependencies. Starting from version 1.0 onwards, we will be following a loose form of
  Semantic Versioning (SemVer, https://semver.org) to provide clearer communication regarding any
  potential breaking changes.

  This means that while we strive to maintain backward compatibility, there might be occasional
  updates that introduce breaking changes to our API. To ensure the stability of your projects,
  we highly recommend pinning the version of our API that you rely on. You can pin your current
  holidays v0.x dependency (e.g., holidays==0.62) or limit it (e.g., holidays<1.0) in order to
  avoid potentially unwanted upgrade to the version 1.0 when it's released (ETA 2025Q1-Q2).

  If you have any questions or concerns regarding this change, please don't hesitate to reach out
  to us via https://github.com/vacanza/holidays/discussions/1800.

    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform win32, python 3.10.11-final-0 ----------
Name                                                             Stmts   Miss  Cover   Missing
----------------------------------------------------------------------------------------------
src\__init__.py                                                      0      0   100%
src\abnamro_bsrc_etl\__init__.py                                     0      0   100%
src\abnamro_bsrc_etl\config\__init__.py                              0      0   100%
src\abnamro_bsrc_etl\config\business_logic.py                       54      0   100%
src\abnamro_bsrc_etl\config\constants.py                             2      0   100%
src\abnamro_bsrc_etl\config\exceptions.py                           31     31     0%   1-71
src\abnamro_bsrc_etl\config\process.py                               7      7     0%   1-10
src\abnamro_bsrc_etl\config\schema.py                                5      5     0%   1-52
src\abnamro_bsrc_etl\dq\__init__.py                                  0      0   100%
src\abnamro_bsrc_etl\dq\dq_validation.py                           150     88    41%   54-55, 69, 77-78, 88, 176-181, 201-249, 269-286, 323-350, 377-392, 414-486
src\abnamro_bsrc_etl\extract\__init__.py                             0      0   100%
src\abnamro_bsrc_etl\extract\master_data_sql.py                     96     71    26%   31-33, 37-38, 42, 59-88, 109-137, 149-156, 162-164, 188, 222-231, 285-300, 329-356
src\abnamro_bsrc_etl\month_setup\__init__.py                         0      0   100%
src\abnamro_bsrc_etl\month_setup\dial_derive_snapshotdate.py        36     27    25%   12-18, 28-37, 47-50, 69-85
src\abnamro_bsrc_etl\month_setup\metadata_log_tables.py             40     25    38%   23-84, 159, 166-203
src\abnamro_bsrc_etl\month_setup\setup_new_month.py                 29     29     0%   1-94
src\abnamro_bsrc_etl\scripts\__init__.py                             0      0   100%
src\abnamro_bsrc_etl\scripts\dial_check_delayed_files.py            27     27     0%   1-69
src\abnamro_bsrc_etl\scripts\dial_staging_process.py                65     65     0%   1-280
src\abnamro_bsrc_etl\scripts\export_tine_tables.py                   6      6     0%   1-9
src\abnamro_bsrc_etl\scripts\new_month_setup.py                      7      7     0%   1-18
src\abnamro_bsrc_etl\scripts\nonssf_staging_process.py              63     63     0%   1-279
src\abnamro_bsrc_etl\scripts\run_mapping.py                         26     26     0%   9-113
src\abnamro_bsrc_etl\scripts\ssf_staging_process.py                 58     58     0%   1-234
src\abnamro_bsrc_etl\staging\__init__.py                             0      0   100%
src\abnamro_bsrc_etl\staging\extract_base.py                        77      8    90%   156, 162-164, 304-312
src\abnamro_bsrc_etl\staging\extract_dial_data.py                   77     77     0%   1-360
src\abnamro_bsrc_etl\staging\extract_nonssf_data.py                149     21    86%   114-119, 181-185, 188-193, 217-218, 256-258, 267, 348-350, 409-416
src\abnamro_bsrc_etl\staging\extract_ssf_data.py                   177    177     0%   1-620
src\abnamro_bsrc_etl\staging\status.py                              58      5    91%   18, 53-54, 107, 151
src\abnamro_bsrc_etl\transform\__init__.py                           0      0   100%
src\abnamro_bsrc_etl\transform\table_write_and_comment.py           79     79     0%   1-237
src\abnamro_bsrc_etl\transform\transform_business_logic_sql.py       9      9     0%   1-25
src\abnamro_bsrc_etl\utils\__init__.py                               0      0   100%
src\abnamro_bsrc_etl\utils\alias_util.py                            18     18     0%   1-109
src\abnamro_bsrc_etl\utils\export_parquet.py                        22      6    73%   49-54, 67-68
src\abnamro_bsrc_etl\utils\get_dbutils.py                            3      0   100%
src\abnamro_bsrc_etl\utils\get_env.py                               12      0   100%
src\abnamro_bsrc_etl\utils\logging_util.py                          10      0   100%
src\abnamro_bsrc_etl\utils\parameter_utils.py                       25     13    48%   34, 38-42, 79-84, 105-116
src\abnamro_bsrc_etl\utils\parse_yaml.py                            28     28     0%   1-127
src\abnamro_bsrc_etl\utils\sources_util.py                          56     56     0%   1-218
src\abnamro_bsrc_etl\utils\table_logging.py                         19      0   100%
src\abnamro_bsrc_etl\utils\table_schema.py                           6      6     0%   1-16
src\abnamro_bsrc_etl\utils\transformations_util.py                  20     12    40%   20-25, 39, 51, 65-68
src\abnamro_bsrc_etl\validate\__init__.py                            0      0   100%
src\abnamro_bsrc_etl\validate\base.py                                5      5     0%   1-7
src\abnamro_bsrc_etl\validate\expressions.py                        34     34     0%   1-75
src\abnamro_bsrc_etl\validate\run_all.py                            15     15     0%   1-48
src\abnamro_bsrc_etl\validate\sources.py                            33     33     0%   1-67
src\abnamro_bsrc_etl\validate\transformations.py                   200    200     0%   1-593
src\abnamro_bsrc_etl\validate\validate_sql.py                       63     63     0%   1-130
src\abnamro_bsrc_etl\validate\yaml.py                               19     19     0%   1-34
----------------------------------------------------------------------------------------------
TOTAL                                                             1916   1419    26%
Coverage HTML written to dir htmlcov

=================================================================================== short test summary info ==================================================================================== 
FAILED test/staging/test_extract_non_ssf_data.py::test_extract_non_ssf_data[202505-test-container] - assert 19 == 25
====================================================================== 1 failed, 3 passed, 1 warning in 96.91s (0:01:36) ======================================================================= 
SUCCESS: The process with PID 22796 (child process of PID 512) has been terminated.
SUCCESS: The process with PID 512 (child process of PID 19024) has been terminated.
SUCCESS: The process with PID 19024 (child process of PID 13104) has been terminated.
