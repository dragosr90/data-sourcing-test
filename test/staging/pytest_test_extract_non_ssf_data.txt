(bsrc-etl-venv) PS C:\Users\B25712\bsrc-etl-venv\bsrc-etl> pytest test/staging/test_extract_non_ssf_data.py
====================================================================================== test session starts =======================================================================================
platform win32 -- Python 3.10.11, pytest-8.3.3, pluggy-1.5.0
rootdir: C:\Users\B25712\bsrc-etl-venv\bsrc-etl
configfile: pyproject.toml
plugins: cov-6.0.0, mock-3.14.0
collected 4 items

test\staging\test_extract_non_ssf_data.py ...F                                                                                                                                              [100%]

============================================================================================ FAILURES ============================================================================================ 
___________________________________________________________________ test_place_static_data_keyword_only[202503-test-container] ___________________________________________________________________ 

spark_session = <pyspark.sql.session.SparkSession object at 0x00000222FF6C25C0>, mocker = <pytest_mock.plugin.MockerFixture object at 0x00000222FF952A40>, run_month = '202503'
source_container = 'test-container'

    @pytest.mark.parametrize(
        ("run_month", "source_container"),
        [("202503", "test-container")],
    )
    def test_place_static_data_keyword_only(
        spark_session,
        mocker,
        run_month,
        source_container,
    ):
        """Test that place_static_data requires deadline_passed as keyword argument."""
        # Create mock metadata DataFrame
        schema_meta = [
            "SourceSystem",
            "SourceFileName",
            "SourceFileFormat",
            "SourceFileDelimiter",
            "StgTableName",
            "FileDeliveryStep",
            "FileDeliveryStatus",
        ]
        mock_meta = spark_session.createDataFrame(
            [
                (
                    "LRD_STATIC",  # Uppercase
                    "TEST_FILE",
                    ".txt",
                    "|",
                    "test_file",
                    0,
                    "Expected",
                ),
            ],
            schema=schema_meta,
        )

        # Create schema for log DataFrame
        schema_log = StructType(
            [
                StructField("SourceSystem", StringType(), True),  # noqa: FBT003
                StructField("SourceFileName", StringType(), True),  # noqa: FBT003
                StructField("DeliveryNumber", IntegerType(), True),  # noqa: FBT003
                StructField("FileDeliveryStep", IntegerType(), True),  # noqa: FBT003
                StructField("FileDeliveryStatus", StringType(), True),  # noqa: FBT003
                StructField("Result", StringType(), True),  # noqa: FBT003
                StructField("LastUpdatedDateTimestamp", TimestampType(), True),  # noqa: FBT003
                StructField("Comment", StringType(), True),  # noqa: FBT003
            ]
        )

        # Create empty DataFrame with schema
        mock_log = spark_session.createDataFrame([], schema=schema_log)

        # Mock spark.read
        mock_read = mocker.patch("pyspark.sql.SparkSession.read", autospec=True)
        mock_read.table.side_effect = [mock_meta, mock_log]

        # Create extraction instance
        extraction = ExtractNonSSFData(
            spark_session,
            run_month,
            source_container=source_container,
        )

        # Test that calling with positional argument raises TypeError
        with pytest.raises(
            TypeError, match="takes 2 positional arguments but 3 were given"
        ):
            extraction.place_static_data([], True)  # noqa: FBT003 - Testing that positional bool fails

        # Test that calling with keyword argument works
>       result = extraction.place_static_data([], deadline_passed=True)  # This should work

test\staging\test_extract_non_ssf_data.py:498:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  
src\staging\extract_nonssf_data.py:136: in place_static_data
    for file in self.dbutils.fs.ls(processed_folder)
..\bsrc-etl-venv\lib\site-packages\databricks\sdk\dbutils.py:59: in ls
    return [
..\bsrc-etl-venv\lib\site-packages\databricks\sdk\dbutils.py:59: in <listcomp>
    return [
..\bsrc-etl-venv\lib\site-packages\databricks\sdk\mixins\files.py:620: in list
    p = self._path(path)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  

self = <databricks.sdk.mixins.files.DbfsExt object at 0x00000222FF9C85E0>
src = ParseResult(scheme='abfss', netloc='test-container@bsrcdadls.dfs.core.windows.net', path='/LRD_STATIC/processed', params='', query='', fragment='')

    def _path(self, src):
        src = parse.urlparse(str(src))
        if src.scheme and src.scheme not in self.__ALLOWED_SCHEMES:
>           raise ValueError(
                f'unsupported scheme "{src.scheme}". DBUtils in the SDK only supports local, root DBFS, and '
                "UC Volumes paths, not external locations or DBFS mount points."
            )
E           ValueError: unsupported scheme "abfss". DBUtils in the SDK only supports local, root DBFS, and UC Volumes paths, not external locations or DBFS mount points.

..\bsrc-etl-venv\lib\site-packages\databricks\sdk\mixins\files.py:638: ValueError
-------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------- 

======================================================================================== warnings summary ======================================================================================== 
..\bsrc-etl-venv\lib\site-packages\holidays\deprecations\v1_incompatibility.py:40
  C:\Users\B25712\bsrc-etl-venv\bsrc-etl-venv\lib\site-packages\holidays\deprecations\v1_incompatibility.py:40: FutureIncompatibilityWarning:

  This is a future version incompatibility warning from Holidays v0.62
  to inform you about an upcoming change in our API versioning strategy that may affect your
  project's dependencies. Starting from version 1.0 onwards, we will be following a loose form of
  Semantic Versioning (SemVer, https://semver.org) to provide clearer communication regarding any
  potential breaking changes.

  This means that while we strive to maintain backward compatibility, there might be occasional
  updates that introduce breaking changes to our API. To ensure the stability of your projects,
  we highly recommend pinning the version of our API that you rely on. You can pin your current
  holidays v0.x dependency (e.g., holidays==0.62) or limit it (e.g., holidays<1.0) in order to
  avoid potentially unwanted upgrade to the version 1.0 when it's released (ETA 2025Q1-Q2).

  If you have any questions or concerns regarding this change, please don't hesitate to reach out
  to us via https://github.com/vacanza/holidays/discussions/1800.

    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform win32, python 3.10.11-final-0 ----------
Name                                            Stmts   Miss  Cover   Missing
-----------------------------------------------------------------------------
src\__init__.py                                     0      0   100%
src\config\__init__.py                              0      0   100%
src\config\business_logic.py                       52      0   100%
src\config\constants.py                             1      0   100%
src\config\exceptions.py                           21     21     0%   6-48
src\config\process.py                               4      4     0%   7-10
src\config\schema.py                                4      4     0%   3-52
src\dq\__init__.py                                  0      0   100%
src\dq\dq_validation.py                           141     88    38%   54-55, 69, 77-78, 88, 176-181, 201-249, 269-286, 323-350, 377-392, 414-486
src\extract\__init__.py                             0      0   100%
src\extract\master_data_sql.py                     90     71    21%   31-33, 37-38, 42, 59-88, 109-137, 149-156, 162-164, 188, 222-231, 285-300, 329-356
src\month_setup\__init__.py                         0      0   100%
src\month_setup\dial_derive_snapshotdate.py        32     27    16%   12-18, 28-37, 47-50, 69-85
src\month_setup\metadata_log_tables.py             32     25    22%   23-84, 159, 166-203
src\month_setup\setup_new_month.py                 13     13     0%   17-84
src\staging\__init__.py                             0      0   100%
src\staging\extract_base.py                        65      8    88%   156, 162-164, 304-312
src\staging\extract_dial_data.py                   65     65     0%   16-360
src\staging\extract_nonssf_data.py                103     13    87%   126-130, 140-143, 146-150, 175-176, 209-211, 291-295
src\staging\extract_ssf_data.py                   164    164     0%   26-620
src\staging\status.py                              57      5    91%   18, 53-54, 107, 151
src\transform\__init__.py                           0      0   100%
src\transform\table_write_and_comment.py           72     72     0%   14-237
src\transform\transform_business_logic_sql.py       6      6     0%   6-25
src\utils\__init__.py                               0      0   100%
src\utils\alias_util.py                            13     13     0%   10-109
src\utils\export_parquet.py                        15      6    60%   49-54, 67-68
src\utils\get_dbutils.py                            2      0   100%
src\utils\get_env.py                               10      0   100%
src\utils\logging_util.py                           6      0   100%
src\utils\parameter_utils.py                       23     13    43%   34, 38-42, 79-84, 105-116
src\utils\parse_yaml.py                            22     22     0%   11-127
src\utils\sources_util.py                          52     52     0%   7-218
src\utils\table_logging.py                         14      0   100%
src\utils\table_schema.py                           3      3     0%   8-16
src\utils\transformations_util.py                  17     12    29%   20-25, 39, 51, 65-68
src\validate\__init__.py                            0      0   100%
src\validate\base.py                                4      4     0%   4-7
src\validate\expressions.py                        27     27     0%   15-75
src\validate\run_all.py                             7      7     0%   12-48
src\validate\sources.py                            29     29     0%   7-67
src\validate\transformations.py                   192    192     0%   21-593
src\validate\validate_sql.py                       54     54     0%   13-130
src\validate\yaml.py                               18     18     0%   3-34
-----------------------------------------------------------------------------
TOTAL                                            1430   1038    27%
Coverage HTML written to dir htmlcov

==================================================================================== short test summary info =====================================================================================
FAILED test/staging/test_extract_non_ssf_data.py::test_place_static_data_keyword_only[202503-test-container] - ValueError: unsupported scheme "abfss". DBUtils in the SDK only supports local, root DBFS, and UC Volumes paths, not external locations or DBFS mount points.
======================================================================= 1 failed, 3 passed, 1 warning in 99.91s (0:01:39) ======================================================================== 
SUCCESS: The process with PID 2572 (child process of PID 24128) has been terminated.
SUCCESS: The process with PID 24128 (child process of PID 24880) has been terminated.
SUCCESS: The process with PID 24880 (child process of PID 20200) has been terminated.
