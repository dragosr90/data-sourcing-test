2025-09-05T12:28:08.5797203Z ##[section]Starting: Test with pytest
2025-09-05T12:28:08.5802155Z ==============================================================================
2025-09-05T12:28:08.5802344Z Task         : Command line
2025-09-05T12:28:08.5802440Z Description  : Run a command line script using Bash on Linux and macOS and cmd.exe on Windows
2025-09-05T12:28:08.5802583Z Version      : 2.250.1
2025-09-05T12:28:08.5802673Z Author       : Microsoft Corporation
2025-09-05T12:28:08.5802768Z Help         : https://docs.microsoft.com/azure/devops/pipelines/tasks/utility/command-line
2025-09-05T12:28:08.5802889Z ==============================================================================
2025-09-05T12:28:08.8012347Z Generating script.
2025-09-05T12:28:08.8020327Z ========================== Starting Command Output ===========================
2025-09-05T12:28:08.8032320Z [command]/usr/bin/bash --noprofile --norc /__w/_temp/e1c27730-d817-43aa-a69b-dbb1f4a61df4.sh
2025-09-05T12:28:08.8092394Z ------------------------- python -m site ---------
2025-09-05T12:28:08.8219697Z sys.path = [
2025-09-05T12:28:08.8220324Z     '/__w/167/s',
2025-09-05T12:28:08.8220761Z     '/usr/local/lib/python311.zip',
2025-09-05T12:28:08.8221228Z     '/usr/local/lib/python3.11',
2025-09-05T12:28:08.8221656Z     '/usr/local/lib/python3.11/lib-dynload',
2025-09-05T12:28:08.8222129Z     '/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages',
2025-09-05T12:28:08.8222619Z     '/usr/local/lib/python3.11/site-packages',
2025-09-05T12:28:08.8223078Z ]
2025-09-05T12:28:08.8223633Z USER_BASE: '/home/pipeuser_azpcontainer/.local' (exists)
2025-09-05T12:28:08.8224123Z USER_SITE: '/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages' (exists)
2025-09-05T12:28:08.8224566Z ENABLE_USER_SITE: True
2025-09-05T12:28:08.8248690Z ------------------------ python -c 'import site; print(site.getsitepackages())' ----------
2025-09-05T12:28:08.8334854Z ['/usr/local/lib/python3.11/site-packages']
2025-09-05T12:28:08.8355180Z ------------------------ python -m site --user-site ----------
2025-09-05T12:28:08.8542050Z /home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages
2025-09-05T12:28:09.1090739Z Defaulting to user installation because normal site-packages is not writeable
2025-09-05T12:28:09.1972511Z Looking in indexes: https://p-nexus-3.development.nl.eu.abnamro.com:8443/repository/python-group/simple, https://p-nexus-3.development.nl.eu.abnamro.com:8443/repository/python-group/simple
2025-09-05T12:28:09.2875338Z Collecting pytest-azure-devops
2025-09-05T12:28:09.2966816Z   Downloading https://p-nexus-3.development.nl.eu.abnamro.com:8443/repository/python-group/packages/pytest-azure-devops/0.3.0/pytest_azure_devops-0.3.0-py3-none-any.whl (9.2 kB)
2025-09-05T12:28:09.3118702Z Requirement already satisfied: pytest in /home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages (8.3.3)
2025-09-05T12:28:09.3132203Z Requirement already satisfied: pytest-cov in /home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages (6.0.0)
2025-09-05T12:28:09.3140301Z Requirement already satisfied: pytest-mock in /home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages (3.14.0)
2025-09-05T12:28:09.3236737Z Requirement already satisfied: iniconfig in /home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages (from pytest) (2.1.0)
2025-09-05T12:28:09.3244449Z Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from pytest) (25.0)
2025-09-05T12:28:09.3254111Z Requirement already satisfied: pluggy<2,>=1.5 in /home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages (from pytest) (1.6.0)
2025-09-05T12:28:09.3316817Z Requirement already satisfied: coverage>=7.5 in /home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages (from coverage[toml]>=7.5->pytest-cov) (7.10.6)
2025-09-05T12:28:09.6378315Z Installing collected packages: pytest-azure-devops
2025-09-05T12:28:09.6580078Z Successfully installed pytest-azure-devops-0.3.0
2025-09-05T12:28:09.6973871Z 
2025-09-05T12:28:09.6974658Z [notice] A new release of pip is available: 24.0 -> 25.2
2025-09-05T12:28:09.6975295Z [notice] To update, run: pip install --upgrade pip
2025-09-05T12:28:12.3260120Z ============================= test session starts ==============================
2025-09-05T12:28:12.3260573Z platform linux -- Python 3.11.13, pytest-8.3.3, pluggy-1.6.0
2025-09-05T12:28:12.3260872Z rootdir: /__w/167/s
2025-09-05T12:28:12.3261158Z configfile: pyproject.toml
2025-09-05T12:28:12.3261479Z plugins: mock-3.14.0, cov-6.0.0, azure-devops-0.3.0, anyio-4.10.0
2025-09-05T12:28:12.3261823Z Agent nr. 1 of 1 selected 397 of 397 tests (other filters might apply afterwards, e.g. pytest marks)
2025-09-05T12:28:12.3262127Z collected 397 items
2025-09-05T12:28:12.3262236Z 
2025-09-05T12:28:12.4995381Z test/month_setup/test_dial_snapshotdate.py ............                  [  3%]
2025-09-05T12:28:25.5384407Z test/scripts/test_check_dependencies.py ......                           [  4%]
2025-09-05T12:28:26.9889238Z test/scripts/test_dial_check_delayed_files.py .....                      [  5%]
2025-09-05T12:28:27.2385610Z test/scripts/test_dial_staging_process.py .................              [ 10%]
2025-09-05T12:28:28.9787331Z test/scripts/test_export_tine_tables.py ....                             [ 11%]
2025-09-05T12:28:29.1662034Z test/scripts/test_new_month_catalog_setup.py ...                         [ 11%]
2025-09-05T12:28:29.4676862Z test/scripts/test_nonssf_staging_process.py .................            [ 16%]
2025-09-05T12:28:30.0156435Z test/scripts/test_run_mapping.py ....................................    [ 25%]
2025-09-05T12:28:30.3626131Z test/scripts/test_ssf_staging_process.py ....................            [ 30%]
2025-09-05T12:28:30.4521379Z test/scripts/test_ssf_staging_process_xml.py ...                         [ 30%]
2025-09-05T12:28:42.8679750Z test/staging/test_extract_dial_data.py .                                 [ 31%]
2025-09-05T12:28:56.5427753Z test/staging/test_extract_non_ssf_data.py ....                           [ 32%]
2025-09-05T12:29:13.4740427Z test/staging/test_extract_ssf_data.py ..........                         [ 34%]
2025-09-05T12:29:15.3264097Z test/test_dq/test_dq_validation.py FF.FFFFFFFFFFF.FFFF.FFF.FF.FFF.FFFF   [ 43%]
2025-09-05T12:29:31.0633654Z test/test_extract/test_get_master_data.py ..............                 [ 47%]
2025-09-05T12:29:33.3615492Z test/test_transform/test_all_columns.py ....                             [ 48%]
2025-09-05T12:29:34.3606377Z test/test_transform/test_complex_types.py ...                            [ 48%]
2025-09-05T12:29:38.7158242Z test/test_transform/test_expressions.py .....                            [ 50%]
2025-09-05T12:29:40.5163291Z test/test_transform/test_pipeline_yaml_integrated_target.py F.FF         [ 51%]
2025-09-05T12:29:53.7839191Z test/test_transform/test_transform_business_logic_sql.py ..........      [ 53%]
2025-09-05T12:30:03.6109160Z test/test_transform/test_validate.py ................................... [ 62%]
2025-09-05T12:30:07.5452963Z .......................                                                  [ 68%]
2025-09-05T12:30:07.8944763Z test/test_transform/test_write_and_comment.py .......................... [ 74%]
2025-09-05T12:30:07.9459753Z ..                                                                       [ 75%]
2025-09-05T12:30:07.9551913Z test/test_utils/test_azure_utils.py .                                    [ 75%]
2025-09-05T12:30:08.7183225Z test/test_utils/test_export_parquet.py ..                                [ 76%]
2025-09-05T12:30:08.7585881Z test/test_utils/test_get_catalog.py .....                                [ 77%]
2025-09-05T12:30:08.8459389Z test/test_utils/test_metadata_log_tables.py ...                          [ 78%]
2025-09-05T12:30:09.0516480Z test/test_utils/test_parameter_utils.py ................................ [ 86%]
2025-09-05T12:30:09.1157866Z ...........                                                              [ 88%]
2025-09-05T12:30:09.1510281Z test/test_utils/test_parse_yaml.py F                                     [ 89%]
2025-09-05T12:30:09.2275517Z test/test_utils/test_process_logging.py ........                         [ 91%]
2025-09-05T12:30:09.2593935Z test/test_utils/test_sources_util.py ......                              [ 92%]
2025-09-05T12:30:09.2935922Z test/test_utils/test_table_schema.py F                                   [ 92%]
2025-09-05T12:30:11.3901445Z test/test_utils/test_xml_utils.py ............................           [100%]
2025-09-05T12:30:11.3901909Z 
2025-09-05T12:30:11.3902294Z =================================== FAILURES ===================================
2025-09-05T12:30:11.3902657Z _____ test_dq_validation[dq_test_happy-True-Checks completed successfully] _____
2025-09-05T12:30:11.3902792Z 
2025-09-05T12:30:11.3903094Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.3922916Z validation_output = True, reference_data = None
2025-09-05T12:30:11.3923853Z expected_logging = 'Checks completed successfully'
2025-09-05T12:30:11.3924277Z main_data = ('dq_test_happy', None)
2025-09-05T12:30:11.3924682Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a43814d0>
2025-09-05T12:30:11.3924811Z 
2025-09-05T12:30:11.3925051Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.3925314Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.3925602Z         [
2025-09-05T12:30:11.3925971Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.3926295Z             (
2025-09-05T12:30:11.3926630Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.3926988Z                 True,
2025-09-05T12:30:11.3927360Z                 "Checks completed successfully",
2025-09-05T12:30:11.3927709Z             ),
2025-09-05T12:30:11.3928088Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.3928356Z             (
2025-09-05T12:30:11.3928614Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.3928946Z                 False,
2025-09-05T12:30:11.3929248Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3929476Z             ),
2025-09-05T12:30:11.3929688Z             (
2025-09-05T12:30:11.3930019Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.3930340Z                 False,
2025-09-05T12:30:11.3930641Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3930967Z             ),
2025-09-05T12:30:11.3931319Z             (
2025-09-05T12:30:11.3931671Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.3932039Z                 False,
2025-09-05T12:30:11.3932424Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3932773Z             ),
2025-09-05T12:30:11.3933091Z             (
2025-09-05T12:30:11.3933475Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.3933704Z                 False,
2025-09-05T12:30:11.3933935Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3934154Z             ),
2025-09-05T12:30:11.3934348Z             (
2025-09-05T12:30:11.3934568Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.3934779Z                 False,
2025-09-05T12:30:11.3934996Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3935207Z             ),
2025-09-05T12:30:11.3935407Z             (
2025-09-05T12:30:11.3935622Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.3935835Z                 False,
2025-09-05T12:30:11.3936066Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3936300Z             ),
2025-09-05T12:30:11.3936506Z             (
2025-09-05T12:30:11.3936787Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.3937120Z                 False,
2025-09-05T12:30:11.3937484Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3937825Z             ),
2025-09-05T12:30:11.3938067Z             (
2025-09-05T12:30:11.3938371Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.3938758Z                 False,
2025-09-05T12:30:11.3939130Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3939563Z             ),
2025-09-05T12:30:11.3939766Z             (
2025-09-05T12:30:11.3939994Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.3940222Z                 False,
2025-09-05T12:30:11.3940453Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3940680Z             ),
2025-09-05T12:30:11.3940894Z         ],
2025-09-05T12:30:11.3941120Z         indirect=["main_data"],
2025-09-05T12:30:11.3941346Z     )
2025-09-05T12:30:11.3941566Z     def test_dq_validation(
2025-09-05T12:30:11.3941808Z         spark_session,
2025-09-05T12:30:11.3942036Z         validation_output,
2025-09-05T12:30:11.3942262Z         reference_data,
2025-09-05T12:30:11.3942486Z         expected_logging,
2025-09-05T12:30:11.3942709Z         main_data,
2025-09-05T12:30:11.3943068Z         caplog,
2025-09-05T12:30:11.3943471Z     ):
2025-09-05T12:30:11.3943843Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.3944215Z     
2025-09-05T12:30:11.3944573Z         table_name = main_data[0]
2025-09-05T12:30:11.3944911Z     
2025-09-05T12:30:11.3945266Z         dq_validation = DQValidation(
2025-09-05T12:30:11.3945696Z             spark_session,
2025-09-05T12:30:11.3946032Z             table_name,
2025-09-05T12:30:11.3946334Z             schema_name="dq",
2025-09-05T12:30:11.3946623Z             run_month="",
2025-09-05T12:30:11.3946867Z             dq_check_folder="test/data",
2025-09-05T12:30:11.3947085Z             local=True,
2025-09-05T12:30:11.3947283Z         )
2025-09-05T12:30:11.3947480Z     
2025-09-05T12:30:11.3947719Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.3947976Z E       assert None == True
2025-09-05T12:30:11.3948219Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.3948507Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a4380590>.checks
2025-09-05T12:30:11.3948638Z 
2025-09-05T12:30:11.3948892Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.3949171Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.3949506Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.3949893Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.3950221Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.3950497Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.3950768Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.3951046Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.3951317Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.3951595Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.3951882Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.3952158Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.3952559Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.3953024Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.3953567Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.3954002Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.3954414Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.3954994Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.3955489Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.3955787Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.3956085Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.3956402Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.3956703Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.3957007Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.3957300Z _ test_dq_validation[dq_test_happy_col_num-True-Checks completed successfully] _
2025-09-05T12:30:11.3957413Z 
2025-09-05T12:30:11.3957654Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.3957976Z validation_output = True, reference_data = None
2025-09-05T12:30:11.3958237Z expected_logging = 'Checks completed successfully'
2025-09-05T12:30:11.3958488Z main_data = ('dq_test_happy_col_num', None)
2025-09-05T12:30:11.3958749Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a43e3190>
2025-09-05T12:30:11.3958877Z 
2025-09-05T12:30:11.3959206Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.3959598Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.3959963Z         [
2025-09-05T12:30:11.3960345Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.3960697Z             (
2025-09-05T12:30:11.3961046Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.3961375Z                 True,
2025-09-05T12:30:11.3961602Z                 "Checks completed successfully",
2025-09-05T12:30:11.3961824Z             ),
2025-09-05T12:30:11.3962058Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.3962284Z             (
2025-09-05T12:30:11.3962504Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.3962730Z                 False,
2025-09-05T12:30:11.3962959Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3963173Z             ),
2025-09-05T12:30:11.3963562Z             (
2025-09-05T12:30:11.3963806Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.3964027Z                 False,
2025-09-05T12:30:11.3964255Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3964472Z             ),
2025-09-05T12:30:11.3964687Z             (
2025-09-05T12:30:11.3964907Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.3965128Z                 False,
2025-09-05T12:30:11.3965356Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3965572Z             ),
2025-09-05T12:30:11.3965769Z             (
2025-09-05T12:30:11.3965990Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.3966214Z                 False,
2025-09-05T12:30:11.3966447Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3966665Z             ),
2025-09-05T12:30:11.3966869Z             (
2025-09-05T12:30:11.3967089Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.3967315Z                 False,
2025-09-05T12:30:11.3967545Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3967759Z             ),
2025-09-05T12:30:11.3968006Z             (
2025-09-05T12:30:11.3968354Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.3968701Z                 False,
2025-09-05T12:30:11.3969060Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3969428Z             ),
2025-09-05T12:30:11.3969745Z             (
2025-09-05T12:30:11.3970098Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.3970403Z                 False,
2025-09-05T12:30:11.3970631Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3970857Z             ),
2025-09-05T12:30:11.3971054Z             (
2025-09-05T12:30:11.3971273Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.3971495Z                 False,
2025-09-05T12:30:11.3971857Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3972075Z             ),
2025-09-05T12:30:11.3972273Z             (
2025-09-05T12:30:11.3972497Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.3972725Z                 False,
2025-09-05T12:30:11.3972950Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3973166Z             ),
2025-09-05T12:30:11.3973482Z         ],
2025-09-05T12:30:11.3973715Z         indirect=["main_data"],
2025-09-05T12:30:11.3973928Z     )
2025-09-05T12:30:11.3974147Z     def test_dq_validation(
2025-09-05T12:30:11.3974372Z         spark_session,
2025-09-05T12:30:11.3974606Z         validation_output,
2025-09-05T12:30:11.3974832Z         reference_data,
2025-09-05T12:30:11.3975055Z         expected_logging,
2025-09-05T12:30:11.3975325Z         main_data,
2025-09-05T12:30:11.3975621Z         caplog,
2025-09-05T12:30:11.3975933Z     ):
2025-09-05T12:30:11.3976291Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.3976660Z     
2025-09-05T12:30:11.3977026Z         table_name = main_data[0]
2025-09-05T12:30:11.3977366Z     
2025-09-05T12:30:11.3977712Z         dq_validation = DQValidation(
2025-09-05T12:30:11.3978062Z             spark_session,
2025-09-05T12:30:11.3978303Z             table_name,
2025-09-05T12:30:11.3978529Z             schema_name="dq",
2025-09-05T12:30:11.3978753Z             run_month="",
2025-09-05T12:30:11.3978986Z             dq_check_folder="test/data",
2025-09-05T12:30:11.3979221Z             local=True,
2025-09-05T12:30:11.3979424Z         )
2025-09-05T12:30:11.3979621Z     
2025-09-05T12:30:11.3979868Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.3980136Z E       assert None == True
2025-09-05T12:30:11.3980378Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.3980660Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a43e0090>.checks
2025-09-05T12:30:11.3980791Z 
2025-09-05T12:30:11.3981030Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.3981318Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.3982086Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_happy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy_col_num.yml
2025-09-05T12:30:11.3982483Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_happy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy_col_num.yml
2025-09-05T12:30:11.3982824Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.3983104Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.3983470Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.3983755Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.3984027Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.3984298Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.3984616Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.3985038Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.3985486Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.3985956Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.3986421Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.3986836Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.3987196Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.3987551Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_happy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy_col_num.yml
2025-09-05T12:30:11.3988036Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.3988325Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.3988621Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.3988930Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.3989229Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.3989526Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.3989817Z _ test_dq_validation[dq_test_unhappy_col_num-False-Checks completed - DQ issues found] _
2025-09-05T12:30:11.3990006Z 
2025-09-05T12:30:11.3990256Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.3990528Z validation_output = False, reference_data = None
2025-09-05T12:30:11.3990782Z expected_logging = 'Checks completed - DQ issues found'
2025-09-05T12:30:11.3991054Z main_data = ('dq_test_unhappy_col_num', None)
2025-09-05T12:30:11.3991322Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a43d1350>
2025-09-05T12:30:11.3991432Z 
2025-09-05T12:30:11.3991659Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.3991922Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.3992151Z         [
2025-09-05T12:30:11.3992421Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.3992772Z             (
2025-09-05T12:30:11.3993121Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.3993547Z                 True,
2025-09-05T12:30:11.3993949Z                 "Checks completed successfully",
2025-09-05T12:30:11.3994260Z             ),
2025-09-05T12:30:11.3994610Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.3994921Z             (
2025-09-05T12:30:11.3995235Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.3995577Z                 False,
2025-09-05T12:30:11.3995961Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3996285Z             ),
2025-09-05T12:30:11.3996581Z             (
2025-09-05T12:30:11.3996916Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.3997297Z                 False,
2025-09-05T12:30:11.3997680Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3998039Z             ),
2025-09-05T12:30:11.3998355Z             (
2025-09-05T12:30:11.3998717Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.3999085Z                 False,
2025-09-05T12:30:11.3999463Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.3999831Z             ),
2025-09-05T12:30:11.4000166Z             (
2025-09-05T12:30:11.4000525Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4000879Z                 False,
2025-09-05T12:30:11.4001255Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4001676Z             ),
2025-09-05T12:30:11.4002015Z             (
2025-09-05T12:30:11.4002396Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4002761Z                 False,
2025-09-05T12:30:11.4003148Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4003613Z             ),
2025-09-05T12:30:11.4003953Z             (
2025-09-05T12:30:11.4004331Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4004738Z                 False,
2025-09-05T12:30:11.4005132Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4005522Z             ),
2025-09-05T12:30:11.4005850Z             (
2025-09-05T12:30:11.4006226Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4006605Z                 False,
2025-09-05T12:30:11.4007000Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4007349Z             ),
2025-09-05T12:30:11.4007856Z             (
2025-09-05T12:30:11.4008220Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4008584Z                 False,
2025-09-05T12:30:11.4008981Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4009370Z             ),
2025-09-05T12:30:11.4009695Z             (
2025-09-05T12:30:11.4010049Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4010414Z                 False,
2025-09-05T12:30:11.4010762Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4011133Z             ),
2025-09-05T12:30:11.4011477Z         ],
2025-09-05T12:30:11.4011822Z         indirect=["main_data"],
2025-09-05T12:30:11.4012174Z     )
2025-09-05T12:30:11.4012531Z     def test_dq_validation(
2025-09-05T12:30:11.4012922Z         spark_session,
2025-09-05T12:30:11.4013312Z         validation_output,
2025-09-05T12:30:11.4013971Z         reference_data,
2025-09-05T12:30:11.4014359Z         expected_logging,
2025-09-05T12:30:11.4014731Z         main_data,
2025-09-05T12:30:11.4015098Z         caplog,
2025-09-05T12:30:11.4015431Z     ):
2025-09-05T12:30:11.4015820Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4016199Z     
2025-09-05T12:30:11.4016570Z         table_name = main_data[0]
2025-09-05T12:30:11.4016875Z     
2025-09-05T12:30:11.4017229Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4017611Z             spark_session,
2025-09-05T12:30:11.4017967Z             table_name,
2025-09-05T12:30:11.4018347Z             schema_name="dq",
2025-09-05T12:30:11.4018738Z             run_month="",
2025-09-05T12:30:11.4019113Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4019503Z             local=True,
2025-09-05T12:30:11.4019854Z         )
2025-09-05T12:30:11.4020199Z     
2025-09-05T12:30:11.4020626Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.4021078Z E       assert None == False
2025-09-05T12:30:11.4021487Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4021969Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a43d0d10>.checks
2025-09-05T12:30:11.4022172Z 
2025-09-05T12:30:11.4022530Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.4022986Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4023652Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_col_num.yml
2025-09-05T12:30:11.4024297Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_col_num.yml
2025-09-05T12:30:11.4024722Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4025155Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4025586Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4026006Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4026483Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4026971Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4027436Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4027819Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4028277Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4028582Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4028977Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.4029358Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.4029809Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4030566Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_col_num.yml
2025-09-05T12:30:11.4031188Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4031693Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4032025Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4032324Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4032706Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4033210Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4033777Z _ test_dq_validation[dq_test_unhappy_pk_dup-False-Checks completed - DQ issues found] _
2025-09-05T12:30:11.4033902Z 
2025-09-05T12:30:11.4034168Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4034447Z validation_output = False, reference_data = None
2025-09-05T12:30:11.4034713Z expected_logging = 'Checks completed - DQ issues found'
2025-09-05T12:30:11.4034984Z main_data = ('dq_test_unhappy_pk_dup', None)
2025-09-05T12:30:11.4035272Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a4406b50>
2025-09-05T12:30:11.4035387Z 
2025-09-05T12:30:11.4035604Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4035852Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4036084Z         [
2025-09-05T12:30:11.4036323Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.4036548Z             (
2025-09-05T12:30:11.4036770Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4036995Z                 True,
2025-09-05T12:30:11.4037226Z                 "Checks completed successfully",
2025-09-05T12:30:11.4037442Z             ),
2025-09-05T12:30:11.4037690Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.4038027Z             (
2025-09-05T12:30:11.4038349Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4038692Z                 False,
2025-09-05T12:30:11.4039038Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4039374Z             ),
2025-09-05T12:30:11.4039680Z             (
2025-09-05T12:30:11.4040025Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4040366Z                 False,
2025-09-05T12:30:11.4040606Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4040824Z             ),
2025-09-05T12:30:11.4041029Z             (
2025-09-05T12:30:11.4041249Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4041482Z                 False,
2025-09-05T12:30:11.4041714Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4041931Z             ),
2025-09-05T12:30:11.4042137Z             (
2025-09-05T12:30:11.4042370Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4042591Z                 False,
2025-09-05T12:30:11.4042821Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4043041Z             ),
2025-09-05T12:30:11.4043247Z             (
2025-09-05T12:30:11.4043665Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4043895Z                 False,
2025-09-05T12:30:11.4044129Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4044382Z             ),
2025-09-05T12:30:11.4044682Z             (
2025-09-05T12:30:11.4044923Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4045220Z                 False,
2025-09-05T12:30:11.4045571Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4045867Z             ),
2025-09-05T12:30:11.4046137Z             (
2025-09-05T12:30:11.4046471Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4046793Z                 False,
2025-09-05T12:30:11.4047259Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4047560Z             ),
2025-09-05T12:30:11.4047857Z             (
2025-09-05T12:30:11.4048219Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4048541Z                 False,
2025-09-05T12:30:11.4048863Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4049161Z             ),
2025-09-05T12:30:11.4049437Z             (
2025-09-05T12:30:11.4049744Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4050063Z                 False,
2025-09-05T12:30:11.4050370Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4050697Z             ),
2025-09-05T12:30:11.4051002Z         ],
2025-09-05T12:30:11.4051330Z         indirect=["main_data"],
2025-09-05T12:30:11.4051671Z     )
2025-09-05T12:30:11.4052147Z     def test_dq_validation(
2025-09-05T12:30:11.4052486Z         spark_session,
2025-09-05T12:30:11.4052810Z         validation_output,
2025-09-05T12:30:11.4053157Z         reference_data,
2025-09-05T12:30:11.4053644Z         expected_logging,
2025-09-05T12:30:11.4053981Z         main_data,
2025-09-05T12:30:11.4054326Z         caplog,
2025-09-05T12:30:11.4054604Z     ):
2025-09-05T12:30:11.4054851Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4055081Z     
2025-09-05T12:30:11.4055299Z         table_name = main_data[0]
2025-09-05T12:30:11.4055511Z     
2025-09-05T12:30:11.4055731Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4055972Z             spark_session,
2025-09-05T12:30:11.4056189Z             table_name,
2025-09-05T12:30:11.4056409Z             schema_name="dq",
2025-09-05T12:30:11.4056644Z             run_month="",
2025-09-05T12:30:11.4056885Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4057113Z             local=True,
2025-09-05T12:30:11.4057319Z         )
2025-09-05T12:30:11.4057521Z     
2025-09-05T12:30:11.4057770Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.4058023Z E       assert None == False
2025-09-05T12:30:11.4058269Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4058545Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a4405750>.checks
2025-09-05T12:30:11.4058684Z 
2025-09-05T12:30:11.4058925Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.4059204Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4059543Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_pk_dup at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_dup.yml
2025-09-05T12:30:11.4059941Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_pk_dup at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_dup.yml
2025-09-05T12:30:11.4060280Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4060551Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4060821Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4061086Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4061355Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4061624Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4061900Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4062166Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4062443Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4062744Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4063017Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.4063876Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.4064160Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4064523Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_pk_dup at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_dup.yml
2025-09-05T12:30:11.4064881Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4065179Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4065488Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4065798Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4066092Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4066451Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4066749Z _ test_dq_validation[dq_test_unhappy_pk_null-False-Checks completed - DQ issues found] _
2025-09-05T12:30:11.4066873Z 
2025-09-05T12:30:11.4067120Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4067389Z validation_output = False, reference_data = None
2025-09-05T12:30:11.4067652Z expected_logging = 'Checks completed - DQ issues found'
2025-09-05T12:30:11.4067908Z main_data = ('dq_test_unhappy_pk_null', None)
2025-09-05T12:30:11.4068180Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a4407210>
2025-09-05T12:30:11.4068291Z 
2025-09-05T12:30:11.4068526Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4068774Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4068993Z         [
2025-09-05T12:30:11.4069231Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.4069464Z             (
2025-09-05T12:30:11.4069682Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4069904Z                 True,
2025-09-05T12:30:11.4070133Z                 "Checks completed successfully",
2025-09-05T12:30:11.4070359Z             ),
2025-09-05T12:30:11.4070595Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.4070817Z             (
2025-09-05T12:30:11.4071035Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4071263Z                 False,
2025-09-05T12:30:11.4071491Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4071710Z             ),
2025-09-05T12:30:11.4071915Z             (
2025-09-05T12:30:11.4072138Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4072357Z                 False,
2025-09-05T12:30:11.4072582Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4072799Z             ),
2025-09-05T12:30:11.4073011Z             (
2025-09-05T12:30:11.4073232Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4073598Z                 False,
2025-09-05T12:30:11.4073833Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4074062Z             ),
2025-09-05T12:30:11.4074266Z             (
2025-09-05T12:30:11.4074491Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4074717Z                 False,
2025-09-05T12:30:11.4074954Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4075172Z             ),
2025-09-05T12:30:11.4075374Z             (
2025-09-05T12:30:11.4075594Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4075823Z                 False,
2025-09-05T12:30:11.4076048Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4076265Z             ),
2025-09-05T12:30:11.4076464Z             (
2025-09-05T12:30:11.4076699Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4076927Z                 False,
2025-09-05T12:30:11.4077154Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4077371Z             ),
2025-09-05T12:30:11.4077682Z             (
2025-09-05T12:30:11.4077918Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4078142Z                 False,
2025-09-05T12:30:11.4078380Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4078608Z             ),
2025-09-05T12:30:11.4078810Z             (
2025-09-05T12:30:11.4079030Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4079258Z                 False,
2025-09-05T12:30:11.4079490Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4079704Z             ),
2025-09-05T12:30:11.4079899Z             (
2025-09-05T12:30:11.4080121Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4080348Z                 False,
2025-09-05T12:30:11.4080572Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4080787Z             ),
2025-09-05T12:30:11.4081031Z         ],
2025-09-05T12:30:11.4081252Z         indirect=["main_data"],
2025-09-05T12:30:11.4081459Z     )
2025-09-05T12:30:11.4081678Z     def test_dq_validation(
2025-09-05T12:30:11.4081900Z         spark_session,
2025-09-05T12:30:11.4082133Z         validation_output,
2025-09-05T12:30:11.4082361Z         reference_data,
2025-09-05T12:30:11.4082590Z         expected_logging,
2025-09-05T12:30:11.4082812Z         main_data,
2025-09-05T12:30:11.4083037Z         caplog,
2025-09-05T12:30:11.4083241Z     ):
2025-09-05T12:30:11.4083637Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4083894Z     
2025-09-05T12:30:11.4084117Z         table_name = main_data[0]
2025-09-05T12:30:11.4084342Z     
2025-09-05T12:30:11.4084566Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4084808Z             spark_session,
2025-09-05T12:30:11.4085035Z             table_name,
2025-09-05T12:30:11.4085273Z             schema_name="dq",
2025-09-05T12:30:11.4085504Z             run_month="",
2025-09-05T12:30:11.4085735Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4085960Z             local=True,
2025-09-05T12:30:11.4086179Z         )
2025-09-05T12:30:11.4086377Z     
2025-09-05T12:30:11.4086626Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.4086879Z E       assert None == False
2025-09-05T12:30:11.4087131Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4087419Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a4407610>.checks
2025-09-05T12:30:11.4087613Z 
2025-09-05T12:30:11.4087880Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.4088164Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4088513Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_pk_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_null.yml
2025-09-05T12:30:11.4088909Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_pk_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_null.yml
2025-09-05T12:30:11.4089257Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4089534Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4089801Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4090069Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4090344Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4090616Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4090889Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4091160Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4091442Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4091728Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4092080Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.4092350Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.4092620Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4092979Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_pk_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_null.yml
2025-09-05T12:30:11.4093348Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4093795Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4094093Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4094445Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4094750Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4095042Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4095332Z _ test_dq_validation[dq_test_unhappy_not_null-False-Checks completed - DQ issues found] _
2025-09-05T12:30:11.4095451Z 
2025-09-05T12:30:11.4095712Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4095986Z validation_output = False, reference_data = None
2025-09-05T12:30:11.4096247Z expected_logging = 'Checks completed - DQ issues found'
2025-09-05T12:30:11.4096516Z main_data = ('dq_test_unhappy_not_null', None)
2025-09-05T12:30:11.4096782Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a427b610>
2025-09-05T12:30:11.4096894Z 
2025-09-05T12:30:11.4097114Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4097364Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4097610Z         [
2025-09-05T12:30:11.4097851Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.4098079Z             (
2025-09-05T12:30:11.4098301Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4098525Z                 True,
2025-09-05T12:30:11.4098751Z                 "Checks completed successfully",
2025-09-05T12:30:11.4098973Z             ),
2025-09-05T12:30:11.4099205Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.4099435Z             (
2025-09-05T12:30:11.4099653Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4099875Z                 False,
2025-09-05T12:30:11.4100105Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4100333Z             ),
2025-09-05T12:30:11.4100533Z             (
2025-09-05T12:30:11.4100750Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4100968Z                 False,
2025-09-05T12:30:11.4101207Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4101422Z             ),
2025-09-05T12:30:11.4101654Z             (
2025-09-05T12:30:11.4101870Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4102094Z                 False,
2025-09-05T12:30:11.4102323Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4102539Z             ),
2025-09-05T12:30:11.4102740Z             (
2025-09-05T12:30:11.4102968Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4103192Z                 False,
2025-09-05T12:30:11.4103522Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4103755Z             ),
2025-09-05T12:30:11.4103967Z             (
2025-09-05T12:30:11.4104191Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4104414Z                 False,
2025-09-05T12:30:11.4104643Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4104869Z             ),
2025-09-05T12:30:11.4105075Z             (
2025-09-05T12:30:11.4105306Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4105532Z                 False,
2025-09-05T12:30:11.4105850Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4106070Z             ),
2025-09-05T12:30:11.4106280Z             (
2025-09-05T12:30:11.4106509Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4106750Z                 False,
2025-09-05T12:30:11.4106988Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4107215Z             ),
2025-09-05T12:30:11.4107427Z             (
2025-09-05T12:30:11.4107669Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4107893Z                 False,
2025-09-05T12:30:11.4108117Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4108331Z             ),
2025-09-05T12:30:11.4108535Z             (
2025-09-05T12:30:11.4108753Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4109011Z                 False,
2025-09-05T12:30:11.4109235Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4109453Z             ),
2025-09-05T12:30:11.4109656Z         ],
2025-09-05T12:30:11.4109877Z         indirect=["main_data"],
2025-09-05T12:30:11.4110087Z     )
2025-09-05T12:30:11.4110313Z     def test_dq_validation(
2025-09-05T12:30:11.4110534Z         spark_session,
2025-09-05T12:30:11.4110755Z         validation_output,
2025-09-05T12:30:11.4110976Z         reference_data,
2025-09-05T12:30:11.4111202Z         expected_logging,
2025-09-05T12:30:11.4111420Z         main_data,
2025-09-05T12:30:11.4111634Z         caplog,
2025-09-05T12:30:11.4111839Z     ):
2025-09-05T12:30:11.4112074Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4112287Z     
2025-09-05T12:30:11.4112505Z         table_name = main_data[0]
2025-09-05T12:30:11.4112718Z     
2025-09-05T12:30:11.4112944Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4113173Z             spark_session,
2025-09-05T12:30:11.4113482Z             table_name,
2025-09-05T12:30:11.4113785Z             schema_name="dq",
2025-09-05T12:30:11.4114019Z             run_month="",
2025-09-05T12:30:11.4114253Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4114479Z             local=True,
2025-09-05T12:30:11.4114687Z         )
2025-09-05T12:30:11.4114898Z     
2025-09-05T12:30:11.4115149Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.4115415Z E       assert None == False
2025-09-05T12:30:11.4115675Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4115959Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a4404c50>.checks
2025-09-05T12:30:11.4116085Z 
2025-09-05T12:30:11.4116325Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.4116602Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4116954Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_not_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_not_null.yml
2025-09-05T12:30:11.4117366Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_not_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_not_null.yml
2025-09-05T12:30:11.4117702Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4117978Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4118245Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4118510Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4118779Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4119062Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4119334Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4119604Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4119888Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4120273Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4120552Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.4120812Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.4121098Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4121457Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_not_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_not_null.yml
2025-09-05T12:30:11.4121822Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4122126Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4122456Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4122755Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4123053Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4123351Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4123817Z _ test_dq_validation[dq_test_unhappy_num_cols-False-Checks completed - DQ issues found] _
2025-09-05T12:30:11.4123944Z 
2025-09-05T12:30:11.4124195Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4124477Z validation_output = False, reference_data = None
2025-09-05T12:30:11.4124734Z expected_logging = 'Checks completed - DQ issues found'
2025-09-05T12:30:11.4124999Z main_data = ('dq_test_unhappy_num_cols', None)
2025-09-05T12:30:11.4125270Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a434c990>
2025-09-05T12:30:11.4125395Z 
2025-09-05T12:30:11.4125616Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4125867Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4126091Z         [
2025-09-05T12:30:11.4126338Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.4126569Z             (
2025-09-05T12:30:11.4126794Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4127018Z                 True,
2025-09-05T12:30:11.4127254Z                 "Checks completed successfully",
2025-09-05T12:30:11.4127472Z             ),
2025-09-05T12:30:11.4127706Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.4127928Z             (
2025-09-05T12:30:11.4128157Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4128375Z                 False,
2025-09-05T12:30:11.4128598Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4128811Z             ),
2025-09-05T12:30:11.4129022Z             (
2025-09-05T12:30:11.4129240Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4129456Z                 False,
2025-09-05T12:30:11.4129682Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4129901Z             ),
2025-09-05T12:30:11.4130096Z             (
2025-09-05T12:30:11.4130314Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4130536Z                 False,
2025-09-05T12:30:11.4130770Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4130984Z             ),
2025-09-05T12:30:11.4131185Z             (
2025-09-05T12:30:11.4131401Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4131655Z                 False,
2025-09-05T12:30:11.4131958Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4132291Z             ),
2025-09-05T12:30:11.4132494Z             (
2025-09-05T12:30:11.4132723Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4132948Z                 False,
2025-09-05T12:30:11.4133178Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4133549Z             ),
2025-09-05T12:30:11.4133938Z             (
2025-09-05T12:30:11.4134165Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4134389Z                 False,
2025-09-05T12:30:11.4134622Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4134852Z             ),
2025-09-05T12:30:11.4135057Z             (
2025-09-05T12:30:11.4135285Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4135505Z                 False,
2025-09-05T12:30:11.4135744Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4135957Z             ),
2025-09-05T12:30:11.4136167Z             (
2025-09-05T12:30:11.4136389Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4136619Z                 False,
2025-09-05T12:30:11.4136844Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4137120Z             ),
2025-09-05T12:30:11.4137327Z             (
2025-09-05T12:30:11.4137557Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4137771Z                 False,
2025-09-05T12:30:11.4137997Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4138210Z             ),
2025-09-05T12:30:11.4138419Z         ],
2025-09-05T12:30:11.4138642Z         indirect=["main_data"],
2025-09-05T12:30:11.4138848Z     )
2025-09-05T12:30:11.4139065Z     def test_dq_validation(
2025-09-05T12:30:11.4139287Z         spark_session,
2025-09-05T12:30:11.4139513Z         validation_output,
2025-09-05T12:30:11.4139737Z         reference_data,
2025-09-05T12:30:11.4139958Z         expected_logging,
2025-09-05T12:30:11.4140172Z         main_data,
2025-09-05T12:30:11.4140391Z         caplog,
2025-09-05T12:30:11.4140597Z     ):
2025-09-05T12:30:11.4140833Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4141051Z     
2025-09-05T12:30:11.4141274Z         table_name = main_data[0]
2025-09-05T12:30:11.4141492Z     
2025-09-05T12:30:11.4141707Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4141947Z             spark_session,
2025-09-05T12:30:11.4142180Z             table_name,
2025-09-05T12:30:11.4142402Z             schema_name="dq",
2025-09-05T12:30:11.4142630Z             run_month="",
2025-09-05T12:30:11.4142861Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4143097Z             local=True,
2025-09-05T12:30:11.4143299Z         )
2025-09-05T12:30:11.4143662Z     
2025-09-05T12:30:11.4143912Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.4144180Z E       assert None == False
2025-09-05T12:30:11.4144424Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4144712Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a434f3d0>.checks
2025-09-05T12:30:11.4144842Z 
2025-09-05T12:30:11.4145107Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.4145388Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4145732Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_num_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_num_cols.yml
2025-09-05T12:30:11.4146301Z 2025-09-05 12:29:13 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_num_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_num_cols.yml
2025-09-05T12:30:11.4146650Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4146922Z 2025-09-05 12:29:13 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4147189Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4147458Z 2025-09-05 12:29:13 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4147726Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4147996Z 2025-09-05 12:29:13 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4148273Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4148626Z 2025-09-05 12:29:13 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4148912Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4149201Z 2025-09-05 12:29:13 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4149482Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.4149748Z 2025-09-05 12:29:13 [INFO] checks:  No checks done
2025-09-05T12:30:11.4150020Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4150376Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_num_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_num_cols.yml
2025-09-05T12:30:11.4150785Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4151073Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4151368Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4151676Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4151973Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4152266Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4152574Z _ test_dq_validation[dq_test_unhappy_type_cols-False-Checks completed - DQ issues found] _
2025-09-05T12:30:11.4152696Z 
2025-09-05T12:30:11.4152945Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4153212Z validation_output = False, reference_data = None
2025-09-05T12:30:11.4153556Z expected_logging = 'Checks completed - DQ issues found'
2025-09-05T12:30:11.4153858Z main_data = ('dq_test_unhappy_type_cols', None)
2025-09-05T12:30:11.4154131Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a434c890>
2025-09-05T12:30:11.4154251Z 
2025-09-05T12:30:11.4154475Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4154743Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4154972Z         [
2025-09-05T12:30:11.4155221Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.4155446Z             (
2025-09-05T12:30:11.4155679Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4155899Z                 True,
2025-09-05T12:30:11.4156130Z                 "Checks completed successfully",
2025-09-05T12:30:11.4156347Z             ),
2025-09-05T12:30:11.4156588Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.4156812Z             (
2025-09-05T12:30:11.4157033Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4157255Z                 False,
2025-09-05T12:30:11.4157491Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4157705Z             ),
2025-09-05T12:30:11.4157906Z             (
2025-09-05T12:30:11.4158130Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4158366Z                 False,
2025-09-05T12:30:11.4158594Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4158808Z             ),
2025-09-05T12:30:11.4159005Z             (
2025-09-05T12:30:11.4159232Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4159449Z                 False,
2025-09-05T12:30:11.4159677Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4159891Z             ),
2025-09-05T12:30:11.4160098Z             (
2025-09-05T12:30:11.4160315Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4160534Z                 False,
2025-09-05T12:30:11.4160761Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4160988Z             ),
2025-09-05T12:30:11.4161190Z             (
2025-09-05T12:30:11.4161412Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4161633Z                 False,
2025-09-05T12:30:11.4162008Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4162227Z             ),
2025-09-05T12:30:11.4162433Z             (
2025-09-05T12:30:11.4162661Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4162898Z                 False,
2025-09-05T12:30:11.4163128Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4163349Z             ),
2025-09-05T12:30:11.4163778Z             (
2025-09-05T12:30:11.4164013Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4164237Z                 False,
2025-09-05T12:30:11.4164464Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4164682Z             ),
2025-09-05T12:30:11.4164899Z             (
2025-09-05T12:30:11.4165120Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4165403Z                 False,
2025-09-05T12:30:11.4165632Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4165862Z             ),
2025-09-05T12:30:11.4166061Z             (
2025-09-05T12:30:11.4166282Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4166501Z                 False,
2025-09-05T12:30:11.4166744Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4166960Z             ),
2025-09-05T12:30:11.4167159Z         ],
2025-09-05T12:30:11.4167375Z         indirect=["main_data"],
2025-09-05T12:30:11.4167589Z     )
2025-09-05T12:30:11.4167807Z     def test_dq_validation(
2025-09-05T12:30:11.4168033Z         spark_session,
2025-09-05T12:30:11.4168252Z         validation_output,
2025-09-05T12:30:11.4168477Z         reference_data,
2025-09-05T12:30:11.4168697Z         expected_logging,
2025-09-05T12:30:11.4168916Z         main_data,
2025-09-05T12:30:11.4169125Z         caplog,
2025-09-05T12:30:11.4169330Z     ):
2025-09-05T12:30:11.4169557Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4169768Z     
2025-09-05T12:30:11.4169986Z         table_name = main_data[0]
2025-09-05T12:30:11.4170202Z     
2025-09-05T12:30:11.4170422Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4170646Z             spark_session,
2025-09-05T12:30:11.4170865Z             table_name,
2025-09-05T12:30:11.4171084Z             schema_name="dq",
2025-09-05T12:30:11.4171309Z             run_month="",
2025-09-05T12:30:11.4171542Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4171766Z             local=True,
2025-09-05T12:30:11.4171970Z         )
2025-09-05T12:30:11.4172178Z     
2025-09-05T12:30:11.4172417Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.4172669Z E       assert None == False
2025-09-05T12:30:11.4172915Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4173199Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a434c0d0>.checks
2025-09-05T12:30:11.4173329Z 
2025-09-05T12:30:11.4173861Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.4174145Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4174503Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_type_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_type_cols.yml
2025-09-05T12:30:11.4174909Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_type_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_type_cols.yml
2025-09-05T12:30:11.4175271Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4175762Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4176256Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4176611Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4176960Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4177412Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4177961Z 2025-09-05 12:29:14 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4178477Z 2025-09-05 12:29:14 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4178975Z 2025-09-05 12:29:14 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4179500Z 2025-09-05 12:29:14 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4180033Z 2025-09-05 12:29:14 [INFO] checks:  No checks done
2025-09-05T12:30:11.4180525Z 2025-09-05 12:29:14 [INFO] checks:  No checks done
2025-09-05T12:30:11.4181044Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4181779Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_type_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_type_cols.yml
2025-09-05T12:30:11.4182535Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4183104Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4183814Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4184397Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4184978Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4185596Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4186217Z _ test_dq_validation[dq_test_unhappy_ref-False-Checks completed - DQ issues found] _
2025-09-05T12:30:11.4186456Z 
2025-09-05T12:30:11.4209831Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4210537Z validation_output = False, reference_data = None
2025-09-05T12:30:11.4210990Z expected_logging = 'Checks completed - DQ issues found'
2025-09-05T12:30:11.4211442Z main_data = ('dq_test_unhappy_ref', None)
2025-09-05T12:30:11.4211756Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a428c610>
2025-09-05T12:30:11.4211871Z 
2025-09-05T12:30:11.4212107Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4212366Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4212595Z         [
2025-09-05T12:30:11.4212835Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.4213079Z             (
2025-09-05T12:30:11.4213304Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4213672Z                 True,
2025-09-05T12:30:11.4213903Z                 "Checks completed successfully",
2025-09-05T12:30:11.4214129Z             ),
2025-09-05T12:30:11.4214373Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.4214610Z             (
2025-09-05T12:30:11.4214843Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4215091Z                 False,
2025-09-05T12:30:11.4215338Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4215561Z             ),
2025-09-05T12:30:11.4215766Z             (
2025-09-05T12:30:11.4215999Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4216225Z                 False,
2025-09-05T12:30:11.4216457Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4216683Z             ),
2025-09-05T12:30:11.4216904Z             (
2025-09-05T12:30:11.4217140Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4217364Z                 False,
2025-09-05T12:30:11.4217599Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4217833Z             ),
2025-09-05T12:30:11.4218043Z             (
2025-09-05T12:30:11.4218271Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4218503Z                 False,
2025-09-05T12:30:11.4218744Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4218966Z             ),
2025-09-05T12:30:11.4219402Z             (
2025-09-05T12:30:11.4219629Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4219867Z                 False,
2025-09-05T12:30:11.4220119Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4220347Z             ),
2025-09-05T12:30:11.4220554Z             (
2025-09-05T12:30:11.4220788Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4221015Z                 False,
2025-09-05T12:30:11.4221251Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4221469Z             ),
2025-09-05T12:30:11.4221688Z             (
2025-09-05T12:30:11.4221910Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4222143Z                 False,
2025-09-05T12:30:11.4222369Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4222665Z             ),
2025-09-05T12:30:11.4222870Z             (
2025-09-05T12:30:11.4223095Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4223334Z                 False,
2025-09-05T12:30:11.4223703Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4223924Z             ),
2025-09-05T12:30:11.4224132Z             (
2025-09-05T12:30:11.4224357Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4224600Z                 False,
2025-09-05T12:30:11.4224839Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4225061Z             ),
2025-09-05T12:30:11.4225289Z         ],
2025-09-05T12:30:11.4225515Z         indirect=["main_data"],
2025-09-05T12:30:11.4225729Z     )
2025-09-05T12:30:11.4225946Z     def test_dq_validation(
2025-09-05T12:30:11.4226177Z         spark_session,
2025-09-05T12:30:11.4226396Z         validation_output,
2025-09-05T12:30:11.4226617Z         reference_data,
2025-09-05T12:30:11.4226838Z         expected_logging,
2025-09-05T12:30:11.4227067Z         main_data,
2025-09-05T12:30:11.4227278Z         caplog,
2025-09-05T12:30:11.4227478Z     ):
2025-09-05T12:30:11.4227713Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4227937Z     
2025-09-05T12:30:11.4228152Z         table_name = main_data[0]
2025-09-05T12:30:11.4228365Z     
2025-09-05T12:30:11.4228586Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4228819Z             spark_session,
2025-09-05T12:30:11.4229037Z             table_name,
2025-09-05T12:30:11.4229255Z             schema_name="dq",
2025-09-05T12:30:11.4229479Z             run_month="",
2025-09-05T12:30:11.4229714Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4229935Z             local=True,
2025-09-05T12:30:11.4230139Z         )
2025-09-05T12:30:11.4230337Z     
2025-09-05T12:30:11.4230586Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.4230847Z E       assert None == False
2025-09-05T12:30:11.4231087Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4231365Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a428c350>.checks
2025-09-05T12:30:11.4231504Z 
2025-09-05T12:30:11.4231750Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.4232030Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4232377Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_ref at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref.yml
2025-09-05T12:30:11.4232780Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_ref at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref.yml
2025-09-05T12:30:11.4233113Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4233481Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4233824Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4234091Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4234458Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4234735Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4235025Z 2025-09-05 12:29:14 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4235302Z 2025-09-05 12:29:14 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4235591Z 2025-09-05 12:29:14 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4235905Z 2025-09-05 12:29:14 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4236187Z 2025-09-05 12:29:14 [INFO] checks:  No checks done
2025-09-05T12:30:11.4236443Z 2025-09-05 12:29:14 [INFO] checks:  No checks done
2025-09-05T12:30:11.4236711Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4237126Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_ref at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref.yml
2025-09-05T12:30:11.4237475Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4237771Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4238079Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4238374Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4238670Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4238962Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4239259Z _ test_dq_validation[dq_test_unhappy_ref_filter-False-Checks completed - DQ issues found] _
2025-09-05T12:30:11.4239384Z 
2025-09-05T12:30:11.4239634Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4239891Z validation_output = False, reference_data = None
2025-09-05T12:30:11.4240147Z expected_logging = 'Checks completed - DQ issues found'
2025-09-05T12:30:11.4240405Z main_data = ('dq_test_unhappy_ref_filter', None)
2025-09-05T12:30:11.4240677Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a434fad0>
2025-09-05T12:30:11.4240799Z 
2025-09-05T12:30:11.4241014Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4241261Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4241481Z         [
2025-09-05T12:30:11.4241728Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.4241953Z             (
2025-09-05T12:30:11.4242172Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4242387Z                 True,
2025-09-05T12:30:11.4242623Z                 "Checks completed successfully",
2025-09-05T12:30:11.4242839Z             ),
2025-09-05T12:30:11.4243072Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.4243291Z             (
2025-09-05T12:30:11.4243706Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4243933Z                 False,
2025-09-05T12:30:11.4244165Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4244383Z             ),
2025-09-05T12:30:11.4244593Z             (
2025-09-05T12:30:11.4244816Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4245038Z                 False,
2025-09-05T12:30:11.4245268Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4245489Z             ),
2025-09-05T12:30:11.4245689Z             (
2025-09-05T12:30:11.4245909Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4246132Z                 False,
2025-09-05T12:30:11.4246373Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4246589Z             ),
2025-09-05T12:30:11.4246794Z             (
2025-09-05T12:30:11.4247018Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4247246Z                 False,
2025-09-05T12:30:11.4247557Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4247770Z             ),
2025-09-05T12:30:11.4247976Z             (
2025-09-05T12:30:11.4248209Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4248433Z                 False,
2025-09-05T12:30:11.4248665Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4248885Z             ),
2025-09-05T12:30:11.4249103Z             (
2025-09-05T12:30:11.4249331Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4249560Z                 False,
2025-09-05T12:30:11.4249798Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4250024Z             ),
2025-09-05T12:30:11.4250224Z             (
2025-09-05T12:30:11.4250444Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4250710Z                 False,
2025-09-05T12:30:11.4250949Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4251161Z             ),
2025-09-05T12:30:11.4251359Z             (
2025-09-05T12:30:11.4251581Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4251810Z                 False,
2025-09-05T12:30:11.4252039Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4252258Z             ),
2025-09-05T12:30:11.4252462Z             (
2025-09-05T12:30:11.4252683Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4252913Z                 False,
2025-09-05T12:30:11.4253140Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4253359Z             ),
2025-09-05T12:30:11.4253724Z         ],
2025-09-05T12:30:11.4253951Z         indirect=["main_data"],
2025-09-05T12:30:11.4254171Z     )
2025-09-05T12:30:11.4254393Z     def test_dq_validation(
2025-09-05T12:30:11.4254623Z         spark_session,
2025-09-05T12:30:11.4254863Z         validation_output,
2025-09-05T12:30:11.4255096Z         reference_data,
2025-09-05T12:30:11.4255322Z         expected_logging,
2025-09-05T12:30:11.4255543Z         main_data,
2025-09-05T12:30:11.4255770Z         caplog,
2025-09-05T12:30:11.4255974Z     ):
2025-09-05T12:30:11.4256208Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4256424Z     
2025-09-05T12:30:11.4256650Z         table_name = main_data[0]
2025-09-05T12:30:11.4256864Z     
2025-09-05T12:30:11.4257089Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4257316Z             spark_session,
2025-09-05T12:30:11.4257545Z             table_name,
2025-09-05T12:30:11.4257765Z             schema_name="dq",
2025-09-05T12:30:11.4257991Z             run_month="",
2025-09-05T12:30:11.4258222Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4258460Z             local=True,
2025-09-05T12:30:11.4258666Z         )
2025-09-05T12:30:11.4258868Z     
2025-09-05T12:30:11.4259114Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.4259380Z E       assert None == False
2025-09-05T12:30:11.4259624Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4259914Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a434c090>.checks
2025-09-05T12:30:11.4260045Z 
2025-09-05T12:30:11.4260297Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.4260577Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4260921Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_ref_filter at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref_filter.yml
2025-09-05T12:30:11.4261319Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_ref_filter at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref_filter.yml
2025-09-05T12:30:11.4261669Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4261942Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4262312Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4262588Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4262856Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4263132Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4263541Z 2025-09-05 12:29:14 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4263822Z 2025-09-05 12:29:14 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4264101Z 2025-09-05 12:29:14 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4264395Z 2025-09-05 12:29:14 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4264684Z 2025-09-05 12:29:14 [INFO] checks:  No checks done
2025-09-05T12:30:11.4265036Z 2025-09-05 12:29:14 [INFO] checks:  No checks done
2025-09-05T12:30:11.4265303Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4265667Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_ref_filter at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref_filter.yml
2025-09-05T12:30:11.4266033Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4266329Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4266627Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4266929Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4267228Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4267521Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4267826Z _ test_dq_validation[dq_test_unhappy_unique-False-Checks completed - DQ issues found] _
2025-09-05T12:30:11.4267949Z 
2025-09-05T12:30:11.4268195Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4268460Z validation_output = False, reference_data = None
2025-09-05T12:30:11.4268714Z expected_logging = 'Checks completed - DQ issues found'
2025-09-05T12:30:11.4268977Z main_data = ('dq_test_unhappy_unique', None)
2025-09-05T12:30:11.4269241Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a43c2f50>
2025-09-05T12:30:11.4269348Z 
2025-09-05T12:30:11.4269564Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4269825Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4270053Z         [
2025-09-05T12:30:11.4270295Z             ("dq_test_happy", True, "Checks completed successfully"),
2025-09-05T12:30:11.4270518Z             (
2025-09-05T12:30:11.4270750Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4270971Z                 True,
2025-09-05T12:30:11.4271200Z                 "Checks completed successfully",
2025-09-05T12:30:11.4271418Z             ),
2025-09-05T12:30:11.4271654Z             ("dq_test_no_checks", None, "No checks done"),
2025-09-05T12:30:11.4271875Z             (
2025-09-05T12:30:11.4272094Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4272317Z                 False,
2025-09-05T12:30:11.4272558Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4272778Z             ),
2025-09-05T12:30:11.4272975Z             (
2025-09-05T12:30:11.4273193Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4273518Z                 False,
2025-09-05T12:30:11.4273825Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4274042Z             ),
2025-09-05T12:30:11.4274239Z             (
2025-09-05T12:30:11.4274469Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4274687Z                 False,
2025-09-05T12:30:11.4274912Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4275129Z             ),
2025-09-05T12:30:11.4275411Z             (
2025-09-05T12:30:11.4275634Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4275857Z                 False,
2025-09-05T12:30:11.4276085Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4276311Z             ),
2025-09-05T12:30:11.4276517Z             (
2025-09-05T12:30:11.4276738Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4276962Z                 False,
2025-09-05T12:30:11.4277196Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4277417Z             ),
2025-09-05T12:30:11.4277618Z             (
2025-09-05T12:30:11.4277840Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4278072Z                 False,
2025-09-05T12:30:11.4278299Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4278554Z             ),
2025-09-05T12:30:11.4278758Z             (
2025-09-05T12:30:11.4279001Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4279225Z                 False,
2025-09-05T12:30:11.4279463Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4279690Z             ),
2025-09-05T12:30:11.4279913Z             (
2025-09-05T12:30:11.4280134Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4280359Z                 False,
2025-09-05T12:30:11.4280590Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4280816Z             ),
2025-09-05T12:30:11.4281017Z             (
2025-09-05T12:30:11.4281235Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4281456Z                 False,
2025-09-05T12:30:11.4281685Z                 "Checks completed - DQ issues found",
2025-09-05T12:30:11.4281895Z             ),
2025-09-05T12:30:11.4282093Z         ],
2025-09-05T12:30:11.4282313Z         indirect=["main_data"],
2025-09-05T12:30:11.4282536Z     )
2025-09-05T12:30:11.4282747Z     def test_dq_validation(
2025-09-05T12:30:11.4282970Z         spark_session,
2025-09-05T12:30:11.4283186Z         validation_output,
2025-09-05T12:30:11.4283558Z         reference_data,
2025-09-05T12:30:11.4283814Z         expected_logging,
2025-09-05T12:30:11.4284031Z         main_data,
2025-09-05T12:30:11.4284254Z         caplog,
2025-09-05T12:30:11.4284463Z     ):
2025-09-05T12:30:11.4284697Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4284917Z     
2025-09-05T12:30:11.4285139Z         table_name = main_data[0]
2025-09-05T12:30:11.4285360Z     
2025-09-05T12:30:11.4285582Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4285807Z             spark_session,
2025-09-05T12:30:11.4286029Z             table_name,
2025-09-05T12:30:11.4286248Z             schema_name="dq",
2025-09-05T12:30:11.4286480Z             run_month="",
2025-09-05T12:30:11.4286709Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4286940Z             local=True,
2025-09-05T12:30:11.4287148Z         )
2025-09-05T12:30:11.4287354Z     
2025-09-05T12:30:11.4287602Z >       assert dq_validation.checks(functional=True) == validation_output
2025-09-05T12:30:11.4287858Z E       assert None == False
2025-09-05T12:30:11.4288102Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4288394Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a43c2c10>.checks
2025-09-05T12:30:11.4288520Z 
2025-09-05T12:30:11.4288756Z test/test_dq/test_dq_validation.py:128: AssertionError
2025-09-05T12:30:11.4289030Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4289381Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_unique at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_unique.yml
2025-09-05T12:30:11.4289779Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_unique at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_unique.yml
2025-09-05T12:30:11.4290112Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4290484Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4290758Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4291026Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4291311Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4291591Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4291873Z 2025-09-05 12:29:14 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4292146Z 2025-09-05 12:29:14 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4292445Z 2025-09-05 12:29:14 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4292774Z 2025-09-05 12:29:14 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4293048Z 2025-09-05 12:29:14 [INFO] checks:  No checks done
2025-09-05T12:30:11.4293307Z 2025-09-05 12:29:14 [INFO] checks:  No checks done
2025-09-05T12:30:11.4293713Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4294065Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_unique at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_unique.yml
2025-09-05T12:30:11.4294432Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4294731Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4295030Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4295328Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4295636Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4295933Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4296219Z ______________ test_columns[dq_test_happy-True-expected_logging0] ______________
2025-09-05T12:30:11.4296336Z 
2025-09-05T12:30:11.4296582Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4296863Z main_data = ('dq_test_happy', None), reference_data = None
2025-09-05T12:30:11.4297112Z validation_output = True
2025-09-05T12:30:11.4297375Z expected_logging = ['Number of columns matches: 4 expected and received', 'Datatypes match']
2025-09-05T12:30:11.4297671Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a41223d0>
2025-09-05T12:30:11.4297780Z 
2025-09-05T12:30:11.4297996Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4298246Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4298471Z         [
2025-09-05T12:30:11.4298684Z             (
2025-09-05T12:30:11.4298898Z                 "dq_test_happy",
2025-09-05T12:30:11.4299114Z                 True,
2025-09-05T12:30:11.4299364Z                 ["Number of columns matches: 4 expected and received", "Datatypes match"],
2025-09-05T12:30:11.4299617Z             ),
2025-09-05T12:30:11.4299818Z             (
2025-09-05T12:30:11.4300036Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4300257Z                 True,
2025-09-05T12:30:11.4300476Z                 [
2025-09-05T12:30:11.4300711Z                     "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4300954Z                     "No datatypes checked",
2025-09-05T12:30:11.4301165Z                 ],
2025-09-05T12:30:11.4301376Z             ),
2025-09-05T12:30:11.4301573Z             (
2025-09-05T12:30:11.4301826Z                 "dq_test_no_checks",
2025-09-05T12:30:11.4302039Z                 None,
2025-09-05T12:30:11.4302267Z                 ["No columns to check"],
2025-09-05T12:30:11.4302480Z             ),
2025-09-05T12:30:11.4302682Z             (
2025-09-05T12:30:11.4302897Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4303199Z                 False,
2025-09-05T12:30:11.4303516Z                 [
2025-09-05T12:30:11.4303834Z                     "Number of columns incorrect: expected 5, received 4",
2025-09-05T12:30:11.4304081Z                     "No datatypes checked",
2025-09-05T12:30:11.4304304Z                 ],
2025-09-05T12:30:11.4304511Z             ),
2025-09-05T12:30:11.4304714Z             (
2025-09-05T12:30:11.4304940Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4305180Z                 False,
2025-09-05T12:30:11.4305393Z                 [
2025-09-05T12:30:11.4305630Z                     "Number of columns incorrect: expected 5, received 4",
2025-09-05T12:30:11.4305881Z                     "Mismatch in datatypes, differences: "
2025-09-05T12:30:11.4306146Z                     "expected [('Extra', 'int')], received []",
2025-09-05T12:30:11.4306420Z                 ],
2025-09-05T12:30:11.4306627Z             ),
2025-09-05T12:30:11.4306829Z             (
2025-09-05T12:30:11.4307062Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4307288Z                 False,
2025-09-05T12:30:11.4307504Z                 [
2025-09-05T12:30:11.4307739Z                     "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4308003Z                     "Mismatch in datatypes, differences: "
2025-09-05T12:30:11.4308266Z                     "expected [('Type', 'int')], received [('Type', 'string')]",
2025-09-05T12:30:11.4308505Z                 ],
2025-09-05T12:30:11.4308719Z             ),
2025-09-05T12:30:11.4308925Z         ],
2025-09-05T12:30:11.4309146Z         indirect=["main_data"],
2025-09-05T12:30:11.4309354Z     )
2025-09-05T12:30:11.4309567Z     def test_columns(
2025-09-05T12:30:11.4309792Z         spark_session,
2025-09-05T12:30:11.4310006Z         main_data,
2025-09-05T12:30:11.4310222Z         reference_data,
2025-09-05T12:30:11.4310443Z         validation_output,
2025-09-05T12:30:11.4310669Z         expected_logging,
2025-09-05T12:30:11.4310879Z         caplog,
2025-09-05T12:30:11.4311084Z     ):
2025-09-05T12:30:11.4311316Z         """Test number of columns and datatypes for a given table"""
2025-09-05T12:30:11.4311557Z         table_name = main_data[0]
2025-09-05T12:30:11.4311761Z     
2025-09-05T12:30:11.4311982Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4312206Z             spark_session,
2025-09-05T12:30:11.4312425Z             table_name,
2025-09-05T12:30:11.4312646Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4312869Z             schema_name="dq",
2025-09-05T12:30:11.4313092Z             run_month="",
2025-09-05T12:30:11.4313309Z             local=True,
2025-09-05T12:30:11.4313715Z         )
2025-09-05T12:30:11.4313921Z     
2025-09-05T12:30:11.4314176Z >       assert dq_validation.columns_datatypes().get("result", None) == validation_output
2025-09-05T12:30:11.4314453Z E       AssertionError: assert None == True
2025-09-05T12:30:11.4314724Z E        +  where None = <built-in method get of dict object at 0x7fe8a428e5c0>('result', None)
2025-09-05T12:30:11.4315014Z E        +    where <built-in method get of dict object at 0x7fe8a428e5c0> = {}.get
2025-09-05T12:30:11.4315282Z E        +      where {} = columns_datatypes()
2025-09-05T12:30:11.4315577Z E        +        where columns_datatypes = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a4121d50>.columns_datatypes
2025-09-05T12:30:11.4315718Z 
2025-09-05T12:30:11.4315960Z test/test_dq/test_dq_validation.py:202: AssertionError
2025-09-05T12:30:11.4316348Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4316719Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4317102Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4317523Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4317808Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4318091Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4318442Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4318819Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4319114Z __________ test_columns[dq_test_happy_col_num-True-expected_logging1] __________
2025-09-05T12:30:11.4319231Z 
2025-09-05T12:30:11.4319485Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4319810Z main_data = ('dq_test_happy_col_num', None), reference_data = None
2025-09-05T12:30:11.4320052Z validation_output = True
2025-09-05T12:30:11.4320315Z expected_logging = ['Number of columns matches: 4 expected and received', 'No datatypes checked']
2025-09-05T12:30:11.4320614Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a439ded0>
2025-09-05T12:30:11.4320723Z 
2025-09-05T12:30:11.4320935Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4321187Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4321409Z         [
2025-09-05T12:30:11.4321631Z             (
2025-09-05T12:30:11.4321844Z                 "dq_test_happy",
2025-09-05T12:30:11.4322056Z                 True,
2025-09-05T12:30:11.4322300Z                 ["Number of columns matches: 4 expected and received", "Datatypes match"],
2025-09-05T12:30:11.4322540Z             ),
2025-09-05T12:30:11.4322739Z             (
2025-09-05T12:30:11.4322956Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4323173Z                 True,
2025-09-05T12:30:11.4323501Z                 [
2025-09-05T12:30:11.4323842Z                     "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4324131Z                     "No datatypes checked",
2025-09-05T12:30:11.4324346Z                 ],
2025-09-05T12:30:11.4324559Z             ),
2025-09-05T12:30:11.4324766Z             (
2025-09-05T12:30:11.4324985Z                 "dq_test_no_checks",
2025-09-05T12:30:11.4325207Z                 None,
2025-09-05T12:30:11.4325436Z                 ["No columns to check"],
2025-09-05T12:30:11.4325649Z             ),
2025-09-05T12:30:11.4325856Z             (
2025-09-05T12:30:11.4326083Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4326317Z                 False,
2025-09-05T12:30:11.4326528Z                 [
2025-09-05T12:30:11.4326766Z                     "Number of columns incorrect: expected 5, received 4",
2025-09-05T12:30:11.4327017Z                     "No datatypes checked",
2025-09-05T12:30:11.4327241Z                 ],
2025-09-05T12:30:11.4327443Z             ),
2025-09-05T12:30:11.4327646Z             (
2025-09-05T12:30:11.4327862Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4328094Z                 False,
2025-09-05T12:30:11.4328300Z                 [
2025-09-05T12:30:11.4328535Z                     "Number of columns incorrect: expected 5, received 4",
2025-09-05T12:30:11.4328785Z                     "Mismatch in datatypes, differences: "
2025-09-05T12:30:11.4329034Z                     "expected [('Extra', 'int')], received []",
2025-09-05T12:30:11.4329249Z                 ],
2025-09-05T12:30:11.4329447Z             ),
2025-09-05T12:30:11.4329643Z             (
2025-09-05T12:30:11.4329873Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4330093Z                 False,
2025-09-05T12:30:11.4330296Z                 [
2025-09-05T12:30:11.4330529Z                     "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4330786Z                     "Mismatch in datatypes, differences: "
2025-09-05T12:30:11.4331039Z                     "expected [('Type', 'int')], received [('Type', 'string')]",
2025-09-05T12:30:11.4331356Z                 ],
2025-09-05T12:30:11.4331556Z             ),
2025-09-05T12:30:11.4331767Z         ],
2025-09-05T12:30:11.4331986Z         indirect=["main_data"],
2025-09-05T12:30:11.4332197Z     )
2025-09-05T12:30:11.4332410Z     def test_columns(
2025-09-05T12:30:11.4332637Z         spark_session,
2025-09-05T12:30:11.4332853Z         main_data,
2025-09-05T12:30:11.4333069Z         reference_data,
2025-09-05T12:30:11.4333296Z         validation_output,
2025-09-05T12:30:11.4333651Z         expected_logging,
2025-09-05T12:30:11.4333868Z         caplog,
2025-09-05T12:30:11.4334077Z     ):
2025-09-05T12:30:11.4334324Z         """Test number of columns and datatypes for a given table"""
2025-09-05T12:30:11.4334577Z         table_name = main_data[0]
2025-09-05T12:30:11.4334793Z     
2025-09-05T12:30:11.4335076Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4335305Z             spark_session,
2025-09-05T12:30:11.4335538Z             table_name,
2025-09-05T12:30:11.4335781Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4336011Z             schema_name="dq",
2025-09-05T12:30:11.4336234Z             run_month="",
2025-09-05T12:30:11.4336469Z             local=True,
2025-09-05T12:30:11.4336677Z         )
2025-09-05T12:30:11.4336875Z     
2025-09-05T12:30:11.4337128Z >       assert dq_validation.columns_datatypes().get("result", None) == validation_output
2025-09-05T12:30:11.4337407Z E       AssertionError: assert None == True
2025-09-05T12:30:11.4337669Z E        +  where None = <built-in method get of dict object at 0x7fe8a4276d00>('result', None)
2025-09-05T12:30:11.4337954Z E        +    where <built-in method get of dict object at 0x7fe8a4276d00> = {}.get
2025-09-05T12:30:11.4338209Z E        +      where {} = columns_datatypes()
2025-09-05T12:30:11.4338501Z E        +        where columns_datatypes = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a439f490>.columns_datatypes
2025-09-05T12:30:11.4338639Z 
2025-09-05T12:30:11.4338878Z test/test_dq/test_dq_validation.py:202: AssertionError
2025-09-05T12:30:11.4339157Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4339506Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_happy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy_col_num.yml
2025-09-05T12:30:11.4339898Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_happy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy_col_num.yml
2025-09-05T12:30:11.4340227Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4340503Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4340773Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4341126Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_happy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy_col_num.yml
2025-09-05T12:30:11.4341581Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4341869Z ________ test_columns[dq_test_unhappy_col_num-False-expected_logging3] _________
2025-09-05T12:30:11.4341983Z 
2025-09-05T12:30:11.4342229Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4342518Z main_data = ('dq_test_unhappy_col_num', None), reference_data = None
2025-09-05T12:30:11.4342764Z validation_output = False
2025-09-05T12:30:11.4343033Z expected_logging = ['Number of columns incorrect: expected 5, received 4', 'No datatypes checked']
2025-09-05T12:30:11.4343325Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a427aad0>
2025-09-05T12:30:11.4343607Z 
2025-09-05T12:30:11.4343832Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4344086Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4344379Z         [
2025-09-05T12:30:11.4344593Z             (
2025-09-05T12:30:11.4344810Z                 "dq_test_happy",
2025-09-05T12:30:11.4345033Z                 True,
2025-09-05T12:30:11.4345284Z                 ["Number of columns matches: 4 expected and received", "Datatypes match"],
2025-09-05T12:30:11.4345533Z             ),
2025-09-05T12:30:11.4345736Z             (
2025-09-05T12:30:11.4345962Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4346190Z                 True,
2025-09-05T12:30:11.4346483Z                 [
2025-09-05T12:30:11.4346787Z                     "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4347030Z                     "No datatypes checked",
2025-09-05T12:30:11.4347245Z                 ],
2025-09-05T12:30:11.4347452Z             ),
2025-09-05T12:30:11.4347714Z             (
2025-09-05T12:30:11.4347934Z                 "dq_test_no_checks",
2025-09-05T12:30:11.4348152Z                 None,
2025-09-05T12:30:11.4348381Z                 ["No columns to check"],
2025-09-05T12:30:11.4348599Z             ),
2025-09-05T12:30:11.4348807Z             (
2025-09-05T12:30:11.4349034Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4349275Z                 False,
2025-09-05T12:30:11.4349488Z                 [
2025-09-05T12:30:11.4349721Z                     "Number of columns incorrect: expected 5, received 4",
2025-09-05T12:30:11.4349961Z                     "No datatypes checked",
2025-09-05T12:30:11.4350182Z                 ],
2025-09-05T12:30:11.4350381Z             ),
2025-09-05T12:30:11.4350582Z             (
2025-09-05T12:30:11.4350803Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4351029Z                 False,
2025-09-05T12:30:11.4351242Z                 [
2025-09-05T12:30:11.4351486Z                     "Number of columns incorrect: expected 5, received 4",
2025-09-05T12:30:11.4351740Z                     "Mismatch in datatypes, differences: "
2025-09-05T12:30:11.4352004Z                     "expected [('Extra', 'int')], received []",
2025-09-05T12:30:11.4352231Z                 ],
2025-09-05T12:30:11.4352438Z             ),
2025-09-05T12:30:11.4352641Z             (
2025-09-05T12:30:11.4352872Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4353101Z                 False,
2025-09-05T12:30:11.4353311Z                 [
2025-09-05T12:30:11.4353684Z                     "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4353947Z                     "Mismatch in datatypes, differences: "
2025-09-05T12:30:11.4354210Z                     "expected [('Type', 'int')], received [('Type', 'string')]",
2025-09-05T12:30:11.4354442Z                 ],
2025-09-05T12:30:11.4354652Z             ),
2025-09-05T12:30:11.4354873Z         ],
2025-09-05T12:30:11.4355096Z         indirect=["main_data"],
2025-09-05T12:30:11.4355314Z     )
2025-09-05T12:30:11.4355535Z     def test_columns(
2025-09-05T12:30:11.4355768Z         spark_session,
2025-09-05T12:30:11.4355981Z         main_data,
2025-09-05T12:30:11.4356202Z         reference_data,
2025-09-05T12:30:11.4356425Z         validation_output,
2025-09-05T12:30:11.4356661Z         expected_logging,
2025-09-05T12:30:11.4356903Z         caplog,
2025-09-05T12:30:11.4357109Z     ):
2025-09-05T12:30:11.4357347Z         """Test number of columns and datatypes for a given table"""
2025-09-05T12:30:11.4357593Z         table_name = main_data[0]
2025-09-05T12:30:11.4357805Z     
2025-09-05T12:30:11.4358024Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4358251Z             spark_session,
2025-09-05T12:30:11.4358483Z             table_name,
2025-09-05T12:30:11.4358712Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4358936Z             schema_name="dq",
2025-09-05T12:30:11.4359155Z             run_month="",
2025-09-05T12:30:11.4359383Z             local=True,
2025-09-05T12:30:11.4359592Z         )
2025-09-05T12:30:11.4359791Z     
2025-09-05T12:30:11.4360037Z >       assert dq_validation.columns_datatypes().get("result", None) == validation_output
2025-09-05T12:30:11.4360416Z E       AssertionError: assert None == False
2025-09-05T12:30:11.4360689Z E        +  where None = <built-in method get of dict object at 0x7fe8a4279600>('result', None)
2025-09-05T12:30:11.4360976Z E        +    where <built-in method get of dict object at 0x7fe8a4279600> = {}.get
2025-09-05T12:30:11.4361237Z E        +      where {} = columns_datatypes()
2025-09-05T12:30:11.4361544Z E        +        where columns_datatypes = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a427a990>.columns_datatypes
2025-09-05T12:30:11.4361685Z 
2025-09-05T12:30:11.4361932Z test/test_dq/test_dq_validation.py:202: AssertionError
2025-09-05T12:30:11.4362216Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4362571Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_col_num.yml
2025-09-05T12:30:11.4363016Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_col_num.yml
2025-09-05T12:30:11.4363358Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4363854Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4364137Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4364500Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_col_num at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_col_num.yml
2025-09-05T12:30:11.4364869Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4365160Z ________ test_columns[dq_test_unhappy_num_cols-False-expected_logging4] ________
2025-09-05T12:30:11.4365275Z 
2025-09-05T12:30:11.4365529Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4365823Z main_data = ('dq_test_unhappy_num_cols', None), reference_data = None
2025-09-05T12:30:11.4366082Z validation_output = False
2025-09-05T12:30:11.4366382Z expected_logging = ['Number of columns incorrect: expected 5, received 4', "Mismatch in datatypes, differences: expected [('Extra', 'int')], received []"]
2025-09-05T12:30:11.4366694Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a4272150>
2025-09-05T12:30:11.4366812Z 
2025-09-05T12:30:11.4367025Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4367277Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4367501Z         [
2025-09-05T12:30:11.4367714Z             (
2025-09-05T12:30:11.4367927Z                 "dq_test_happy",
2025-09-05T12:30:11.4368149Z                 True,
2025-09-05T12:30:11.4368398Z                 ["Number of columns matches: 4 expected and received", "Datatypes match"],
2025-09-05T12:30:11.4368647Z             ),
2025-09-05T12:30:11.4368850Z             (
2025-09-05T12:30:11.4369067Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4369290Z                 True,
2025-09-05T12:30:11.4369503Z                 [
2025-09-05T12:30:11.4369739Z                     "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4369979Z                     "No datatypes checked",
2025-09-05T12:30:11.4370196Z                 ],
2025-09-05T12:30:11.4370405Z             ),
2025-09-05T12:30:11.4370600Z             (
2025-09-05T12:30:11.4370817Z                 "dq_test_no_checks",
2025-09-05T12:30:11.4371033Z                 None,
2025-09-05T12:30:11.4371268Z                 ["No columns to check"],
2025-09-05T12:30:11.4371476Z             ),
2025-09-05T12:30:11.4371682Z             (
2025-09-05T12:30:11.4371903Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4372135Z                 False,
2025-09-05T12:30:11.4372342Z                 [
2025-09-05T12:30:11.4372700Z                     "Number of columns incorrect: expected 5, received 4",
2025-09-05T12:30:11.4372957Z                     "No datatypes checked",
2025-09-05T12:30:11.4373190Z                 ],
2025-09-05T12:30:11.4373479Z             ),
2025-09-05T12:30:11.4373692Z             (
2025-09-05T12:30:11.4373923Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4374163Z                 False,
2025-09-05T12:30:11.4374380Z                 [
2025-09-05T12:30:11.4374632Z                     "Number of columns incorrect: expected 5, received 4",
2025-09-05T12:30:11.4374897Z                     "Mismatch in datatypes, differences: "
2025-09-05T12:30:11.4375171Z                     "expected [('Extra', 'int')], received []",
2025-09-05T12:30:11.4375405Z                 ],
2025-09-05T12:30:11.4375618Z             ),
2025-09-05T12:30:11.4375865Z             (
2025-09-05T12:30:11.4376097Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4376324Z                 False,
2025-09-05T12:30:11.4376539Z                 [
2025-09-05T12:30:11.4376788Z                     "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4377051Z                     "Mismatch in datatypes, differences: "
2025-09-05T12:30:11.4377313Z                     "expected [('Type', 'int')], received [('Type', 'string')]",
2025-09-05T12:30:11.4377555Z                 ],
2025-09-05T12:30:11.4377769Z             ),
2025-09-05T12:30:11.4377993Z         ],
2025-09-05T12:30:11.4378217Z         indirect=["main_data"],
2025-09-05T12:30:11.4378427Z     )
2025-09-05T12:30:11.4378642Z     def test_columns(
2025-09-05T12:30:11.4378874Z         spark_session,
2025-09-05T12:30:11.4379091Z         main_data,
2025-09-05T12:30:11.4379311Z         reference_data,
2025-09-05T12:30:11.4379540Z         validation_output,
2025-09-05T12:30:11.4379774Z         expected_logging,
2025-09-05T12:30:11.4379993Z         caplog,
2025-09-05T12:30:11.4380196Z     ):
2025-09-05T12:30:11.4380429Z         """Test number of columns and datatypes for a given table"""
2025-09-05T12:30:11.4380680Z         table_name = main_data[0]
2025-09-05T12:30:11.4380884Z     
2025-09-05T12:30:11.4381105Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4381340Z             spark_session,
2025-09-05T12:30:11.4381569Z             table_name,
2025-09-05T12:30:11.4381801Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4382033Z             schema_name="dq",
2025-09-05T12:30:11.4382261Z             run_month="",
2025-09-05T12:30:11.4382484Z             local=True,
2025-09-05T12:30:11.4382691Z         )
2025-09-05T12:30:11.4382884Z     
2025-09-05T12:30:11.4383135Z >       assert dq_validation.columns_datatypes().get("result", None) == validation_output
2025-09-05T12:30:11.4383512Z E       AssertionError: assert None == False
2025-09-05T12:30:11.4383789Z E        +  where None = <built-in method get of dict object at 0x7fe8a4278480>('result', None)
2025-09-05T12:30:11.4384086Z E        +    where <built-in method get of dict object at 0x7fe8a4278480> = {}.get
2025-09-05T12:30:11.4384350Z E        +      where {} = columns_datatypes()
2025-09-05T12:30:11.4384659Z E        +        where columns_datatypes = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a41546d0>.columns_datatypes
2025-09-05T12:30:11.4384801Z 
2025-09-05T12:30:11.4385045Z test/test_dq/test_dq_validation.py:202: AssertionError
2025-09-05T12:30:11.4385327Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4385680Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_num_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_num_cols.yml
2025-09-05T12:30:11.4386074Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_num_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_num_cols.yml
2025-09-05T12:30:11.4386412Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4386791Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4387186Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4387844Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_num_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_num_cols.yml
2025-09-05T12:30:11.4388499Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4389001Z _______ test_columns[dq_test_unhappy_type_cols-False-expected_logging5] ________
2025-09-05T12:30:11.4389156Z 
2025-09-05T12:30:11.4389499Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4389895Z main_data = ('dq_test_unhappy_type_cols', None), reference_data = None
2025-09-05T12:30:11.4390439Z validation_output = False
2025-09-05T12:30:11.4390996Z expected_logging = ['Number of columns matches: 4 expected and received', "Mismatch in datatypes, differences: expected [('Type', 'int')], received [('Type', 'string')]"]
2025-09-05T12:30:11.4391575Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a434cd50>
2025-09-05T12:30:11.4391792Z 
2025-09-05T12:30:11.4392176Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4392590Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4392977Z         [
2025-09-05T12:30:11.4393269Z             (
2025-09-05T12:30:11.4393672Z                 "dq_test_happy",
2025-09-05T12:30:11.4393928Z                 True,
2025-09-05T12:30:11.4394179Z                 ["Number of columns matches: 4 expected and received", "Datatypes match"],
2025-09-05T12:30:11.4394428Z             ),
2025-09-05T12:30:11.4394635Z             (
2025-09-05T12:30:11.4394857Z                 "dq_test_happy_col_num",
2025-09-05T12:30:11.4395079Z                 True,
2025-09-05T12:30:11.4395302Z                 [
2025-09-05T12:30:11.4395541Z                     "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4395785Z                     "No datatypes checked",
2025-09-05T12:30:11.4396005Z                 ],
2025-09-05T12:30:11.4396216Z             ),
2025-09-05T12:30:11.4396420Z             (
2025-09-05T12:30:11.4396639Z                 "dq_test_no_checks",
2025-09-05T12:30:11.4396859Z                 None,
2025-09-05T12:30:11.4397087Z                 ["No columns to check"],
2025-09-05T12:30:11.4397296Z             ),
2025-09-05T12:30:11.4397500Z             (
2025-09-05T12:30:11.4397726Z                 "dq_test_unhappy_col_num",
2025-09-05T12:30:11.4397956Z                 False,
2025-09-05T12:30:11.4398163Z                 [
2025-09-05T12:30:11.4398405Z                     "Number of columns incorrect: expected 5, received 4",
2025-09-05T12:30:11.4398654Z                     "No datatypes checked",
2025-09-05T12:30:11.4398878Z                 ],
2025-09-05T12:30:11.4399079Z             ),
2025-09-05T12:30:11.4399301Z             (
2025-09-05T12:30:11.4399525Z                 "dq_test_unhappy_num_cols",
2025-09-05T12:30:11.4399755Z                 False,
2025-09-05T12:30:11.4399958Z                 [
2025-09-05T12:30:11.4400196Z                     "Number of columns incorrect: expected 5, received 4",
2025-09-05T12:30:11.4400444Z                     "Mismatch in datatypes, differences: "
2025-09-05T12:30:11.4400695Z                     "expected [('Extra', 'int')], received []",
2025-09-05T12:30:11.4400914Z                 ],
2025-09-05T12:30:11.4401111Z             ),
2025-09-05T12:30:11.4401309Z             (
2025-09-05T12:30:11.4401544Z                 "dq_test_unhappy_type_cols",
2025-09-05T12:30:11.4401793Z                 False,
2025-09-05T12:30:11.4401996Z                 [
2025-09-05T12:30:11.4402232Z                     "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4402489Z                     "Mismatch in datatypes, differences: "
2025-09-05T12:30:11.4402741Z                     "expected [('Type', 'int')], received [('Type', 'string')]",
2025-09-05T12:30:11.4403122Z                 ],
2025-09-05T12:30:11.4403328Z             ),
2025-09-05T12:30:11.4403645Z         ],
2025-09-05T12:30:11.4403867Z         indirect=["main_data"],
2025-09-05T12:30:11.4404078Z     )
2025-09-05T12:30:11.4404296Z     def test_columns(
2025-09-05T12:30:11.4404526Z         spark_session,
2025-09-05T12:30:11.4404745Z         main_data,
2025-09-05T12:30:11.4404965Z         reference_data,
2025-09-05T12:30:11.4405190Z         validation_output,
2025-09-05T12:30:11.4405421Z         expected_logging,
2025-09-05T12:30:11.4405633Z         caplog,
2025-09-05T12:30:11.4405835Z     ):
2025-09-05T12:30:11.4406075Z         """Test number of columns and datatypes for a given table"""
2025-09-05T12:30:11.4406322Z         table_name = main_data[0]
2025-09-05T12:30:11.4406583Z     
2025-09-05T12:30:11.4406801Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4407033Z             spark_session,
2025-09-05T12:30:11.4407259Z             table_name,
2025-09-05T12:30:11.4407490Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4407722Z             schema_name="dq",
2025-09-05T12:30:11.4407948Z             run_month="",
2025-09-05T12:30:11.4408177Z             local=True,
2025-09-05T12:30:11.4408390Z         )
2025-09-05T12:30:11.4408599Z     
2025-09-05T12:30:11.4408850Z >       assert dq_validation.columns_datatypes().get("result", None) == validation_output
2025-09-05T12:30:11.4409125Z E       AssertionError: assert None == False
2025-09-05T12:30:11.4409398Z E        +  where None = <built-in method get of dict object at 0x7fe8a4273800>('result', None)
2025-09-05T12:30:11.4409677Z E        +    where <built-in method get of dict object at 0x7fe8a4273800> = {}.get
2025-09-05T12:30:11.4409934Z E        +      where {} = columns_datatypes()
2025-09-05T12:30:11.4410233Z E        +        where columns_datatypes = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a434ebd0>.columns_datatypes
2025-09-05T12:30:11.4410369Z 
2025-09-05T12:30:11.4410609Z test/test_dq/test_dq_validation.py:202: AssertionError
2025-09-05T12:30:11.4410884Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4411242Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_type_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_type_cols.yml
2025-09-05T12:30:11.4411640Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_type_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_type_cols.yml
2025-09-05T12:30:11.4411980Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4412262Z 2025-09-05 12:29:14 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4412538Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4412893Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_type_cols at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_type_cols.yml
2025-09-05T12:30:11.4413256Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4413604Z ____________ test_primary_key[dq_test_happy-True-expected_logging0] ____________
2025-09-05T12:30:11.4413721Z 
2025-09-05T12:30:11.4413963Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4414242Z main_data = ('dq_test_happy', None), reference_data = None
2025-09-05T12:30:11.4414485Z validation_output = True
2025-09-05T12:30:11.4414770Z expected_logging = ["['PK1', 'PK2'] is unique", "No nulls found in ['PK1', 'PK2']", "Primary key ['PK1', 'PK2'] validated successfully"]
2025-09-05T12:30:11.4415071Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a42d19d0>
2025-09-05T12:30:11.4415192Z 
2025-09-05T12:30:11.4415415Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4415758Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4415988Z         [
2025-09-05T12:30:11.4416202Z             (
2025-09-05T12:30:11.4416423Z                 "dq_test_happy",
2025-09-05T12:30:11.4416643Z                 True,
2025-09-05T12:30:11.4416853Z                 [
2025-09-05T12:30:11.4417116Z                     "['PK1', 'PK2'] is unique",
2025-09-05T12:30:11.4417453Z                     "No nulls found in ['PK1', 'PK2']",
2025-09-05T12:30:11.4417823Z                     "Primary key ['PK1', 'PK2'] validated successfully",
2025-09-05T12:30:11.4418054Z                 ],
2025-09-05T12:30:11.4418270Z             ),
2025-09-05T12:30:11.4418477Z             (
2025-09-05T12:30:11.4418696Z                 "dq_test_no_check",
2025-09-05T12:30:11.4418916Z                 None,
2025-09-05T12:30:11.4419224Z                 ["No Primary Key to check"],
2025-09-05T12:30:11.4419439Z             ),
2025-09-05T12:30:11.4419640Z             (
2025-09-05T12:30:11.4419863Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4420096Z                 False,
2025-09-05T12:30:11.4420328Z                 [
2025-09-05T12:30:11.4420567Z                     "Duplicates found in ['PK1']: [Row(PK1=2, count=2)]",
2025-09-05T12:30:11.4420817Z                     "No nulls found in ['PK1']",
2025-09-05T12:30:11.4421066Z                     "Issues found in primary key ['PK1']",
2025-09-05T12:30:11.4421286Z                 ],
2025-09-05T12:30:11.4421488Z             ),
2025-09-05T12:30:11.4421688Z             (
2025-09-05T12:30:11.4421915Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4422138Z                 False,
2025-09-05T12:30:11.4422343Z                 [
2025-09-05T12:30:11.4422565Z                     "['PK1', 'PK2', 'PK3'] is unique",
2025-09-05T12:30:11.4422826Z                     "Nulls found in not nullable column(s): ['PK3']",
2025-09-05T12:30:11.4423089Z                     "Issues found in primary key ['PK1', 'PK2', 'PK3']",
2025-09-05T12:30:11.4423319Z                 ],
2025-09-05T12:30:11.4423647Z             ),
2025-09-05T12:30:11.4423902Z         ],
2025-09-05T12:30:11.4424117Z         indirect=["main_data"],
2025-09-05T12:30:11.4424329Z     )
2025-09-05T12:30:11.4424548Z     def test_primary_key(
2025-09-05T12:30:11.4424777Z         spark_session,
2025-09-05T12:30:11.4424994Z         main_data,
2025-09-05T12:30:11.4425213Z         reference_data,
2025-09-05T12:30:11.4425441Z         validation_output,
2025-09-05T12:30:11.4425662Z         expected_logging,
2025-09-05T12:30:11.4425882Z         caplog,
2025-09-05T12:30:11.4426083Z     ):
2025-09-05T12:30:11.4426323Z         """Test primary key nulls and uniqueness for a given table"""
2025-09-05T12:30:11.4426546Z     
2025-09-05T12:30:11.4426773Z         table_name = main_data[0]
2025-09-05T12:30:11.4426980Z     
2025-09-05T12:30:11.4427204Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4427428Z             spark_session,
2025-09-05T12:30:11.4427653Z             table_name,
2025-09-05T12:30:11.4427878Z             schema_name="dq",
2025-09-05T12:30:11.4428096Z             run_month="",
2025-09-05T12:30:11.4428328Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4428561Z             local=True,
2025-09-05T12:30:11.4428766Z         )
2025-09-05T12:30:11.4428964Z     
2025-09-05T12:30:11.4429211Z >       assert dq_validation.primary_key().get("result", None) == validation_output
2025-09-05T12:30:11.4429483Z E       AssertionError: assert None == True
2025-09-05T12:30:11.4429754Z E        +  where None = <built-in method get of dict object at 0x7fe8a4274c80>('result', None)
2025-09-05T12:30:11.4430040Z E        +    where <built-in method get of dict object at 0x7fe8a4274c80> = {}.get
2025-09-05T12:30:11.4430301Z E        +      where {} = primary_key()
2025-09-05T12:30:11.4430573Z E        +        where primary_key = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a42d2190>.primary_key
2025-09-05T12:30:11.4430708Z 
2025-09-05T12:30:11.4430943Z test/test_dq/test_dq_validation.py:265: AssertionError
2025-09-05T12:30:11.4431311Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4431653Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4432028Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4432347Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4432627Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4432905Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4433290Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4433741Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4434029Z _______ test_primary_key[dq_test_unhappy_pk_dup-False-expected_logging2] _______
2025-09-05T12:30:11.4434142Z 
2025-09-05T12:30:11.4434386Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4434667Z main_data = ('dq_test_unhappy_pk_dup', None), reference_data = None
2025-09-05T12:30:11.4434918Z validation_output = False
2025-09-05T12:30:11.4435207Z expected_logging = ["Duplicates found in ['PK1']: [Row(PK1=2, count=2)]", "No nulls found in ['PK1']", "Issues found in primary key ['PK1']"]
2025-09-05T12:30:11.4435508Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a4289550>
2025-09-05T12:30:11.4435625Z 
2025-09-05T12:30:11.4435844Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4436086Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4436310Z         [
2025-09-05T12:30:11.4436524Z             (
2025-09-05T12:30:11.4436742Z                 "dq_test_happy",
2025-09-05T12:30:11.4436956Z                 True,
2025-09-05T12:30:11.4437165Z                 [
2025-09-05T12:30:11.4437398Z                     "['PK1', 'PK2'] is unique",
2025-09-05T12:30:11.4437635Z                     "No nulls found in ['PK1', 'PK2']",
2025-09-05T12:30:11.4437885Z                     "Primary key ['PK1', 'PK2'] validated successfully",
2025-09-05T12:30:11.4438109Z                 ],
2025-09-05T12:30:11.4438319Z             ),
2025-09-05T12:30:11.4438544Z             (
2025-09-05T12:30:11.4438760Z                 "dq_test_no_check",
2025-09-05T12:30:11.4438974Z                 None,
2025-09-05T12:30:11.4439205Z                 ["No Primary Key to check"],
2025-09-05T12:30:11.4439419Z             ),
2025-09-05T12:30:11.4439619Z             (
2025-09-05T12:30:11.4439842Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4440069Z                 False,
2025-09-05T12:30:11.4440274Z                 [
2025-09-05T12:30:11.4440504Z                     "Duplicates found in ['PK1']: [Row(PK1=2, count=2)]",
2025-09-05T12:30:11.4440748Z                     "No nulls found in ['PK1']",
2025-09-05T12:30:11.4440989Z                     "Issues found in primary key ['PK1']",
2025-09-05T12:30:11.4441218Z                 ],
2025-09-05T12:30:11.4441490Z             ),
2025-09-05T12:30:11.4441769Z             (
2025-09-05T12:30:11.4442051Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4442271Z                 False,
2025-09-05T12:30:11.4442472Z                 [
2025-09-05T12:30:11.4442694Z                     "['PK1', 'PK2', 'PK3'] is unique",
2025-09-05T12:30:11.4442945Z                     "Nulls found in not nullable column(s): ['PK3']",
2025-09-05T12:30:11.4443196Z                     "Issues found in primary key ['PK1', 'PK2', 'PK3']",
2025-09-05T12:30:11.4443506Z                 ],
2025-09-05T12:30:11.4443972Z             ),
2025-09-05T12:30:11.4444316Z         ],
2025-09-05T12:30:11.4444735Z         indirect=["main_data"],
2025-09-05T12:30:11.4445076Z     )
2025-09-05T12:30:11.4445383Z     def test_primary_key(
2025-09-05T12:30:11.4445705Z         spark_session,
2025-09-05T12:30:11.4446052Z         main_data,
2025-09-05T12:30:11.4446333Z         reference_data,
2025-09-05T12:30:11.4446668Z         validation_output,
2025-09-05T12:30:11.4447011Z         expected_logging,
2025-09-05T12:30:11.4447324Z         caplog,
2025-09-05T12:30:11.4447603Z     ):
2025-09-05T12:30:11.4447913Z         """Test primary key nulls and uniqueness for a given table"""
2025-09-05T12:30:11.4448270Z     
2025-09-05T12:30:11.4448573Z         table_name = main_data[0]
2025-09-05T12:30:11.4448870Z     
2025-09-05T12:30:11.4449163Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4467557Z             spark_session,
2025-09-05T12:30:11.4468065Z             table_name,
2025-09-05T12:30:11.4468315Z             schema_name="dq",
2025-09-05T12:30:11.4468561Z             run_month="",
2025-09-05T12:30:11.4468806Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4469039Z             local=True,
2025-09-05T12:30:11.4469252Z         )
2025-09-05T12:30:11.4469465Z     
2025-09-05T12:30:11.4469719Z >       assert dq_validation.primary_key().get("result", None) == validation_output
2025-09-05T12:30:11.4469998Z E       AssertionError: assert None == False
2025-09-05T12:30:11.4470283Z E        +  where None = <built-in method get of dict object at 0x7fe8a4288940>('result', None)
2025-09-05T12:30:11.4470585Z E        +    where <built-in method get of dict object at 0x7fe8a4288940> = {}.get
2025-09-05T12:30:11.4470843Z E        +      where {} = primary_key()
2025-09-05T12:30:11.4471124Z E        +        where primary_key = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a428b750>.primary_key
2025-09-05T12:30:11.4471278Z 
2025-09-05T12:30:11.4471534Z test/test_dq/test_dq_validation.py:265: AssertionError
2025-09-05T12:30:11.4471822Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4472179Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_pk_dup at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_dup.yml
2025-09-05T12:30:11.4472591Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_pk_dup at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_dup.yml
2025-09-05T12:30:11.4472931Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4473205Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4473630Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4473995Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_pk_dup at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_dup.yml
2025-09-05T12:30:11.4474368Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4474677Z ______ test_primary_key[dq_test_unhappy_pk_null-False-expected_logging3] _______
2025-09-05T12:30:11.4474791Z 
2025-09-05T12:30:11.4475036Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4475322Z main_data = ('dq_test_unhappy_pk_null', None), reference_data = None
2025-09-05T12:30:11.4475702Z validation_output = False
2025-09-05T12:30:11.4476106Z expected_logging = ["['PK1', 'PK2', 'PK3'] is unique", "Nulls found in not nullable column(s): ['PK3']", "Issues found in primary key ['PK1', 'PK2', 'PK3']"]
2025-09-05T12:30:11.4476427Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a44070d0>
2025-09-05T12:30:11.4476537Z 
2025-09-05T12:30:11.4476757Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4477018Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4477243Z         [
2025-09-05T12:30:11.4477451Z             (
2025-09-05T12:30:11.4477805Z                 "dq_test_happy",
2025-09-05T12:30:11.4478034Z                 True,
2025-09-05T12:30:11.4478243Z                 [
2025-09-05T12:30:11.4478472Z                     "['PK1', 'PK2'] is unique",
2025-09-05T12:30:11.4478716Z                     "No nulls found in ['PK1', 'PK2']",
2025-09-05T12:30:11.4478982Z                     "Primary key ['PK1', 'PK2'] validated successfully",
2025-09-05T12:30:11.4479217Z                 ],
2025-09-05T12:30:11.4479433Z             ),
2025-09-05T12:30:11.4479641Z             (
2025-09-05T12:30:11.4479878Z                 "dq_test_no_check",
2025-09-05T12:30:11.4480103Z                 None,
2025-09-05T12:30:11.4480341Z                 ["No Primary Key to check"],
2025-09-05T12:30:11.4480566Z             ),
2025-09-05T12:30:11.4480790Z             (
2025-09-05T12:30:11.4481074Z                 "dq_test_unhappy_pk_dup",
2025-09-05T12:30:11.4481304Z                 False,
2025-09-05T12:30:11.4481519Z                 [
2025-09-05T12:30:11.4481770Z                     "Duplicates found in ['PK1']: [Row(PK1=2, count=2)]",
2025-09-05T12:30:11.4482022Z                     "No nulls found in ['PK1']",
2025-09-05T12:30:11.4482269Z                     "Issues found in primary key ['PK1']",
2025-09-05T12:30:11.4482499Z                 ],
2025-09-05T12:30:11.4482721Z             ),
2025-09-05T12:30:11.4482934Z             (
2025-09-05T12:30:11.4483167Z                 "dq_test_unhappy_pk_null",
2025-09-05T12:30:11.4483580Z                 False,
2025-09-05T12:30:11.4483806Z                 [
2025-09-05T12:30:11.4484052Z                     "['PK1', 'PK2', 'PK3'] is unique",
2025-09-05T12:30:11.4484310Z                     "Nulls found in not nullable column(s): ['PK3']",
2025-09-05T12:30:11.4484591Z                     "Issues found in primary key ['PK1', 'PK2', 'PK3']",
2025-09-05T12:30:11.4484830Z                 ],
2025-09-05T12:30:11.4485047Z             ),
2025-09-05T12:30:11.4485261Z         ],
2025-09-05T12:30:11.4485490Z         indirect=["main_data"],
2025-09-05T12:30:11.4485705Z     )
2025-09-05T12:30:11.4485920Z     def test_primary_key(
2025-09-05T12:30:11.4486137Z         spark_session,
2025-09-05T12:30:11.4486355Z         main_data,
2025-09-05T12:30:11.4486573Z         reference_data,
2025-09-05T12:30:11.4486797Z         validation_output,
2025-09-05T12:30:11.4487018Z         expected_logging,
2025-09-05T12:30:11.4487234Z         caplog,
2025-09-05T12:30:11.4487447Z     ):
2025-09-05T12:30:11.4487682Z         """Test primary key nulls and uniqueness for a given table"""
2025-09-05T12:30:11.4487899Z     
2025-09-05T12:30:11.4488117Z         table_name = main_data[0]
2025-09-05T12:30:11.4488339Z     
2025-09-05T12:30:11.4488557Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4488784Z             spark_session,
2025-09-05T12:30:11.4489002Z             table_name,
2025-09-05T12:30:11.4489236Z             schema_name="dq",
2025-09-05T12:30:11.4489459Z             run_month="",
2025-09-05T12:30:11.4489688Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4489920Z             local=True,
2025-09-05T12:30:11.4490138Z         )
2025-09-05T12:30:11.4490338Z     
2025-09-05T12:30:11.4490589Z >       assert dq_validation.primary_key().get("result", None) == validation_output
2025-09-05T12:30:11.4490865Z E       AssertionError: assert None == False
2025-09-05T12:30:11.4491141Z E        +  where None = <built-in method get of dict object at 0x7fe8a4382f80>('result', None)
2025-09-05T12:30:11.4491422Z E        +    where <built-in method get of dict object at 0x7fe8a4382f80> = {}.get
2025-09-05T12:30:11.4491684Z E        +      where {} = primary_key()
2025-09-05T12:30:11.4491976Z E        +        where primary_key = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a44073d0>.primary_key
2025-09-05T12:30:11.4492106Z 
2025-09-05T12:30:11.4492352Z test/test_dq/test_dq_validation.py:265: AssertionError
2025-09-05T12:30:11.4492633Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4493085Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_pk_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_null.yml
2025-09-05T12:30:11.4493651Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_pk_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_null.yml
2025-09-05T12:30:11.4494021Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4494311Z 2025-09-05 12:29:14 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4494594Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4494942Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_pk_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_pk_null.yml
2025-09-05T12:30:11.4495362Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4495660Z _____________ test_not_nulls[dq_test_happy-True-expected_logging0] _____________
2025-09-05T12:30:11.4495771Z 
2025-09-05T12:30:11.4496015Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4496281Z main_data = ('dq_test_happy', None), reference_data = None
2025-09-05T12:30:11.4496554Z validation_output = True, expected_logging = ["No nulls found in ['PK1']"]
2025-09-05T12:30:11.4496823Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a428fa50>
2025-09-05T12:30:11.4496933Z 
2025-09-05T12:30:11.4497148Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4497406Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4497626Z         [
2025-09-05T12:30:11.4497824Z             (
2025-09-05T12:30:11.4498036Z                 "dq_test_happy",
2025-09-05T12:30:11.4498256Z                 True,
2025-09-05T12:30:11.4498501Z                 ["No nulls found in ['PK1']"],
2025-09-05T12:30:11.4498726Z             ),
2025-09-05T12:30:11.4498938Z             (
2025-09-05T12:30:11.4499152Z                 "dq_test_no_check",
2025-09-05T12:30:11.4499376Z                 None,
2025-09-05T12:30:11.4499603Z                 ["No not nullable columns to check"],
2025-09-05T12:30:11.4499830Z             ),
2025-09-05T12:30:11.4500032Z             (
2025-09-05T12:30:11.4500249Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4500469Z                 False,
2025-09-05T12:30:11.4500710Z                 ["Nulls found in not nullable column(s): ['Type']"],
2025-09-05T12:30:11.4500930Z             ),
2025-09-05T12:30:11.4501130Z         ],
2025-09-05T12:30:11.4501343Z         indirect=["main_data"],
2025-09-05T12:30:11.4501560Z     )
2025-09-05T12:30:11.4501798Z     def test_not_nulls(
2025-09-05T12:30:11.4502020Z         spark_session,
2025-09-05T12:30:11.4502236Z         main_data,
2025-09-05T12:30:11.4502461Z         reference_data,
2025-09-05T12:30:11.4502683Z         validation_output,
2025-09-05T12:30:11.4502909Z         expected_logging,
2025-09-05T12:30:11.4503128Z         caplog,
2025-09-05T12:30:11.4503344Z     ):
2025-09-05T12:30:11.4503706Z         """Test not nullable columns for a given table"""
2025-09-05T12:30:11.4503926Z     
2025-09-05T12:30:11.4504148Z         table_name = main_data[0]
2025-09-05T12:30:11.4504368Z     
2025-09-05T12:30:11.4504598Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4504828Z             spark_session,
2025-09-05T12:30:11.4505054Z             table_name,
2025-09-05T12:30:11.4505283Z             schema_name="dq",
2025-09-05T12:30:11.4505522Z             run_month="",
2025-09-05T12:30:11.4505750Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4505972Z             local=True,
2025-09-05T12:30:11.4506176Z         )
2025-09-05T12:30:11.4506396Z     
2025-09-05T12:30:11.4506646Z >       assert dq_validation.not_null().get("result", None) == validation_output
2025-09-05T12:30:11.4506919Z E       AssertionError: assert None == True
2025-09-05T12:30:11.4507259Z E        +  where None = <built-in method get of dict object at 0x7fe8a43b8a80>('result', None)
2025-09-05T12:30:11.4507566Z E        +    where <built-in method get of dict object at 0x7fe8a43b8a80> = {}.get
2025-09-05T12:30:11.4507828Z E        +      where {} = not_null()
2025-09-05T12:30:11.4508114Z E        +        where not_null = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a428dd50>.not_null
2025-09-05T12:30:11.4508246Z 
2025-09-05T12:30:11.4508504Z test/test_dq/test_dq_validation.py:311: AssertionError
2025-09-05T12:30:11.4508783Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4509115Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4509540Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4509864Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4510140Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4510426Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4510766Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4511116Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4511405Z _______ test_not_nulls[dq_test_unhappy_not_null-False-expected_logging2] _______
2025-09-05T12:30:11.4511530Z 
2025-09-05T12:30:11.4511772Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4512045Z main_data = ('dq_test_unhappy_not_null', None), reference_data = None
2025-09-05T12:30:11.4512300Z validation_output = False
2025-09-05T12:30:11.4512557Z expected_logging = ["Nulls found in not nullable column(s): ['Type']"]
2025-09-05T12:30:11.4512820Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a425a910>
2025-09-05T12:30:11.4512926Z 
2025-09-05T12:30:11.4513143Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4513467Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4513692Z         [
2025-09-05T12:30:11.4513897Z             (
2025-09-05T12:30:11.4514117Z                 "dq_test_happy",
2025-09-05T12:30:11.4514347Z                 True,
2025-09-05T12:30:11.4514578Z                 ["No nulls found in ['PK1']"],
2025-09-05T12:30:11.4514797Z             ),
2025-09-05T12:30:11.4515007Z             (
2025-09-05T12:30:11.4515238Z                 "dq_test_no_check",
2025-09-05T12:30:11.4515465Z                 None,
2025-09-05T12:30:11.4515696Z                 ["No not nullable columns to check"],
2025-09-05T12:30:11.4515924Z             ),
2025-09-05T12:30:11.4516137Z             (
2025-09-05T12:30:11.4516365Z                 "dq_test_unhappy_not_null",
2025-09-05T12:30:11.4516589Z                 False,
2025-09-05T12:30:11.4516829Z                 ["Nulls found in not nullable column(s): ['Type']"],
2025-09-05T12:30:11.4517060Z             ),
2025-09-05T12:30:11.4517274Z         ],
2025-09-05T12:30:11.4517494Z         indirect=["main_data"],
2025-09-05T12:30:11.4517707Z     )
2025-09-05T12:30:11.4517926Z     def test_not_nulls(
2025-09-05T12:30:11.4518147Z         spark_session,
2025-09-05T12:30:11.4518364Z         main_data,
2025-09-05T12:30:11.4518582Z         reference_data,
2025-09-05T12:30:11.4518810Z         validation_output,
2025-09-05T12:30:11.4519032Z         expected_logging,
2025-09-05T12:30:11.4519246Z         caplog,
2025-09-05T12:30:11.4519448Z     ):
2025-09-05T12:30:11.4519673Z         """Test not nullable columns for a given table"""
2025-09-05T12:30:11.4519966Z     
2025-09-05T12:30:11.4520184Z         table_name = main_data[0]
2025-09-05T12:30:11.4520391Z     
2025-09-05T12:30:11.4520611Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4520845Z             spark_session,
2025-09-05T12:30:11.4521060Z             table_name,
2025-09-05T12:30:11.4521284Z             schema_name="dq",
2025-09-05T12:30:11.4521500Z             run_month="",
2025-09-05T12:30:11.4521731Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4521948Z             local=True,
2025-09-05T12:30:11.4522144Z         )
2025-09-05T12:30:11.4522339Z     
2025-09-05T12:30:11.4522585Z >       assert dq_validation.not_null().get("result", None) == validation_output
2025-09-05T12:30:11.4522847Z E       AssertionError: assert None == False
2025-09-05T12:30:11.4523120Z E        +  where None = <built-in method get of dict object at 0x7fe8a411a080>('result', None)
2025-09-05T12:30:11.4523547Z E        +    where <built-in method get of dict object at 0x7fe8a411a080> = {}.get
2025-09-05T12:30:11.4523803Z E        +      where {} = not_null()
2025-09-05T12:30:11.4524078Z E        +        where not_null = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a425a810>.not_null
2025-09-05T12:30:11.4524209Z 
2025-09-05T12:30:11.4524455Z test/test_dq/test_dq_validation.py:311: AssertionError
2025-09-05T12:30:11.4524745Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4525090Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_not_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_not_null.yml
2025-09-05T12:30:11.4525502Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_not_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_not_null.yml
2025-09-05T12:30:11.4525848Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4526440Z 2025-09-05 12:29:14 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4526731Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4527097Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_not_null at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_not_null.yml
2025-09-05T12:30:11.4527468Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4527768Z _______ test_referential_integrity[dq_test_happy-True-expected_logging0] _______
2025-09-05T12:30:11.4527897Z 
2025-09-05T12:30:11.4528148Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4528422Z main_data = ('dq_test_happy', None), reference_data = None
2025-09-05T12:30:11.4528670Z validation_output = True
2025-09-05T12:30:11.4528968Z expected_logging = ["Referential check successful, all values from Type with filter 'Type is not null' are present in reference.Lookup1"]
2025-09-05T12:30:11.4529281Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a42d0590>
2025-09-05T12:30:11.4529393Z 
2025-09-05T12:30:11.4529603Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4529853Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4530080Z         [
2025-09-05T12:30:11.4530278Z             (
2025-09-05T12:30:11.4530491Z                 "dq_test_happy",
2025-09-05T12:30:11.4530704Z                 True,
2025-09-05T12:30:11.4530917Z                 [
2025-09-05T12:30:11.4531153Z                     "Referential check successful, all values from Type "
2025-09-05T12:30:11.4531418Z                     "with filter 'Type is not null' are present in reference.Lookup1"
2025-09-05T12:30:11.4531661Z                 ],
2025-09-05T12:30:11.4531864Z             ),
2025-09-05T12:30:11.4532062Z             (
2025-09-05T12:30:11.4532279Z                 "dq_test_no_check",
2025-09-05T12:30:11.4532502Z                 None,
2025-09-05T12:30:11.4532795Z                 ["No referential integrity checks"],
2025-09-05T12:30:11.4533014Z             ),
2025-09-05T12:30:11.4533216Z             (
2025-09-05T12:30:11.4533501Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4533734Z                 False,
2025-09-05T12:30:11.4533947Z                 [
2025-09-05T12:30:11.4534189Z                     "Referential check failed, not all values from Type "
2025-09-05T12:30:11.4534467Z                     "with filter 'Type is not null' are present in reference.Lookup2\n"
2025-09-05T12:30:11.4534733Z                     "1 values not available: ['B']"
2025-09-05T12:30:11.4534956Z                 ],
2025-09-05T12:30:11.4535164Z             ),
2025-09-05T12:30:11.4535378Z             (
2025-09-05T12:30:11.4535607Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4535882Z                 False,
2025-09-05T12:30:11.4536094Z                 [
2025-09-05T12:30:11.4536374Z                     "Referential check failed, not all values from Type are present in reference.Lookup1\n1 values not available: [None]"  # noqa: E501
2025-09-05T12:30:11.4536639Z                 ],
2025-09-05T12:30:11.4536839Z             ),
2025-09-05T12:30:11.4537043Z         ],
2025-09-05T12:30:11.4537286Z         indirect=["main_data"],
2025-09-05T12:30:11.4537494Z     )
2025-09-05T12:30:11.4537712Z     def test_referential_integrity(
2025-09-05T12:30:11.4537936Z         spark_session,
2025-09-05T12:30:11.4538160Z         main_data,
2025-09-05T12:30:11.4538371Z         reference_data,
2025-09-05T12:30:11.4538592Z         validation_output,
2025-09-05T12:30:11.4538811Z         expected_logging,
2025-09-05T12:30:11.4539028Z         caplog,
2025-09-05T12:30:11.4539231Z     ):
2025-09-05T12:30:11.4539459Z         """Test referential integrity for a given table"""
2025-09-05T12:30:11.4539677Z     
2025-09-05T12:30:11.4539899Z         table_name = main_data[0]
2025-09-05T12:30:11.4540105Z     
2025-09-05T12:30:11.4540325Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4540555Z             spark_session,
2025-09-05T12:30:11.4540773Z             table_name,
2025-09-05T12:30:11.4541001Z             schema_name="dq",
2025-09-05T12:30:11.4541223Z             run_month="",
2025-09-05T12:30:11.4541447Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4541667Z             local=True,
2025-09-05T12:30:11.4541873Z         )
2025-09-05T12:30:11.4542071Z     
2025-09-05T12:30:11.4542279Z >       assert (
2025-09-05T12:30:11.4542533Z             dq_validation.referential_integrity().get("result", None) == validation_output
2025-09-05T12:30:11.4542780Z         )
2025-09-05T12:30:11.4543007Z E       AssertionError: assert None == True
2025-09-05T12:30:11.4543273Z E        +  where None = <built-in method get of dict object at 0x7fe8a4380a40>('result', None)
2025-09-05T12:30:11.4543674Z E        +    where <built-in method get of dict object at 0x7fe8a4380a40> = {}.get
2025-09-05T12:30:11.4543941Z E        +      where {} = referential_integrity()
2025-09-05T12:30:11.4544241Z E        +        where referential_integrity = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a41b1250>.referential_integrity
2025-09-05T12:30:11.4544385Z 
2025-09-05T12:30:11.4544637Z test/test_dq/test_dq_validation.py:371: AssertionError
2025-09-05T12:30:11.4544925Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4545259Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4545636Z 2025-09-05 12:29:14 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4545978Z 2025-09-05 12:29:14 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4546275Z 2025-09-05 12:29:14 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4546649Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4547016Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4547377Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4547680Z ___ test_referential_integrity[dq_test_unhappy_ref-False-expected_logging2] ____
2025-09-05T12:30:11.4547798Z 
2025-09-05T12:30:11.4548059Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4548341Z main_data = ('dq_test_unhappy_ref', None), reference_data = None
2025-09-05T12:30:11.4548600Z validation_output = False
2025-09-05T12:30:11.4548932Z expected_logging = ["Referential check failed, not all values from Type with filter 'Type is not null' are present in reference.Lookup2\n1 values not available: ['B']"]
2025-09-05T12:30:11.4549259Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a421a650>
2025-09-05T12:30:11.4549369Z 
2025-09-05T12:30:11.4549583Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4549823Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4550050Z         [
2025-09-05T12:30:11.4550250Z             (
2025-09-05T12:30:11.4550456Z                 "dq_test_happy",
2025-09-05T12:30:11.4550670Z                 True,
2025-09-05T12:30:11.4550881Z                 [
2025-09-05T12:30:11.4551115Z                     "Referential check successful, all values from Type "
2025-09-05T12:30:11.4551375Z                     "with filter 'Type is not null' are present in reference.Lookup1"
2025-09-05T12:30:11.4551613Z                 ],
2025-09-05T12:30:11.4551810Z             ),
2025-09-05T12:30:11.4552012Z             (
2025-09-05T12:30:11.4552230Z                 "dq_test_no_check",
2025-09-05T12:30:11.4552448Z                 None,
2025-09-05T12:30:11.4552689Z                 ["No referential integrity checks"],
2025-09-05T12:30:11.4552907Z             ),
2025-09-05T12:30:11.4553106Z             (
2025-09-05T12:30:11.4553327Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4553621Z                 False,
2025-09-05T12:30:11.4553831Z                 [
2025-09-05T12:30:11.4554077Z                     "Referential check failed, not all values from Type "
2025-09-05T12:30:11.4554341Z                     "with filter 'Type is not null' are present in reference.Lookup2\n"
2025-09-05T12:30:11.4554613Z                     "1 values not available: ['B']"
2025-09-05T12:30:11.4554830Z                 ],
2025-09-05T12:30:11.4555032Z             ),
2025-09-05T12:30:11.4555243Z             (
2025-09-05T12:30:11.4555467Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4555701Z                 False,
2025-09-05T12:30:11.4555913Z                 [
2025-09-05T12:30:11.4556199Z                     "Referential check failed, not all values from Type are present in reference.Lookup1\n1 values not available: [None]"  # noqa: E501
2025-09-05T12:30:11.4556462Z                 ],
2025-09-05T12:30:11.4556665Z             ),
2025-09-05T12:30:11.4556866Z         ],
2025-09-05T12:30:11.4557097Z         indirect=["main_data"],
2025-09-05T12:30:11.4557309Z     )
2025-09-05T12:30:11.4557531Z     def test_referential_integrity(
2025-09-05T12:30:11.4557758Z         spark_session,
2025-09-05T12:30:11.4557974Z         main_data,
2025-09-05T12:30:11.4558187Z         reference_data,
2025-09-05T12:30:11.4558407Z         validation_output,
2025-09-05T12:30:11.4558629Z         expected_logging,
2025-09-05T12:30:11.4558850Z         caplog,
2025-09-05T12:30:11.4559055Z     ):
2025-09-05T12:30:11.4559289Z         """Test referential integrity for a given table"""
2025-09-05T12:30:11.4559510Z     
2025-09-05T12:30:11.4559727Z         table_name = main_data[0]
2025-09-05T12:30:11.4559940Z     
2025-09-05T12:30:11.4560154Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4560446Z             spark_session,
2025-09-05T12:30:11.4560664Z             table_name,
2025-09-05T12:30:11.4560888Z             schema_name="dq",
2025-09-05T12:30:11.4561105Z             run_month="",
2025-09-05T12:30:11.4561331Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4561555Z             local=True,
2025-09-05T12:30:11.4561768Z         )
2025-09-05T12:30:11.4561964Z     
2025-09-05T12:30:11.4562174Z >       assert (
2025-09-05T12:30:11.4562437Z             dq_validation.referential_integrity().get("result", None) == validation_output
2025-09-05T12:30:11.4562691Z         )
2025-09-05T12:30:11.4562920Z E       AssertionError: assert None == False
2025-09-05T12:30:11.4563192Z E        +  where None = <built-in method get of dict object at 0x7fe8a439d1c0>('result', None)
2025-09-05T12:30:11.4563576Z E        +    where <built-in method get of dict object at 0x7fe8a439d1c0> = {}.get
2025-09-05T12:30:11.4563912Z E        +      where {} = referential_integrity()
2025-09-05T12:30:11.4564212Z E        +        where referential_integrity = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a439ca50>.referential_integrity
2025-09-05T12:30:11.4564465Z 
2025-09-05T12:30:11.4564791Z test/test_dq/test_dq_validation.py:371: AssertionError
2025-09-05T12:30:11.4565224Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4565568Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_ref at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref.yml
2025-09-05T12:30:11.4565958Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_ref at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref.yml
2025-09-05T12:30:11.4566306Z 2025-09-05 12:29:15 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4566600Z 2025-09-05 12:29:15 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4566892Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4567251Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_ref at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref.yml
2025-09-05T12:30:11.4567603Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4567899Z _ test_referential_integrity[dq_test_unhappy_ref_filter-False-expected_logging3] _
2025-09-05T12:30:11.4568015Z 
2025-09-05T12:30:11.4568264Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4568545Z main_data = ('dq_test_unhappy_ref_filter', None), reference_data = None
2025-09-05T12:30:11.4568797Z validation_output = False
2025-09-05T12:30:11.4569085Z expected_logging = ['Referential check failed, not all values from Type are present in reference.Lookup1\n1 values not available: [None]']
2025-09-05T12:30:11.4569395Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a425ad50>
2025-09-05T12:30:11.4569506Z 
2025-09-05T12:30:11.4569720Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4569965Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4570192Z         [
2025-09-05T12:30:11.4570387Z             (
2025-09-05T12:30:11.4570599Z                 "dq_test_happy",
2025-09-05T12:30:11.4570810Z                 True,
2025-09-05T12:30:11.4571022Z                 [
2025-09-05T12:30:11.4571255Z                     "Referential check successful, all values from Type "
2025-09-05T12:30:11.4571521Z                     "with filter 'Type is not null' are present in reference.Lookup1"
2025-09-05T12:30:11.4571767Z                 ],
2025-09-05T12:30:11.4571973Z             ),
2025-09-05T12:30:11.4572173Z             (
2025-09-05T12:30:11.4572386Z                 "dq_test_no_check",
2025-09-05T12:30:11.4572601Z                 None,
2025-09-05T12:30:11.4572850Z                 ["No referential integrity checks"],
2025-09-05T12:30:11.4573204Z             ),
2025-09-05T12:30:11.4573472Z             (
2025-09-05T12:30:11.4573692Z                 "dq_test_unhappy_ref",
2025-09-05T12:30:11.4573924Z                 False,
2025-09-05T12:30:11.4574136Z                 [
2025-09-05T12:30:11.4574377Z                     "Referential check failed, not all values from Type "
2025-09-05T12:30:11.4574646Z                     "with filter 'Type is not null' are present in reference.Lookup2\n"
2025-09-05T12:30:11.4574913Z                     "1 values not available: ['B']"
2025-09-05T12:30:11.4575136Z                 ],
2025-09-05T12:30:11.4575343Z             ),
2025-09-05T12:30:11.4575553Z             (
2025-09-05T12:30:11.4575773Z                 "dq_test_unhappy_ref_filter",
2025-09-05T12:30:11.4575995Z                 False,
2025-09-05T12:30:11.4576250Z                 [
2025-09-05T12:30:11.4576543Z                     "Referential check failed, not all values from Type are present in reference.Lookup1\n1 values not available: [None]"  # noqa: E501
2025-09-05T12:30:11.4576815Z                 ],
2025-09-05T12:30:11.4577019Z             ),
2025-09-05T12:30:11.4577229Z         ],
2025-09-05T12:30:11.4577464Z         indirect=["main_data"],
2025-09-05T12:30:11.4577675Z     )
2025-09-05T12:30:11.4577902Z     def test_referential_integrity(
2025-09-05T12:30:11.4578126Z         spark_session,
2025-09-05T12:30:11.4578344Z         main_data,
2025-09-05T12:30:11.4578557Z         reference_data,
2025-09-05T12:30:11.4578780Z         validation_output,
2025-09-05T12:30:11.4579006Z         expected_logging,
2025-09-05T12:30:11.4579217Z         caplog,
2025-09-05T12:30:11.4579428Z     ):
2025-09-05T12:30:11.4579654Z         """Test referential integrity for a given table"""
2025-09-05T12:30:11.4579872Z     
2025-09-05T12:30:11.4580084Z         table_name = main_data[0]
2025-09-05T12:30:11.4580302Z     
2025-09-05T12:30:11.4580519Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4580755Z             spark_session,
2025-09-05T12:30:11.4580971Z             table_name,
2025-09-05T12:30:11.4581201Z             schema_name="dq",
2025-09-05T12:30:11.4581424Z             run_month="",
2025-09-05T12:30:11.4581651Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4581872Z             local=True,
2025-09-05T12:30:11.4582087Z         )
2025-09-05T12:30:11.4582287Z     
2025-09-05T12:30:11.4582496Z >       assert (
2025-09-05T12:30:11.4582752Z             dq_validation.referential_integrity().get("result", None) == validation_output
2025-09-05T12:30:11.4582998Z         )
2025-09-05T12:30:11.4583228Z E       AssertionError: assert None == False
2025-09-05T12:30:11.4583595Z E        +  where None = <built-in method get of dict object at 0x7fe8a42187c0>('result', None)
2025-09-05T12:30:11.4583879Z E        +    where <built-in method get of dict object at 0x7fe8a42187c0> = {}.get
2025-09-05T12:30:11.4584159Z E        +      where {} = referential_integrity()
2025-09-05T12:30:11.4584453Z E        +        where referential_integrity = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a529a250>.referential_integrity
2025-09-05T12:30:11.4584597Z 
2025-09-05T12:30:11.4584835Z test/test_dq/test_dq_validation.py:371: AssertionError
2025-09-05T12:30:11.4585125Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4585476Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_ref_filter at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref_filter.yml
2025-09-05T12:30:11.4585875Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_ref_filter at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref_filter.yml
2025-09-05T12:30:11.4586233Z 2025-09-05 12:29:15 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4586534Z 2025-09-05 12:29:15 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4586882Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4587266Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_ref_filter at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_ref_filter.yml
2025-09-05T12:30:11.4587637Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4587932Z ______________ test_unique[dq_test_happy-True-expected_logging0] _______________
2025-09-05T12:30:11.4588043Z 
2025-09-05T12:30:11.4588376Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4588744Z main_data = ('dq_test_happy', None), validation_output = True
2025-09-05T12:30:11.4589080Z expected_logging = ["['PK2'] is unique"]
2025-09-05T12:30:11.4589591Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a4404cd0>
2025-09-05T12:30:11.4589772Z 
2025-09-05T12:30:11.4590095Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4590338Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4590557Z         [
2025-09-05T12:30:11.4590762Z             (
2025-09-05T12:30:11.4590971Z                 "dq_test_happy",
2025-09-05T12:30:11.4591186Z                 True,
2025-09-05T12:30:11.4591408Z                 ["['PK2'] is unique"],
2025-09-05T12:30:11.4591627Z             ),
2025-09-05T12:30:11.4591832Z             (
2025-09-05T12:30:11.4592048Z                 "dq_test_no_check",
2025-09-05T12:30:11.4592263Z                 None,
2025-09-05T12:30:11.4592497Z                 ["No unique columns to check"],
2025-09-05T12:30:11.4592714Z             ),
2025-09-05T12:30:11.4592916Z             (
2025-09-05T12:30:11.4593136Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4593443Z                 False,
2025-09-05T12:30:11.4593697Z                 ["Duplicates found in ['PK1']: [Row(PK1=2, count=2)]", "['PK2'] is unique"],
2025-09-05T12:30:11.4593939Z             ),
2025-09-05T12:30:11.4594144Z         ],
2025-09-05T12:30:11.4594378Z         indirect=["main_data"],
2025-09-05T12:30:11.4594595Z     )
2025-09-05T12:30:11.4594812Z     def test_unique(
2025-09-05T12:30:11.4595035Z         spark_session,
2025-09-05T12:30:11.4595260Z         main_data,
2025-09-05T12:30:11.4595484Z         validation_output,
2025-09-05T12:30:11.4595711Z         expected_logging,
2025-09-05T12:30:11.4595925Z         caplog,
2025-09-05T12:30:11.4596132Z     ):
2025-09-05T12:30:11.4596364Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4596583Z     
2025-09-05T12:30:11.4596802Z         table_name = main_data[0]
2025-09-05T12:30:11.4597023Z     
2025-09-05T12:30:11.4597248Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4597478Z             spark_session,
2025-09-05T12:30:11.4597700Z             table_name,
2025-09-05T12:30:11.4597928Z             schema_name="dq",
2025-09-05T12:30:11.4598157Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4598384Z             run_month="",
2025-09-05T12:30:11.4598599Z             local=True,
2025-09-05T12:30:11.4598798Z         )
2025-09-05T12:30:11.4599003Z     
2025-09-05T12:30:11.4599207Z >       assert (
2025-09-05T12:30:11.4599464Z             dq_validation.unique(individual=True).get("result", None) == validation_output
2025-09-05T12:30:11.4599698Z         )
2025-09-05T12:30:11.4599930Z E       AssertionError: assert None == True
2025-09-05T12:30:11.4600197Z E        +  where None = <built-in method get of dict object at 0x7fe8a4276100>('result', None)
2025-09-05T12:30:11.4600481Z E        +    where <built-in method get of dict object at 0x7fe8a4276100> = {}.get
2025-09-05T12:30:11.4600744Z E        +      where {} = unique(individual=True)
2025-09-05T12:30:11.4601017Z E        +        where unique = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a42d5510>.unique
2025-09-05T12:30:11.4601146Z 
2025-09-05T12:30:11.4601392Z test/test_dq/test_dq_validation.py:418: AssertionError
2025-09-05T12:30:11.4601796Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4602130Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4602507Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4602842Z 2025-09-05 12:29:15 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4603114Z 2025-09-05 12:29:15 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4603476Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4603866Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_happy.yml
2025-09-05T12:30:11.4604242Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4604535Z _________ test_unique[dq_test_unhappy_unique-False-expected_logging2] __________
2025-09-05T12:30:11.4604653Z 
2025-09-05T12:30:11.4604896Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4605183Z main_data = ('dq_test_unhappy_unique', None), validation_output = False
2025-09-05T12:30:11.4605466Z expected_logging = ["Duplicates found in ['PK1']: [Row(PK1=2, count=2)]", "['PK2'] is unique"]
2025-09-05T12:30:11.4605754Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a43adc50>
2025-09-05T12:30:11.4605864Z 
2025-09-05T12:30:11.4606089Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4606334Z         ("main_data", "validation_output", "expected_logging"),
2025-09-05T12:30:11.4606558Z         [
2025-09-05T12:30:11.4606761Z             (
2025-09-05T12:30:11.4606982Z                 "dq_test_happy",
2025-09-05T12:30:11.4607198Z                 True,
2025-09-05T12:30:11.4607420Z                 ["['PK2'] is unique"],
2025-09-05T12:30:11.4607632Z             ),
2025-09-05T12:30:11.4607844Z             (
2025-09-05T12:30:11.4608057Z                 "dq_test_no_check",
2025-09-05T12:30:11.4608273Z                 None,
2025-09-05T12:30:11.4608498Z                 ["No unique columns to check"],
2025-09-05T12:30:11.4608724Z             ),
2025-09-05T12:30:11.4608920Z             (
2025-09-05T12:30:11.4609137Z                 "dq_test_unhappy_unique",
2025-09-05T12:30:11.4609355Z                 False,
2025-09-05T12:30:11.4609609Z                 ["Duplicates found in ['PK1']: [Row(PK1=2, count=2)]", "['PK2'] is unique"],
2025-09-05T12:30:11.4609839Z             ),
2025-09-05T12:30:11.4610036Z         ],
2025-09-05T12:30:11.4610252Z         indirect=["main_data"],
2025-09-05T12:30:11.4610469Z     )
2025-09-05T12:30:11.4610684Z     def test_unique(
2025-09-05T12:30:11.4610903Z         spark_session,
2025-09-05T12:30:11.4611120Z         main_data,
2025-09-05T12:30:11.4611359Z         validation_output,
2025-09-05T12:30:11.4611587Z         expected_logging,
2025-09-05T12:30:11.4611801Z         caplog,
2025-09-05T12:30:11.4612002Z     ):
2025-09-05T12:30:11.4612247Z         """Test full DQ validation for a given table"""
2025-09-05T12:30:11.4612469Z     
2025-09-05T12:30:11.4612684Z         table_name = main_data[0]
2025-09-05T12:30:11.4612895Z     
2025-09-05T12:30:11.4613124Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4613352Z             spark_session,
2025-09-05T12:30:11.4613649Z             table_name,
2025-09-05T12:30:11.4613875Z             schema_name="dq",
2025-09-05T12:30:11.4614110Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4614359Z             run_month="",
2025-09-05T12:30:11.4614578Z             local=True,
2025-09-05T12:30:11.4614793Z         )
2025-09-05T12:30:11.4614993Z     
2025-09-05T12:30:11.4615213Z >       assert (
2025-09-05T12:30:11.4615471Z             dq_validation.unique(individual=True).get("result", None) == validation_output
2025-09-05T12:30:11.4615793Z         )
2025-09-05T12:30:11.4616027Z E       AssertionError: assert None == False
2025-09-05T12:30:11.4616322Z E        +  where None = <built-in method get of dict object at 0x7fe8a4509580>('result', None)
2025-09-05T12:30:11.4616605Z E        +    where <built-in method get of dict object at 0x7fe8a4509580> = {}.get
2025-09-05T12:30:11.4616877Z E        +      where {} = unique(individual=True)
2025-09-05T12:30:11.4617160Z E        +        where unique = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a4218e10>.unique
2025-09-05T12:30:11.4617285Z 
2025-09-05T12:30:11.4617525Z test/test_dq/test_dq_validation.py:418: AssertionError
2025-09-05T12:30:11.4617797Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4618195Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_unique at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_unique.yml
2025-09-05T12:30:11.4618590Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_unhappy_unique at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_unique.yml
2025-09-05T12:30:11.4618920Z 2025-09-05 12:29:15 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4619195Z 2025-09-05 12:29:15 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4619475Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4619831Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_unhappy_unique at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_unhappy_unique.yml
2025-09-05T12:30:11.4620191Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4620493Z _____________ test_generic_checks[dq_test_fr_happy-fr-log_range0] ______________
2025-09-05T12:30:11.4620612Z 
2025-09-05T12:30:11.4620853Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4621122Z main_data = ('dq_test_fr_happy', None), reference_data = None
2025-09-05T12:30:11.4621388Z source_system = 'fr', log_range = [2, 3, 4, 5, 6, 7, ...]
2025-09-05T12:30:11.4621652Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a4219650>
2025-09-05T12:30:11.4621759Z 
2025-09-05T12:30:11.4621972Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4622219Z         ("main_data", "source_system", "log_range"),
2025-09-05T12:30:11.4622439Z         [
2025-09-05T12:30:11.4622671Z             ("dq_test_fr_happy", "fr", [*list(range(2, 10)), 11]),
2025-09-05T12:30:11.4622938Z             ("dq_test_fr_no_generic", "fr", [*list(range(1, 9)), 10, 11]),
2025-09-05T12:30:11.4623229Z             ("dq_test_nospecific_happy", "nospecific", [0, *list(range(2, 9)), 10, 11]),
2025-09-05T12:30:11.4623568Z         ],
2025-09-05T12:30:11.4623802Z         indirect=["main_data"],
2025-09-05T12:30:11.4624016Z     )
2025-09-05T12:30:11.4624257Z     def test_generic_checks(
2025-09-05T12:30:11.4624527Z         spark_session, main_data, reference_data, source_system, log_range, caplog
2025-09-05T12:30:11.4624768Z     ):
2025-09-05T12:30:11.4624994Z         table_name = main_data[0]
2025-09-05T12:30:11.4625215Z     
2025-09-05T12:30:11.4625425Z         log = [
2025-09-05T12:30:11.4625659Z             "No specific checks file available for "
2025-09-05T12:30:11.4625905Z             "dq.dq_test_nospecific_happy at "
2025-09-05T12:30:11.4626134Z             + str(
2025-09-05T12:30:11.4626347Z                 Path(
2025-09-05T12:30:11.4626571Z                     MAPPING_ROOT_DIR
2025-09-05T12:30:11.4626785Z                     / "test"
2025-09-05T12:30:11.4627006Z                     / "data"
2025-09-05T12:30:11.4627218Z                     / "dq"
2025-09-05T12:30:11.4627450Z                     / "dq_test_nospecific_happy.yml"
2025-09-05T12:30:11.4627664Z                 )
2025-09-05T12:30:11.4627925Z             ),
2025-09-05T12:30:11.4628151Z             "No generic checks file available for "
2025-09-05T12:30:11.4628386Z             "dq.dq_test_fr_no_generic at "
2025-09-05T12:30:11.4628609Z             + str(
2025-09-05T12:30:11.4628831Z                 Path(
2025-09-05T12:30:11.4629074Z                     MAPPING_ROOT_DIR / "test" / "data" / "dq" / "dq_test_[]_no_generic.yml"
2025-09-05T12:30:11.4629312Z                 )
2025-09-05T12:30:11.4629515Z             ),
2025-09-05T12:30:11.4629757Z             "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4629994Z             "Datatypes match",
2025-09-05T12:30:11.4630222Z             "['PK1', 'PK2'] is unique",
2025-09-05T12:30:11.4630453Z             "No nulls found in ['PK1', 'PK2']",
2025-09-05T12:30:11.4630748Z             "Primary key ['PK1', 'PK2'] validated successfully",
2025-09-05T12:30:11.4630990Z             "No nulls found in ['PK1']",
2025-09-05T12:30:11.4631217Z             "['PK2'] is unique",
2025-09-05T12:30:11.4631460Z             "Referential check successful, "
2025-09-05T12:30:11.4631709Z             "all values from Type with filter 'Type is not null' "
2025-09-05T12:30:11.4631957Z             "are present in reference.Lookup1",
2025-09-05T12:30:11.4632199Z             "No referential integrity checks",
2025-09-05T12:30:11.4632445Z             "Checks completed successfully",
2025-09-05T12:30:11.4632658Z         ]
2025-09-05T12:30:11.4632856Z     
2025-09-05T12:30:11.4633079Z         log = [log[i] for i in log_range]
2025-09-05T12:30:11.4633302Z     
2025-09-05T12:30:11.4633595Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4633829Z             spark_session,
2025-09-05T12:30:11.4634050Z             table_name,
2025-09-05T12:30:11.4634279Z             schema_name="dq",
2025-09-05T12:30:11.4634518Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4634752Z             run_month="",
2025-09-05T12:30:11.4634983Z             source_system=source_system,
2025-09-05T12:30:11.4635235Z             local=True,
2025-09-05T12:30:11.4635446Z         )
2025-09-05T12:30:11.4635645Z     
2025-09-05T12:30:11.4635876Z >       assert dq_validation.checks(functional=True)
2025-09-05T12:30:11.4636114Z E       assert None
2025-09-05T12:30:11.4636351Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4636633Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a421a9d0>.checks
2025-09-05T12:30:11.4636759Z 
2025-09-05T12:30:11.4636996Z test/test_dq/test_dq_validation.py:483: AssertionError
2025-09-05T12:30:11.4637287Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4637617Z 2025-09-05 12:29:15 [INFO] __init__:  No generic checks file available for dq.dq_test_fr_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_[]_happy.yml
2025-09-05T12:30:11.4637996Z 2025-09-05 12:29:15 [INFO] __init__:  No generic checks file available for dq.dq_test_fr_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_[]_happy.yml
2025-09-05T12:30:11.4638390Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_fr_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_fr_happy.yml
2025-09-05T12:30:11.4638770Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_fr_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_fr_happy.yml
2025-09-05T12:30:11.4639092Z 2025-09-05 12:29:15 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4639375Z 2025-09-05 12:29:15 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4639647Z 2025-09-05 12:29:15 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4639912Z 2025-09-05 12:29:15 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4640192Z 2025-09-05 12:29:15 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4640511Z 2025-09-05 12:29:15 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4640784Z 2025-09-05 12:29:15 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4641057Z 2025-09-05 12:29:15 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4641350Z 2025-09-05 12:29:15 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4641649Z 2025-09-05 12:29:15 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4641921Z 2025-09-05 12:29:15 [INFO] checks:  No checks done
2025-09-05T12:30:11.4642178Z 2025-09-05 12:29:15 [INFO] checks:  No checks done
2025-09-05T12:30:11.4642458Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4642807Z INFO     betl_src_poc_logger:dq_validation.py:71 No generic checks file available for dq.dq_test_fr_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_[]_happy.yml
2025-09-05T12:30:11.4643247Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_fr_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_fr_happy.yml
2025-09-05T12:30:11.4643842Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4644144Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4644446Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4644749Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4645044Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4645332Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4645617Z ___________ test_generic_checks[dq_test_fr_no_generic-fr-log_range1] ___________
2025-09-05T12:30:11.4645742Z 
2025-09-05T12:30:11.4645984Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4646268Z main_data = ('dq_test_fr_no_generic', None), reference_data = None
2025-09-05T12:30:11.4646538Z source_system = 'fr', log_range = [1, 2, 3, 4, 5, 6, ...]
2025-09-05T12:30:11.4646811Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a4254350>
2025-09-05T12:30:11.4646918Z 
2025-09-05T12:30:11.4647140Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4647381Z         ("main_data", "source_system", "log_range"),
2025-09-05T12:30:11.4647607Z         [
2025-09-05T12:30:11.4647841Z             ("dq_test_fr_happy", "fr", [*list(range(2, 10)), 11]),
2025-09-05T12:30:11.4648101Z             ("dq_test_fr_no_generic", "fr", [*list(range(1, 9)), 10, 11]),
2025-09-05T12:30:11.4648367Z             ("dq_test_nospecific_happy", "nospecific", [0, *list(range(2, 9)), 10, 11]),
2025-09-05T12:30:11.4648616Z         ],
2025-09-05T12:30:11.4648833Z         indirect=["main_data"],
2025-09-05T12:30:11.4649041Z     )
2025-09-05T12:30:11.4649268Z     def test_generic_checks(
2025-09-05T12:30:11.4649538Z         spark_session, main_data, reference_data, source_system, log_range, caplog
2025-09-05T12:30:11.4649769Z     ):
2025-09-05T12:30:11.4649981Z         table_name = main_data[0]
2025-09-05T12:30:11.4650191Z     
2025-09-05T12:30:11.4650402Z         log = [
2025-09-05T12:30:11.4650628Z             "No specific checks file available for "
2025-09-05T12:30:11.4650865Z             "dq.dq_test_nospecific_happy at "
2025-09-05T12:30:11.4651086Z             + str(
2025-09-05T12:30:11.4651302Z                 Path(
2025-09-05T12:30:11.4651518Z                     MAPPING_ROOT_DIR
2025-09-05T12:30:11.4651735Z                     / "test"
2025-09-05T12:30:11.4651946Z                     / "data"
2025-09-05T12:30:11.4652163Z                     / "dq"
2025-09-05T12:30:11.4652390Z                     / "dq_test_nospecific_happy.yml"
2025-09-05T12:30:11.4652612Z                 )
2025-09-05T12:30:11.4652815Z             ),
2025-09-05T12:30:11.4653050Z             "No generic checks file available for "
2025-09-05T12:30:11.4653451Z             "dq.dq_test_fr_no_generic at "
2025-09-05T12:30:11.4653678Z             + str(
2025-09-05T12:30:11.4653898Z                 Path(
2025-09-05T12:30:11.4654152Z                     MAPPING_ROOT_DIR / "test" / "data" / "dq" / "dq_test_[]_no_generic.yml"
2025-09-05T12:30:11.4654391Z                 )
2025-09-05T12:30:11.4654597Z             ),
2025-09-05T12:30:11.4654836Z             "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4655085Z             "Datatypes match",
2025-09-05T12:30:11.4655320Z             "['PK1', 'PK2'] is unique",
2025-09-05T12:30:11.4655553Z             "No nulls found in ['PK1', 'PK2']",
2025-09-05T12:30:11.4655806Z             "Primary key ['PK1', 'PK2'] validated successfully",
2025-09-05T12:30:11.4656055Z             "No nulls found in ['PK1']",
2025-09-05T12:30:11.4656335Z             "['PK2'] is unique",
2025-09-05T12:30:11.4656576Z             "Referential check successful, "
2025-09-05T12:30:11.4656826Z             "all values from Type with filter 'Type is not null' "
2025-09-05T12:30:11.4657086Z             "are present in reference.Lookup1",
2025-09-05T12:30:11.4657326Z             "No referential integrity checks",
2025-09-05T12:30:11.4657574Z             "Checks completed successfully",
2025-09-05T12:30:11.4657800Z         ]
2025-09-05T12:30:11.4657998Z     
2025-09-05T12:30:11.4658216Z         log = [log[i] for i in log_range]
2025-09-05T12:30:11.4658423Z     
2025-09-05T12:30:11.4658638Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4658874Z             spark_session,
2025-09-05T12:30:11.4659091Z             table_name,
2025-09-05T12:30:11.4659311Z             schema_name="dq",
2025-09-05T12:30:11.4659538Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4659771Z             run_month="",
2025-09-05T12:30:11.4660007Z             source_system=source_system,
2025-09-05T12:30:11.4660231Z             local=True,
2025-09-05T12:30:11.4660433Z         )
2025-09-05T12:30:11.4660639Z     
2025-09-05T12:30:11.4660873Z >       assert dq_validation.checks(functional=True)
2025-09-05T12:30:11.4661107Z E       assert None
2025-09-05T12:30:11.4661344Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4661637Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe89f72a0d0>.checks
2025-09-05T12:30:11.4661766Z 
2025-09-05T12:30:11.4662006Z test/test_dq/test_dq_validation.py:483: AssertionError
2025-09-05T12:30:11.4662289Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4662646Z 2025-09-05 12:29:15 [INFO] __init__:  No generic checks file available for dq.dq_test_fr_no_generic at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_[]_no_generic.yml
2025-09-05T12:30:11.4663038Z 2025-09-05 12:29:15 [INFO] __init__:  No generic checks file available for dq.dq_test_fr_no_generic at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_[]_no_generic.yml
2025-09-05T12:30:11.4663525Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_fr_no_generic at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_fr_no_generic.yml
2025-09-05T12:30:11.4663933Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_fr_no_generic at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_fr_no_generic.yml
2025-09-05T12:30:11.4664271Z 2025-09-05 12:29:15 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4664545Z 2025-09-05 12:29:15 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4664834Z 2025-09-05 12:29:15 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4665102Z 2025-09-05 12:29:15 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4665379Z 2025-09-05 12:29:15 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4665673Z 2025-09-05 12:29:15 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4666021Z 2025-09-05 12:29:15 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4666299Z 2025-09-05 12:29:15 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4666592Z 2025-09-05 12:29:15 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4666912Z 2025-09-05 12:29:15 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4667198Z 2025-09-05 12:29:15 [INFO] checks:  No checks done
2025-09-05T12:30:11.4667462Z 2025-09-05 12:29:15 [INFO] checks:  No checks done
2025-09-05T12:30:11.4667747Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4668117Z INFO     betl_src_poc_logger:dq_validation.py:71 No generic checks file available for dq.dq_test_fr_no_generic at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_[]_no_generic.yml
2025-09-05T12:30:11.4668588Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_fr_no_generic at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_fr_no_generic.yml
2025-09-05T12:30:11.4668943Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4669244Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4669534Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4669825Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4670129Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4670416Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4670704Z _____ test_generic_checks[dq_test_nospecific_happy-nospecific-log_range2] ______
2025-09-05T12:30:11.4670818Z 
2025-09-05T12:30:11.4671067Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4671344Z main_data = ('dq_test_nospecific_happy', None), reference_data = None
2025-09-05T12:30:11.4671614Z source_system = 'nospecific', log_range = [0, 2, 3, 4, 5, 6, ...]
2025-09-05T12:30:11.4671877Z caplog = <_pytest.logging.LogCaptureFixture object at 0x7fe8a44e8ed0>
2025-09-05T12:30:11.4671987Z 
2025-09-05T12:30:11.4672200Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4672442Z         ("main_data", "source_system", "log_range"),
2025-09-05T12:30:11.4672659Z         [
2025-09-05T12:30:11.4672902Z             ("dq_test_fr_happy", "fr", [*list(range(2, 10)), 11]),
2025-09-05T12:30:11.4673159Z             ("dq_test_fr_no_generic", "fr", [*list(range(1, 9)), 10, 11]),
2025-09-05T12:30:11.4673507Z             ("dq_test_nospecific_happy", "nospecific", [0, *list(range(2, 9)), 10, 11]),
2025-09-05T12:30:11.4673748Z         ],
2025-09-05T12:30:11.4673981Z         indirect=["main_data"],
2025-09-05T12:30:11.4674199Z     )
2025-09-05T12:30:11.4674423Z     def test_generic_checks(
2025-09-05T12:30:11.4674687Z         spark_session, main_data, reference_data, source_system, log_range, caplog
2025-09-05T12:30:11.4674938Z     ):
2025-09-05T12:30:11.4675158Z         table_name = main_data[0]
2025-09-05T12:30:11.4675371Z     
2025-09-05T12:30:11.4675576Z         log = [
2025-09-05T12:30:11.4675820Z             "No specific checks file available for "
2025-09-05T12:30:11.4676067Z             "dq.dq_test_nospecific_happy at "
2025-09-05T12:30:11.4676292Z             + str(
2025-09-05T12:30:11.4676504Z                 Path(
2025-09-05T12:30:11.4676736Z                     MAPPING_ROOT_DIR
2025-09-05T12:30:11.4676960Z                     / "test"
2025-09-05T12:30:11.4677176Z                     / "data"
2025-09-05T12:30:11.4677389Z                     / "dq"
2025-09-05T12:30:11.4677625Z                     / "dq_test_nospecific_happy.yml"
2025-09-05T12:30:11.4677844Z                 )
2025-09-05T12:30:11.4678051Z             ),
2025-09-05T12:30:11.4678279Z             "No generic checks file available for "
2025-09-05T12:30:11.4678522Z             "dq.dq_test_fr_no_generic at "
2025-09-05T12:30:11.4678797Z             + str(
2025-09-05T12:30:11.4679007Z                 Path(
2025-09-05T12:30:11.4679254Z                     MAPPING_ROOT_DIR / "test" / "data" / "dq" / "dq_test_[]_no_generic.yml"
2025-09-05T12:30:11.4679496Z                 )
2025-09-05T12:30:11.4679699Z             ),
2025-09-05T12:30:11.4679934Z             "Number of columns matches: 4 expected and received",
2025-09-05T12:30:11.4680180Z             "Datatypes match",
2025-09-05T12:30:11.4680427Z             "['PK1', 'PK2'] is unique",
2025-09-05T12:30:11.4680656Z             "No nulls found in ['PK1', 'PK2']",
2025-09-05T12:30:11.4680904Z             "Primary key ['PK1', 'PK2'] validated successfully",
2025-09-05T12:30:11.4681140Z             "No nulls found in ['PK1']",
2025-09-05T12:30:11.4681369Z             "['PK2'] is unique",
2025-09-05T12:30:11.4681636Z             "Referential check successful, "
2025-09-05T12:30:11.4681884Z             "all values from Type with filter 'Type is not null' "
2025-09-05T12:30:11.4682133Z             "are present in reference.Lookup1",
2025-09-05T12:30:11.4682383Z             "No referential integrity checks",
2025-09-05T12:30:11.4682626Z             "Checks completed successfully",
2025-09-05T12:30:11.4682842Z         ]
2025-09-05T12:30:11.4683039Z     
2025-09-05T12:30:11.4683268Z         log = [log[i] for i in log_range]
2025-09-05T12:30:11.4683615Z     
2025-09-05T12:30:11.4683837Z         dq_validation = DQValidation(
2025-09-05T12:30:11.4684071Z             spark_session,
2025-09-05T12:30:11.4684306Z             table_name,
2025-09-05T12:30:11.4684539Z             schema_name="dq",
2025-09-05T12:30:11.4684773Z             dq_check_folder="test/data",
2025-09-05T12:30:11.4685008Z             run_month="",
2025-09-05T12:30:11.4685247Z             source_system=source_system,
2025-09-05T12:30:11.4685479Z             local=True,
2025-09-05T12:30:11.4685681Z         )
2025-09-05T12:30:11.4685879Z     
2025-09-05T12:30:11.4686119Z >       assert dq_validation.checks(functional=True)
2025-09-05T12:30:11.4686356Z E       assert None
2025-09-05T12:30:11.4686594Z E        +  where None = checks(functional=True)
2025-09-05T12:30:11.4686871Z E        +    where checks = <abnamro_bsrc_etl.dq.dq_validation.DQValidation object at 0x7fe8a44e9510>.checks
2025-09-05T12:30:11.4687006Z 
2025-09-05T12:30:11.4687244Z test/test_dq/test_dq_validation.py:483: AssertionError
2025-09-05T12:30:11.4687519Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4687860Z 2025-09-05 12:29:15 [INFO] __init__:  No generic checks file available for dq.dq_test_nospecific_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_[]_happy.yml
2025-09-05T12:30:11.4688256Z 2025-09-05 12:29:15 [INFO] __init__:  No generic checks file available for dq.dq_test_nospecific_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_[]_happy.yml
2025-09-05T12:30:11.4688652Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_nospecific_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_nospecific_happy.yml
2025-09-05T12:30:11.4689046Z 2025-09-05 12:29:15 [INFO] __init__:  No specific checks file available for dq.dq_test_nospecific_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_nospecific_happy.yml
2025-09-05T12:30:11.4689381Z 2025-09-05 12:29:15 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4689654Z 2025-09-05 12:29:15 [INFO] columns_datatypes:  No columns to check
2025-09-05T12:30:11.4689919Z 2025-09-05 12:29:15 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4690190Z 2025-09-05 12:29:15 [INFO] primary_key:  No Primary Key to check
2025-09-05T12:30:11.4690459Z 2025-09-05 12:29:15 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4690732Z 2025-09-05 12:29:15 [INFO] not_null:  No not nullable columns to check
2025-09-05T12:30:11.4691008Z 2025-09-05 12:29:15 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4691329Z 2025-09-05 12:29:15 [INFO] unique:  No unique columns to check
2025-09-05T12:30:11.4691609Z 2025-09-05 12:29:15 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4691904Z 2025-09-05 12:29:15 [INFO] referential_integrity:  No referential integrity checks
2025-09-05T12:30:11.4692189Z 2025-09-05 12:29:15 [INFO] checks:  No checks done
2025-09-05T12:30:11.4692445Z 2025-09-05 12:29:15 [INFO] checks:  No checks done
2025-09-05T12:30:11.4692715Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4693066Z INFO     betl_src_poc_logger:dq_validation.py:71 No generic checks file available for dq.dq_test_nospecific_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_[]_happy.yml
2025-09-05T12:30:11.4693783Z INFO     betl_src_poc_logger:dq_validation.py:87 No specific checks file available for dq.dq_test_nospecific_happy at /__w/167/s/Workspace/Shared/deployment/mappings/test/data/dq/dq_test_nospecific_happy.yml
2025-09-05T12:30:11.4694192Z INFO     betl_src_poc_logger:dq_validation.py:210 No columns to check
2025-09-05T12:30:11.4694489Z INFO     betl_src_poc_logger:dq_validation.py:278 No Primary Key to check
2025-09-05T12:30:11.4694795Z INFO     betl_src_poc_logger:dq_validation.py:387 No not nullable columns to check
2025-09-05T12:30:11.4695089Z INFO     betl_src_poc_logger:dq_validation.py:333 No unique columns to check
2025-09-05T12:30:11.4695381Z INFO     betl_src_poc_logger:dq_validation.py:427 No referential integrity checks
2025-09-05T12:30:11.4695680Z INFO     betl_src_poc_logger:dq_validation.py:171 No checks done
2025-09-05T12:30:11.4695978Z _ test_pipeline_yaml_integrated_target[parameters0-test_catalog.test_schema_20240801.testd1_test_target_table] _
2025-09-05T12:30:11.4696111Z 
2025-09-05T12:30:11.4696361Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4696735Z source_data = {'table_a': {'data': [(1, 2, 3, 1, 5, 1, ...), (2, 3, 3, 1, 5, 2, ...), (3, 1, 3, 0, 5, 3, ...)], 'schema': ['col01', ...col09b']}, 'table_c_testd1': {'data': [(1, 10, 11), (2, 10, 11), (3, 10, 11)], 'schema': ['col01c', 'col11', 'col12']}}
2025-09-05T12:30:11.4697111Z parameters = {'DELIVERY_ENTITY': 'TEST-D1', 'RUN_MONTH': '20240801'}
2025-09-05T12:30:11.4697388Z target_table_name = 'test_catalog.test_schema_20240801.testd1_test_target_table'
2025-09-05T12:30:11.4697500Z 
2025-09-05T12:30:11.4697726Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4697966Z         ("parameters", "target_table_name"),
2025-09-05T12:30:11.4698181Z         [
2025-09-05T12:30:11.4698397Z             (
2025-09-05T12:30:11.4698643Z                 {"RUN_MONTH": "20240801", "DELIVERY_ENTITY": "TEST-D1"},
2025-09-05T12:30:11.4698917Z                 "test_catalog.test_schema_20240801.testd1_test_target_table",
2025-09-05T12:30:11.4699153Z             ),
2025-09-05T12:30:11.4699357Z         ],
2025-09-05T12:30:11.4699564Z     )
2025-09-05T12:30:11.4699794Z     def test_pipeline_yaml_integrated_target(
2025-09-05T12:30:11.4700048Z         spark_session, source_data, parameters, target_table_name
2025-09-05T12:30:11.4700272Z     ):
2025-09-05T12:30:11.4700528Z         """Test full pipeline of YAML, Integrated data and (filtered) target attributes.
2025-09-05T12:30:11.4700759Z     
2025-09-05T12:30:11.4700983Z         Check `test/data/TEST_YAML.yml` for:
2025-09-05T12:30:11.4701209Z         - `description`
2025-09-05T12:30:11.4701426Z         - `sources`
2025-09-05T12:30:11.4701645Z         - `transformations`
2025-09-05T12:30:11.4701893Z         - `expressions`
2025-09-05T12:30:11.4702110Z         - `filter_target`
2025-09-05T12:30:11.4702328Z         """
2025-09-05T12:30:11.4702579Z >       business_logic = parse_yaml("../test/data/TEST_YAML.yml", parameters=parameters)
2025-09-05T12:30:11.4702696Z 
2025-09-05T12:30:11.4702943Z test/test_transform/test_pipeline_yaml_integrated_target.py:80: 
2025-09-05T12:30:11.4703220Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2025-09-05T12:30:11.4703630Z src/abnamro_bsrc_etl/utils/parse_yaml.py:32: in parse_yaml
2025-09-05T12:30:11.4703909Z     with Path.open(MAPPING_ROOT_DIR / "business_logic" / yaml_path) as yaml_file:
2025-09-05T12:30:11.4704174Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2025-09-05T12:30:11.4704281Z 
2025-09-05T12:30:11.4704542Z self = PosixPath('/__w/167/s/Workspace/Shared/deployment/mappings/business_logic/../test/data/TEST_YAML.yml')
2025-09-05T12:30:11.4704837Z mode = 'r', buffering = -1, encoding = 'locale', errors = None, newline = None
2025-09-05T12:30:11.4704946Z 
2025-09-05T12:30:11.4705193Z     def open(self, mode='r', buffering=-1, encoding=None,
2025-09-05T12:30:11.4705443Z              errors=None, newline=None):
2025-09-05T12:30:11.4705656Z         """
2025-09-05T12:30:11.4705944Z         Open the file pointed by this path and return a file object, as
2025-09-05T12:30:11.4706211Z         the built-in open() function does.
2025-09-05T12:30:11.4706429Z         """
2025-09-05T12:30:11.4706640Z         if "b" not in mode:
2025-09-05T12:30:11.4706878Z             encoding = io.text_encoding(encoding)
2025-09-05T12:30:11.4707146Z >       return io.open(self, mode, buffering, encoding, errors, newline)
2025-09-05T12:30:11.4707457Z E       FileNotFoundError: [Errno 2] No such file or directory: '/__w/167/s/Workspace/Shared/deployment/mappings/business_logic/../test/data/TEST_YAML.yml'
2025-09-05T12:30:11.4707607Z 
2025-09-05T12:30:11.4707854Z /usr/local/lib/python3.11/pathlib.py:1044: FileNotFoundError
2025-09-05T12:30:11.4708412Z ___________________________ test_pipeline_yaml_pivot ___________________________
2025-09-05T12:30:11.4708590Z 
2025-09-05T12:30:11.4727943Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4728144Z 
2025-09-05T12:30:11.4728423Z     def test_pipeline_yaml_pivot(spark_session):
2025-09-05T12:30:11.4728704Z >       business_logic = parse_yaml("../test/data/TEST_YAML_PIVOT.yml")
2025-09-05T12:30:11.4728822Z 
2025-09-05T12:30:11.4729086Z test/test_transform/test_pipeline_yaml_integrated_target.py:210: 
2025-09-05T12:30:11.4729364Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2025-09-05T12:30:11.4729633Z src/abnamro_bsrc_etl/utils/parse_yaml.py:32: in parse_yaml
2025-09-05T12:30:11.4729928Z     with Path.open(MAPPING_ROOT_DIR / "business_logic" / yaml_path) as yaml_file:
2025-09-05T12:30:11.4730192Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2025-09-05T12:30:11.4730287Z 
2025-09-05T12:30:11.4730554Z self = PosixPath('/__w/167/s/Workspace/Shared/deployment/mappings/business_logic/../test/data/TEST_YAML_PIVOT.yml')
2025-09-05T12:30:11.4730871Z mode = 'r', buffering = -1, encoding = 'locale', errors = None, newline = None
2025-09-05T12:30:11.4730985Z 
2025-09-05T12:30:11.4731218Z     def open(self, mode='r', buffering=-1, encoding=None,
2025-09-05T12:30:11.4731470Z              errors=None, newline=None):
2025-09-05T12:30:11.4731690Z         """
2025-09-05T12:30:11.4731947Z         Open the file pointed by this path and return a file object, as
2025-09-05T12:30:11.4732208Z         the built-in open() function does.
2025-09-05T12:30:11.4732427Z         """
2025-09-05T12:30:11.4732649Z         if "b" not in mode:
2025-09-05T12:30:11.4732903Z             encoding = io.text_encoding(encoding)
2025-09-05T12:30:11.4733167Z >       return io.open(self, mode, buffering, encoding, errors, newline)
2025-09-05T12:30:11.4733629Z E       FileNotFoundError: [Errno 2] No such file or directory: '/__w/167/s/Workspace/Shared/deployment/mappings/business_logic/../test/data/TEST_YAML_PIVOT.yml'
2025-09-05T12:30:11.4733787Z 
2025-09-05T12:30:11.4734046Z /usr/local/lib/python3.11/pathlib.py:1044: FileNotFoundError
2025-09-05T12:30:11.4734328Z _______________________________ test_run_mapping _______________________________
2025-09-05T12:30:11.4734447Z 
2025-09-05T12:30:11.4734695Z spark_session = <pyspark.sql.session.SparkSession object at 0x7fe8a4d9ec90>
2025-09-05T12:30:11.4735024Z 
2025-09-05T12:30:11.4735255Z     def test_run_mapping(spark_session):
2025-09-05T12:30:11.4735517Z         """Test full pipeline from run_mapping script"""
2025-09-05T12:30:11.4735747Z     
2025-09-05T12:30:11.4735983Z         source_dict = {
2025-09-05T12:30:11.4736214Z             "table_a": {
2025-09-05T12:30:11.4736451Z                 "data": [("a", "b", 2), ("a", "b", 4)],
2025-09-05T12:30:11.4736700Z                 "schema": ["col01", "col02", "col03"],
2025-09-05T12:30:11.4736940Z             },
2025-09-05T12:30:11.4737163Z             "table_b": {
2025-09-05T12:30:11.4737399Z                 "data": [("a", "X"), ("a", "Y"), ("b", "Z")],
2025-09-05T12:30:11.4737642Z                 "schema": ["col01", "col04"],
2025-09-05T12:30:11.4737872Z             },
2025-09-05T12:30:11.4738159Z             "table_c": {
2025-09-05T12:30:11.4738392Z                 "data": [(2, 1.3, 1.8), (2, 2.6, 3.5)],
2025-09-05T12:30:11.4738636Z                 "schema": ["X", "col05", "col06"],
2025-09-05T12:30:11.4738864Z             },
2025-09-05T12:30:11.4739073Z         }
2025-09-05T12:30:11.4739318Z         for source_name, source_data in source_dict.items():
2025-09-05T12:30:11.4739590Z             spark_session.createDataFrame(**source_data).createOrReplaceTempView(
2025-09-05T12:30:11.4739855Z                 source_name
2025-09-05T12:30:11.4740067Z             )
2025-09-05T12:30:11.4740269Z     
2025-09-05T12:30:11.4740478Z >       run_mapping(
2025-09-05T12:30:11.4740712Z             spark_session,
2025-09-05T12:30:11.4740939Z             stage="test/data",
2025-09-05T12:30:11.4741177Z             target_mapping="TEST_YAML_PIVOT.yml",
2025-09-05T12:30:11.4741412Z             run_month="",
2025-09-05T12:30:11.4741641Z             local=True,
2025-09-05T12:30:11.4741843Z         )
2025-09-05T12:30:11.4741924Z 
2025-09-05T12:30:11.4742175Z test/test_transform/test_pipeline_yaml_integrated_target.py:288: 
2025-09-05T12:30:11.4742453Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2025-09-05T12:30:11.4742737Z src/abnamro_bsrc_etl/scripts/run_mapping.py:60: in run_mapping
2025-09-05T12:30:11.4742998Z     business_logic_dict = parse_yaml(
2025-09-05T12:30:11.4743262Z src/abnamro_bsrc_etl/utils/parse_yaml.py:32: in parse_yaml
2025-09-05T12:30:11.4743646Z     with Path.open(MAPPING_ROOT_DIR / "business_logic" / yaml_path) as yaml_file:
2025-09-05T12:30:11.4743935Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2025-09-05T12:30:11.4744032Z 
2025-09-05T12:30:11.4744295Z self = PosixPath('/__w/167/s/Workspace/Shared/deployment/mappings/test/data/TEST_YAML_PIVOT.yml')
2025-09-05T12:30:11.4744600Z mode = 'r', buffering = -1, encoding = 'locale', errors = None, newline = None
2025-09-05T12:30:11.4744712Z 
2025-09-05T12:30:11.4744961Z     def open(self, mode='r', buffering=-1, encoding=None,
2025-09-05T12:30:11.4745216Z              errors=None, newline=None):
2025-09-05T12:30:11.4745427Z         """
2025-09-05T12:30:11.4745670Z         Open the file pointed by this path and return a file object, as
2025-09-05T12:30:11.4745936Z         the built-in open() function does.
2025-09-05T12:30:11.4746151Z         """
2025-09-05T12:30:11.4746366Z         if "b" not in mode:
2025-09-05T12:30:11.4746600Z             encoding = io.text_encoding(encoding)
2025-09-05T12:30:11.4746859Z >       return io.open(self, mode, buffering, encoding, errors, newline)
2025-09-05T12:30:11.4747168Z E       FileNotFoundError: [Errno 2] No such file or directory: '/__w/167/s/Workspace/Shared/deployment/mappings/test/data/TEST_YAML_PIVOT.yml'
2025-09-05T12:30:11.4747309Z 
2025-09-05T12:30:11.4747547Z /usr/local/lib/python3.11/pathlib.py:1044: FileNotFoundError
2025-09-05T12:30:11.4747836Z ----------------------------- Captured stdout call -----------------------------
2025-09-05T12:30:11.4748137Z 2025-09-05 12:29:40 [ERROR] write_to_log:  Error writing to process log table log_.process_log
2025-09-05T12:30:11.4748410Z Traceback (most recent call last):
2025-09-05T12:30:11.4748753Z   File "/__w/167/s/src/abnamro_bsrc_etl/utils/table_logging.py", line 33, in write_to_log
2025-09-05T12:30:11.4749026Z     log_entry_df.write.mode("append").saveAsTable(
2025-09-05T12:30:11.4749320Z   File "/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/pyspark/sql/readwriter.py", line 1586, in saveAsTable
2025-09-05T12:30:11.4749606Z     self._jwrite.saveAsTable(name)
2025-09-05T12:30:11.4749900Z   File "/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/py4j/java_gateway.py", line 1322, in __call__
2025-09-05T12:30:11.4750175Z     return_value = get_return_value(
2025-09-05T12:30:11.4750401Z                    ^^^^^^^^^^^^^^^^^
2025-09-05T12:30:11.4750682Z   File "/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
2025-09-05T12:30:11.4751001Z     raise converted from None
2025-09-05T12:30:11.4751289Z pyspark.errors.exceptions.captured.AnalysisException: Couldn't find a catalog to handle the identifier bsrc_d.log_.process_log.
2025-09-05T12:30:11.4751611Z 2025-09-05 12:29:40 [ERROR] write_to_log:  Error writing to process log table log_.process_log
2025-09-05T12:30:11.4751887Z Traceback (most recent call last):
2025-09-05T12:30:11.4752149Z   File "/__w/167/s/src/abnamro_bsrc_etl/utils/table_logging.py", line 33, in write_to_log
2025-09-05T12:30:11.4752417Z     log_entry_df.write.mode("append").saveAsTable(
2025-09-05T12:30:11.4752709Z   File "/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/pyspark/sql/readwriter.py", line 1586, in saveAsTable
2025-09-05T12:30:11.4752986Z     self._jwrite.saveAsTable(name)
2025-09-05T12:30:11.4753267Z   File "/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/py4j/java_gateway.py", line 1322, in __call__
2025-09-05T12:30:11.4753725Z     return_value = get_return_value(
2025-09-05T12:30:11.4754033Z                    ^^^^^^^^^^^^^^^^^
2025-09-05T12:30:11.4754315Z   File "/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
2025-09-05T12:30:11.4754603Z     raise converted from None
2025-09-05T12:30:11.4754893Z pyspark.errors.exceptions.captured.AnalysisException: Couldn't find a catalog to handle the identifier bsrc_d.log_.process_log.
2025-09-05T12:30:11.4755217Z ------------------------------ Captured log call -------------------------------
2025-09-05T12:30:11.4755524Z ERROR    betl_src_poc_logger:table_logging.py:37 Error writing to process log table log_.process_log
2025-09-05T12:30:11.4755808Z Traceback (most recent call last):
2025-09-05T12:30:11.4756085Z   File "/__w/167/s/src/abnamro_bsrc_etl/utils/table_logging.py", line 33, in write_to_log
2025-09-05T12:30:11.4756349Z     log_entry_df.write.mode("append").saveAsTable(
2025-09-05T12:30:11.4756634Z   File "/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/pyspark/sql/readwriter.py", line 1586, in saveAsTable
2025-09-05T12:30:11.4756913Z     self._jwrite.saveAsTable(name)
2025-09-05T12:30:11.4757189Z   File "/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/py4j/java_gateway.py", line 1322, in __call__
2025-09-05T12:30:11.4757470Z     return_value = get_return_value(
2025-09-05T12:30:11.4757686Z                    ^^^^^^^^^^^^^^^^^
2025-09-05T12:30:11.4757962Z   File "/home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
2025-09-05T12:30:11.4758235Z     raise converted from None
2025-09-05T12:30:11.4758513Z pyspark.errors.exceptions.captured.AnalysisException: Couldn't find a catalog to handle the identifier bsrc_d.log_.process_log.
2025-09-05T12:30:11.4758828Z ___________________ test_parse_yaml[IHUB-FR1-202412-output0] ___________________
2025-09-05T12:30:11.4758941Z 
2025-09-05T12:30:11.4759175Z delivery_entity = 'IHUB-FR1', run_month = '202412'
2025-09-05T12:30:11.4759532Z output = {'expressions': {'DeliveryEntity': "'IHUB-FR1'", 'DeliveryEntity2': "'IHUB-FR1'", 'NewCol01': 'TBLA.col01', 'NewCol11'...BLA', 'right_source': 'TBLC'}}, {'add_variables': {'column_mapping': {'var': "colA in ('''ABC''', '''IHUB-FR1''')"}}}]}
2025-09-05T12:30:11.4759835Z 
2025-09-05T12:30:11.4760059Z     @pytest.mark.parametrize(
2025-09-05T12:30:11.4760311Z         ("delivery_entity", "run_month", "output"),
2025-09-05T12:30:11.4760534Z         [
2025-09-05T12:30:11.4760750Z             (
2025-09-05T12:30:11.4760967Z                 "IHUB-FR1",
2025-09-05T12:30:11.4761191Z                 "202412",
2025-09-05T12:30:11.4761403Z                 {
2025-09-05T12:30:11.4761657Z                     "target": "test_catalog.test_schema_202412.ihubfr1_test_target_table",
2025-09-05T12:30:11.4761897Z                     "sources": [
2025-09-05T12:30:11.4762107Z                         {
2025-09-05T12:30:11.4762327Z                             "alias": "TBLA",
2025-09-05T12:30:11.4762611Z                             "columns": ["col01", "col02", "col03"],
2025-09-05T12:30:11.4762870Z                             "filter": "col02 = '''IHUB-FR1''' AND col03 = '''IHUB-FR1'''",
2025-09-05T12:30:11.4763126Z                             "source": "schema1.ihubfr1_table_a",
2025-09-05T12:30:11.4763355Z                         },
2025-09-05T12:30:11.4763688Z                         {
2025-09-05T12:30:11.4763903Z                             "alias": "TBLC",
2025-09-05T12:30:11.4764140Z                             "columns": ["col01c", "col11", "col12"],
2025-09-05T12:30:11.4764385Z                             "source": "schema2.ihubfr1_table_c",
2025-09-05T12:30:11.4764610Z                         },
2025-09-05T12:30:11.4764819Z                     ],
2025-09-05T12:30:11.4765039Z                     "transformations": [
2025-09-05T12:30:11.4765267Z                         {
2025-09-05T12:30:11.4765484Z                             "join": {
2025-09-05T12:30:11.4765712Z                                 "left_source": "TBLA",
2025-09-05T12:30:11.4765948Z                                 "right_source": "TBLC",
2025-09-05T12:30:11.4766186Z                                 "condition": [
2025-09-05T12:30:11.4766428Z                                     "TBLA.col01 = TBLC.col01c",
2025-09-05T12:30:11.4766673Z                                     "TBLC.col12 = '''IHUB-FR1'''",
2025-09-05T12:30:11.4766912Z                                     "TBLC.col12 = '''IHUB-FR1'''",
2025-09-05T12:30:11.4767150Z                                 ],
2025-09-05T12:30:11.4767371Z                                 "how": "left",
2025-09-05T12:30:11.4767589Z                             }
2025-09-05T12:30:11.4767798Z                         },
2025-09-05T12:30:11.4768014Z                         {
2025-09-05T12:30:11.4768228Z                             "add_variables": {
2025-09-05T12:30:11.4768469Z                                 "column_mapping": {
2025-09-05T12:30:11.4768718Z                                     "var": "colA in ('''ABC''', '''IHUB-FR1''')"
2025-09-05T12:30:11.4768961Z                                 }
2025-09-05T12:30:11.4769171Z                             }
2025-09-05T12:30:11.4769384Z                         },
2025-09-05T12:30:11.4769595Z                     ],
2025-09-05T12:30:11.4769821Z                     "expressions": {
2025-09-05T12:30:11.4770064Z                         "DeliveryEntity": "'IHUB-FR1'",
2025-09-05T12:30:11.4770303Z                         "DeliveryEntity2": "'IHUB-FR1'",
2025-09-05T12:30:11.4770546Z                         "WrongDeliveryEntity": "ihubfr1",
2025-09-05T12:30:11.4770780Z                         "NewCol01": "TBLA.col01",
2025-09-05T12:30:11.4771016Z                         "NewCol11": "TBLC.col11",
2025-09-05T12:30:11.4771231Z                     },
2025-09-05T12:30:11.4771445Z                 },
2025-09-05T12:30:11.4771643Z             ),
2025-09-05T12:30:11.4771843Z         ],
2025-09-05T12:30:11.4772045Z     )
2025-09-05T12:30:11.4772291Z     def test_parse_yaml(delivery_entity, run_month, output):
2025-09-05T12:30:11.4772544Z         """Test Parse YAML file."""
2025-09-05T12:30:11.4772775Z >       business_logic = parse_yaml(
2025-09-05T12:30:11.4773083Z             "../test/data/test_parse_yaml.yml",
2025-09-05T12:30:11.4773454Z             parameters={"DELIVERY_ENTITY": delivery_entity, "RUN_MONTH": run_month},
2025-09-05T12:30:11.4773698Z         )
2025-09-05T12:30:11.4773783Z 
2025-09-05T12:30:11.4774018Z test/test_utils/test_parse_yaml.py:61: 
2025-09-05T12:30:11.4774273Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2025-09-05T12:30:11.4774549Z src/abnamro_bsrc_etl/utils/parse_yaml.py:32: in parse_yaml
2025-09-05T12:30:11.4774823Z     with Path.open(MAPPING_ROOT_DIR / "business_logic" / yaml_path) as yaml_file:
2025-09-05T12:30:11.4775089Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2025-09-05T12:30:11.4775186Z 
2025-09-05T12:30:11.4775457Z self = PosixPath('/__w/167/s/Workspace/Shared/deployment/mappings/business_logic/../test/data/test_parse_yaml.yml')
2025-09-05T12:30:11.4775809Z mode = 'r', buffering = -1, encoding = 'locale', errors = None, newline = None
2025-09-05T12:30:11.4775927Z 
2025-09-05T12:30:11.4776156Z     def open(self, mode='r', buffering=-1, encoding=None,
2025-09-05T12:30:11.4776415Z              errors=None, newline=None):
2025-09-05T12:30:11.4776636Z         """
2025-09-05T12:30:11.4776882Z         Open the file pointed by this path and return a file object, as
2025-09-05T12:30:11.4777135Z         the built-in open() function does.
2025-09-05T12:30:11.4777374Z         """
2025-09-05T12:30:11.4777595Z         if "b" not in mode:
2025-09-05T12:30:11.4777852Z             encoding = io.text_encoding(encoding)
2025-09-05T12:30:11.4778117Z >       return io.open(self, mode, buffering, encoding, errors, newline)
2025-09-05T12:30:11.4778450Z E       FileNotFoundError: [Errno 2] No such file or directory: '/__w/167/s/Workspace/Shared/deployment/mappings/business_logic/../test/data/test_parse_yaml.yml'
2025-09-05T12:30:11.4778606Z 
2025-09-05T12:30:11.4778848Z /usr/local/lib/python3.11/pathlib.py:1044: FileNotFoundError
2025-09-05T12:30:11.4779124Z _______________________________ test_get_schema ________________________________
2025-09-05T12:30:11.4779249Z 
2025-09-05T12:30:11.4779460Z     def test_get_schema():
2025-09-05T12:30:11.4779685Z         schema = StructType(
2025-09-05T12:30:11.4779895Z             [
2025-09-05T12:30:11.4780143Z                 StructField("MainIdentifier", LongType(), nullable=True),
2025-09-05T12:30:11.4780402Z                 StructField("MaxCol3", LongType(), nullable=True),
2025-09-05T12:30:11.4780657Z                 StructField("MedCol12", DoubleType(), nullable=True),
2025-09-05T12:30:11.4780916Z                 StructField("AvgCol09", DoubleType(), nullable=True),
2025-09-05T12:30:11.4781175Z                 StructField("NullInCase", StringType(), nullable=False),
2025-09-05T12:30:11.4781431Z                 StructField("StrInCase", StringType(), nullable=False),
2025-09-05T12:30:11.4781700Z                 StructField("ConstEmptyString", StringType(), nullable=False),
2025-09-05T12:30:11.4781967Z                 StructField("ConstInt", IntegerType(), nullable=False),
2025-09-05T12:30:11.4782228Z                 StructField("ConstString", StringType(), nullable=False),
2025-09-05T12:30:11.4782452Z             ]
2025-09-05T12:30:11.4782649Z         )
2025-09-05T12:30:11.4782867Z >       assert (
2025-09-05T12:30:11.4783121Z             get_schema_from_file(uc_schema="../test/data", table_name="TEST_SCHEMA")
2025-09-05T12:30:11.4783361Z             == schema
2025-09-05T12:30:11.4783781Z         )
2025-09-05T12:30:11.4783874Z 
2025-09-05T12:30:11.4784107Z test/test_utils/test_table_schema.py:27: 
2025-09-05T12:30:11.4784361Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2025-09-05T12:30:11.4784623Z src/abnamro_bsrc_etl/utils/table_schema.py:13: in get_schema_from_file
2025-09-05T12:30:11.4784867Z     with Path.open(
2025-09-05T12:30:11.4785120Z _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
2025-09-05T12:30:11.4785216Z 
2025-09-05T12:30:11.4785475Z self = PosixPath('/__w/167/s/Workspace/Shared/deployment/mappings/table_structures/../test/data/TEST_SCHEMA.json')
2025-09-05T12:30:11.4785853Z mode = 'r', buffering = -1, encoding = 'locale', errors = None, newline = None
2025-09-05T12:30:11.4785974Z 
2025-09-05T12:30:11.4786210Z     def open(self, mode='r', buffering=-1, encoding=None,
2025-09-05T12:30:11.4786460Z              errors=None, newline=None):
2025-09-05T12:30:11.4786679Z         """
2025-09-05T12:30:11.4786932Z         Open the file pointed by this path and return a file object, as
2025-09-05T12:30:11.4787192Z         the built-in open() function does.
2025-09-05T12:30:11.4787408Z         """
2025-09-05T12:30:11.4787626Z         if "b" not in mode:
2025-09-05T12:30:11.4787880Z             encoding = io.text_encoding(encoding)
2025-09-05T12:30:11.4788143Z >       return io.open(self, mode, buffering, encoding, errors, newline)
2025-09-05T12:30:11.4788511Z E       FileNotFoundError: [Errno 2] No such file or directory: '/__w/167/s/Workspace/Shared/deployment/mappings/table_structures/../test/data/TEST_SCHEMA.json'
2025-09-05T12:30:11.4788663Z 
2025-09-05T12:30:11.4788912Z /usr/local/lib/python3.11/pathlib.py:1044: FileNotFoundError
2025-09-05T12:30:11.4789193Z =============================== warnings summary ===============================
2025-09-05T12:30:11.4789504Z ../../../home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/holidays/deprecations/v1_incompatibility.py:40
2025-09-05T12:30:11.4789849Z   /home/pipeuser_azpcontainer/.local/lib/python3.11/site-packages/holidays/deprecations/v1_incompatibility.py:40: FutureIncompatibilityWarning: 
2025-09-05T12:30:11.4790128Z   
2025-09-05T12:30:11.4790376Z   This is a future version incompatibility warning from Holidays v0.62
2025-09-05T12:30:11.4790668Z   to inform you about an upcoming change in our API versioning strategy that may affect your
2025-09-05T12:30:11.4790973Z   project's dependencies. Starting from version 1.0 onwards, we will be following a loose form of
2025-09-05T12:30:11.4791370Z   Semantic Versioning (SemVer, https://semver.org) to provide clearer communication regarding any
2025-09-05T12:30:11.4791644Z   potential breaking changes.
2025-09-05T12:30:11.4791862Z   
2025-09-05T12:30:11.4792127Z   This means that while we strive to maintain backward compatibility, there might be occasional
2025-09-05T12:30:11.4792429Z   updates that introduce breaking changes to our API. To ensure the stability of your projects,
2025-09-05T12:30:11.4792725Z   we highly recommend pinning the version of our API that you rely on. You can pin your current
2025-09-05T12:30:11.4793024Z   holidays v0.x dependency (e.g., holidays==0.62) or limit it (e.g., holidays<1.0) in order to
2025-09-05T12:30:11.4793316Z   avoid potentially unwanted upgrade to the version 1.0 when it's released (ETA 2025Q1-Q2).
2025-09-05T12:30:11.4793616Z   
2025-09-05T12:30:11.4793864Z   If you have any questions or concerns regarding this change, please don't hesitate to reach out
2025-09-05T12:30:11.4794153Z   to us via https://github.com/vacanza/holidays/discussions/1800.
2025-09-05T12:30:11.4794387Z   
2025-09-05T12:30:11.4794596Z     warnings.warn(
2025-09-05T12:30:11.4794684Z 
2025-09-05T12:30:11.4794944Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2025-09-05T12:30:11.4795230Z --- generated xml file: /__w/167/TestResults/test_report/test-results-1.xml ----
2025-09-05T12:30:11.4795340Z 
2025-09-05T12:30:11.4795580Z ---------- coverage: platform linux, python 3.11.13-final-0 ----------
2025-09-05T12:30:11.4795855Z Name                                                             Stmts   Miss Branch BrPart  Cover   Missing
2025-09-05T12:30:11.4796152Z ------------------------------------------------------------------------------------------------------------
2025-09-05T12:30:11.4796430Z src/__init__.py                                                      0      0      0      0   100%
2025-09-05T12:30:11.4796681Z src/abnamro_bsrc_etl/__init__.py                                     0      0      0      0   100%
2025-09-05T12:30:11.4797002Z src/abnamro_bsrc_etl/config/__init__.py                              0      0      0      0   100%
2025-09-05T12:30:11.4797266Z src/abnamro_bsrc_etl/config/business_logic.py                       54      0      0      0   100%
2025-09-05T12:30:11.4797538Z src/abnamro_bsrc_etl/config/constants.py                             2      0      0      0   100%
2025-09-05T12:30:11.4797815Z src/abnamro_bsrc_etl/config/exceptions.py                           37      0      0      0   100%
2025-09-05T12:30:11.4798075Z src/abnamro_bsrc_etl/config/process.py                               7      0      0      0   100%
2025-09-05T12:30:11.4798338Z src/abnamro_bsrc_etl/config/schema.py                                5      0      0      0   100%
2025-09-05T12:30:11.4798617Z src/abnamro_bsrc_etl/config/ssf_tables.py                            2      0      0      0   100%
2025-09-05T12:30:11.4798913Z src/abnamro_bsrc_etl/dq/__init__.py                                  0      0      0      0   100%
2025-09-05T12:30:11.4799238Z src/abnamro_bsrc_etl/dq/dq_validation.py                           153     83     46      8    40%   69, 85, 178-193, 213-261, 281-298, 330->332, 335-362, 384->386, 389-404, 429-498
2025-09-05T12:30:11.4799544Z src/abnamro_bsrc_etl/extract/__init__.py                             0      0      0      0   100%
2025-09-05T12:30:11.4799839Z src/abnamro_bsrc_etl/extract/master_data_sql.py                     96     16     36      3    77%   87, 116-136, 162-164, 298->286
2025-09-05T12:30:11.4800128Z src/abnamro_bsrc_etl/month_setup/__init__.py                         0      0      0      0   100%
2025-09-05T12:30:11.4800405Z src/abnamro_bsrc_etl/month_setup/dial_derive_snapshotdate.py        36      0      8      0   100%
2025-09-05T12:30:11.4800698Z src/abnamro_bsrc_etl/month_setup/metadata_log_tables.py             40      9      8      0    81%   175-180, 187-191, 197-201
2025-09-05T12:30:11.4800990Z src/abnamro_bsrc_etl/month_setup/setup_new_month.py                 29     11      0      0    62%   60-84
2025-09-05T12:30:11.4801265Z src/abnamro_bsrc_etl/scripts/__init__.py                             0      0      0      0   100%
2025-09-05T12:30:11.4801536Z src/abnamro_bsrc_etl/scripts/check_dependencies.py                  26      0      2      0   100%
2025-09-05T12:30:11.4801852Z src/abnamro_bsrc_etl/scripts/dial_check_delayed_files.py            27      0      6      1    97%   67->exit
2025-09-05T12:30:11.4802134Z src/abnamro_bsrc_etl/scripts/dial_staging_process.py                65      0     22      0   100%
2025-09-05T12:30:11.4802411Z src/abnamro_bsrc_etl/scripts/export_tine_tables.py                  33      0      6      0   100%
2025-09-05T12:30:11.4802677Z src/abnamro_bsrc_etl/scripts/new_month_setup.py                      7      0      2      0   100%
2025-09-05T12:30:11.4802954Z src/abnamro_bsrc_etl/scripts/nonssf_staging_process.py              63      0     20      1    99%   38->exit
2025-09-05T12:30:11.4803228Z src/abnamro_bsrc_etl/scripts/run_mapping.py                         26      0      6      0   100%
2025-09-05T12:30:11.4803577Z src/abnamro_bsrc_etl/scripts/ssf_staging_process.py                 58      0     18      0   100%
2025-09-05T12:30:11.4803855Z src/abnamro_bsrc_etl/scripts/ssf_staging_process_xml.py             24      0      0      0   100%
2025-09-05T12:30:11.4804127Z src/abnamro_bsrc_etl/staging/__init__.py                             0      0      0      0   100%
2025-09-05T12:30:11.4804414Z src/abnamro_bsrc_etl/staging/extract_base.py                        77      3     10      2    94%   162-164, 311->321
2025-09-05T12:30:11.4804702Z src/abnamro_bsrc_etl/staging/extract_dial_data.py                   77      0      2      0   100%
2025-09-05T12:30:11.4805012Z src/abnamro_bsrc_etl/staging/extract_nonssf_data.py                153     17     40      6    88%   90, 121-126, 188-192, 195-200, 224-225, 274, 321->303, 355-357, 419-423
2025-09-05T12:30:11.4805373Z src/abnamro_bsrc_etl/staging/extract_ssf_data.py                   179     17     30      7    89%   271-275, 301-307, 322-323, 354, 461-462, 502->451, 514-515, 518-521, 616-619
2025-09-05T12:30:11.4805761Z src/abnamro_bsrc_etl/staging/status.py                              58      3      0      0    95%   18, 53-54
2025-09-05T12:30:11.4806025Z src/abnamro_bsrc_etl/transform/__init__.py                           0      0      0      0   100%
2025-09-05T12:30:11.4806301Z src/abnamro_bsrc_etl/transform/complex_types.py                     15      0      0      0   100%
2025-09-05T12:30:11.4806579Z src/abnamro_bsrc_etl/transform/table_write_and_comment.py           79      0     22      1    99%   225->227
2025-09-05T12:30:11.4806865Z src/abnamro_bsrc_etl/transform/transform_business_logic_sql.py       9      0      0      0   100%
2025-09-05T12:30:11.4807140Z src/abnamro_bsrc_etl/utils/__init__.py                               0      0      0      0   100%
2025-09-05T12:30:11.4807448Z src/abnamro_bsrc_etl/utils/alias_util.py                            18      0      0      0   100%
2025-09-05T12:30:11.4807720Z src/abnamro_bsrc_etl/utils/azure_utils.py                            5      0      0      0   100%
2025-09-05T12:30:11.4807987Z src/abnamro_bsrc_etl/utils/export_parquet.py                        22      2      0      0    91%   67-68
2025-09-05T12:30:11.4808263Z src/abnamro_bsrc_etl/utils/get_dbutils.py                            6      1      0      0    83%   11
2025-09-05T12:30:11.4808525Z src/abnamro_bsrc_etl/utils/get_env.py                               12      0      0      0   100%
2025-09-05T12:30:11.4808790Z src/abnamro_bsrc_etl/utils/logging_util.py                          10      0      0      0   100%
2025-09-05T12:30:11.4809058Z src/abnamro_bsrc_etl/utils/parameter_utils.py                       25      0     10      0   100%
2025-09-05T12:30:11.4809334Z src/abnamro_bsrc_etl/utils/parse_yaml.py                            28     18     12      0    25%   33-66, 91, 119-127
2025-09-05T12:30:11.4809627Z src/abnamro_bsrc_etl/utils/sources_util.py                          56      7     18      3    84%   25->19, 106-110, 149, 193, 202
2025-09-05T12:30:11.4809918Z src/abnamro_bsrc_etl/utils/table_logging.py                         19      0      2      0   100%
2025-09-05T12:30:11.4810184Z src/abnamro_bsrc_etl/utils/table_schema.py                           6      1      0      0    83%   16
2025-09-05T12:30:11.4810459Z src/abnamro_bsrc_etl/utils/transformations_util.py                  20      0      4      0   100%
2025-09-05T12:30:11.4810737Z src/abnamro_bsrc_etl/utils/xml_utils.py                             86      5     30      3    91%   67->59, 94->96, 101-116
2025-09-05T12:30:11.4811018Z src/abnamro_bsrc_etl/validate/__init__.py                            0      0      0      0   100%
2025-09-05T12:30:11.4811278Z src/abnamro_bsrc_etl/validate/base.py                                5      0      0      0   100%
2025-09-05T12:30:11.4811543Z src/abnamro_bsrc_etl/validate/expressions.py                        34     12     10      1    57%   37-61
2025-09-05T12:30:11.4811821Z src/abnamro_bsrc_etl/validate/run_all.py                            15      0      2      0   100%
2025-09-05T12:30:11.4812083Z src/abnamro_bsrc_etl/validate/sources.py                            33      0      6      0   100%
2025-09-05T12:30:11.4812387Z src/abnamro_bsrc_etl/validate/transformations.py                   200     36     84      7    81%   66-72, 84->94, 97->102, 120, 135-136, 172->180, 307-317, 327-354, 477-478
2025-09-05T12:30:11.4812704Z src/abnamro_bsrc_etl/validate/validate_sql.py                       63      1     18      1    98%   87
2025-09-05T12:30:11.4812963Z src/abnamro_bsrc_etl/validate/yaml.py                               19      0      2      0   100%
2025-09-05T12:30:11.4813247Z ------------------------------------------------------------------------------------------------------------
2025-09-05T12:30:11.4813603Z TOTAL                                                             2119    242    482     44    86%
2025-09-05T12:30:11.4813855Z Coverage HTML written to dir htmlcov
2025-09-05T12:30:11.4813990Z 
2025-09-05T12:30:11.4814235Z =========================== short test summary info ============================
2025-09-05T12:30:11.4814542Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_happy-True-Checks completed successfully]
2025-09-05T12:30:11.4814881Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_happy_col_num-True-Checks completed successfully]
2025-09-05T12:30:11.4815219Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_unhappy_col_num-False-Checks completed - DQ issues found]
2025-09-05T12:30:11.4815550Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_unhappy_pk_dup-False-Checks completed - DQ issues found]
2025-09-05T12:30:11.4815889Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_unhappy_pk_null-False-Checks completed - DQ issues found]
2025-09-05T12:30:11.4816252Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_unhappy_not_null-False-Checks completed - DQ issues found]
2025-09-05T12:30:11.4816593Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_unhappy_num_cols-False-Checks completed - DQ issues found]
2025-09-05T12:30:11.4816934Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_unhappy_type_cols-False-Checks completed - DQ issues found]
2025-09-05T12:30:11.4817265Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_unhappy_ref-False-Checks completed - DQ issues found]
2025-09-05T12:30:11.4817600Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_unhappy_ref_filter-False-Checks completed - DQ issues found]
2025-09-05T12:30:11.4817949Z FAILED test/test_dq/test_dq_validation.py::test_dq_validation[dq_test_unhappy_unique-False-Checks completed - DQ issues found]
2025-09-05T12:30:11.4818275Z FAILED test/test_dq/test_dq_validation.py::test_columns[dq_test_happy-True-expected_logging0]
2025-09-05T12:30:11.4818594Z FAILED test/test_dq/test_dq_validation.py::test_columns[dq_test_happy_col_num-True-expected_logging1]
2025-09-05T12:30:11.4818926Z FAILED test/test_dq/test_dq_validation.py::test_columns[dq_test_unhappy_col_num-False-expected_logging3]
2025-09-05T12:30:11.4819248Z FAILED test/test_dq/test_dq_validation.py::test_columns[dq_test_unhappy_num_cols-False-expected_logging4]
2025-09-05T12:30:11.4819566Z FAILED test/test_dq/test_dq_validation.py::test_columns[dq_test_unhappy_type_cols-False-expected_logging5]
2025-09-05T12:30:11.4819886Z FAILED test/test_dq/test_dq_validation.py::test_primary_key[dq_test_happy-True-expected_logging0]
2025-09-05T12:30:11.4820209Z FAILED test/test_dq/test_dq_validation.py::test_primary_key[dq_test_unhappy_pk_dup-False-expected_logging2]
2025-09-05T12:30:11.4820532Z FAILED test/test_dq/test_dq_validation.py::test_primary_key[dq_test_unhappy_pk_null-False-expected_logging3]
2025-09-05T12:30:11.4820848Z FAILED test/test_dq/test_dq_validation.py::test_not_nulls[dq_test_happy-True-expected_logging0]
2025-09-05T12:30:11.4821175Z FAILED test/test_dq/test_dq_validation.py::test_not_nulls[dq_test_unhappy_not_null-False-expected_logging2]
2025-09-05T12:30:11.4821499Z FAILED test/test_dq/test_dq_validation.py::test_referential_integrity[dq_test_happy-True-expected_logging0]
2025-09-05T12:30:11.4821825Z FAILED test/test_dq/test_dq_validation.py::test_referential_integrity[dq_test_unhappy_ref-False-expected_logging2]
2025-09-05T12:30:11.4822178Z FAILED test/test_dq/test_dq_validation.py::test_referential_integrity[dq_test_unhappy_ref_filter-False-expected_logging3]
2025-09-05T12:30:11.4822505Z FAILED test/test_dq/test_dq_validation.py::test_unique[dq_test_happy-True-expected_logging0]
2025-09-05T12:30:11.4822814Z FAILED test/test_dq/test_dq_validation.py::test_unique[dq_test_unhappy_unique-False-expected_logging2]
2025-09-05T12:30:11.4823124Z FAILED test/test_dq/test_dq_validation.py::test_generic_checks[dq_test_fr_happy-fr-log_range0]
2025-09-05T12:30:11.4823531Z FAILED test/test_dq/test_dq_validation.py::test_generic_checks[dq_test_fr_no_generic-fr-log_range1]
2025-09-05T12:30:11.4823918Z FAILED test/test_dq/test_dq_validation.py::test_generic_checks[dq_test_nospecific_happy-nospecific-log_range2]
2025-09-05T12:30:11.4824287Z FAILED test/test_transform/test_pipeline_yaml_integrated_target.py::test_pipeline_yaml_integrated_target[parameters0-test_catalog.test_schema_20240801.testd1_test_target_table]
2025-09-05T12:30:11.4824667Z FAILED test/test_transform/test_pipeline_yaml_integrated_target.py::test_pipeline_yaml_pivot
2025-09-05T12:30:11.4824973Z FAILED test/test_transform/test_pipeline_yaml_integrated_target.py::test_run_mapping
2025-09-05T12:30:11.4825277Z FAILED test/test_utils/test_parse_yaml.py::test_parse_yaml[IHUB-FR1-202412-output0]
2025-09-05T12:30:11.4825583Z FAILED test/test_utils/test_table_schema.py::test_get_schema - FileNotFoundEr...
2025-09-05T12:30:11.4825884Z ============ 34 failed, 363 passed, 1 warning in 120.97s (0:02:00) =============
2025-09-05T12:30:11.8455233Z 
2025-09-05T12:30:11.8497395Z ##[error]Bash exited with code '1'.
2025-09-05T12:30:11.8605189Z ##[section]Finishing: Test with pytest
